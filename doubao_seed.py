"""
Doubao-Seed èŠ‚ç‚¹
åŸºäºComfyUI_Comflyé¡¹ç›®çš„Doubao Seedream4å®ç°
é›†æˆå¤šå®¶APIè°ƒç”¨ï¼Œæ”¯æŒå›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”ŸæˆåŠŸèƒ½
"""

import os
import json
import requests
import time
import random
import base64
import io
import subprocess
from PIL import Image
import torch
import numpy as np
from typing import Optional, Dict, Any, List, Tuple
import urllib3
import ssl
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import tempfile
import shutil
from urllib.parse import urlparse
from fractions import Fraction

# å¯¼å…¥ComfyUIçš„è§†é¢‘ç±»å‹ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†
try:
    from comfy_api.input_impl import VideoFromFile
    HAS_COMFYUI_VIDEO = True
    print("[SeedReam4API] ä¿¡æ¯ï¼šâœ… ComfyUIå®˜æ–¹è§†é¢‘ç±»å‹å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    try:
        # å°è¯•æ—§ç‰ˆæœ¬è·¯å¾„
        from comfy_api.latest._input_impl.video_types import VideoFromComponents
        from comfy_api.latest._util import VideoComponents
        HAS_COMFYUI_VIDEO = True
        print("[SeedReam4API] ä¿¡æ¯ï¼šâœ… ComfyUIè§†é¢‘ç±»å‹å¯¼å…¥æˆåŠŸï¼ˆæ—§ç‰ˆæœ¬ï¼‰")
        # åˆ›å»ºVideoFromFileçš„å…¼å®¹ç±»
        class VideoFromFile:
            def __init__(self, file_or_components):
                if hasattr(file_or_components, 'images'):
                    # è¿™æ˜¯VideoComponentså¯¹è±¡
                    self.components = file_or_components
                    self.file_path = None  # ç»„ä»¶æ¨¡å¼æ²¡æœ‰æ–‡ä»¶è·¯å¾„
                else:
                    # è¿™æ˜¯æ–‡ä»¶è·¯å¾„æˆ–BytesIO
                    self.file_path = file_or_components
                    self.file = file_or_components  # ä¿æŒå‘åå…¼å®¹
            def get_dimensions(self):
                if hasattr(self, 'components'):
                    return self.components.images.shape[2], self.components.images.shape[1]
                else:
                    # ä»æ–‡ä»¶è¯»å–å°ºå¯¸
                    return (512, 512)  # é»˜è®¤å°ºå¯¸
    except ImportError:
        HAS_COMFYUI_VIDEO = False
        print(f"[SeedReam4API] è­¦å‘Šï¼šâš ï¸ ComfyUIè§†é¢‘ç±»å‹å¯¼å…¥å¤±è´¥: {e}")
        # åˆ›å»ºç®€å•çš„æ›¿ä»£ç±»
        class VideoFromFile:
            def __init__(self, file_path):
                self.file_path = file_path
            def get_dimensions(self):
                return (512, 512)  # é»˜è®¤å°ºå¯¸

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†åº“
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    _log_warning("OpenCVæœªå®‰è£…ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å—é™")

try:
    import imageio
    HAS_IMAGEIO = True
except ImportError:
    HAS_IMAGEIO = False

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def create_ssl_compatible_session():
    """åˆ›å»ºSSLå…¼å®¹çš„requests session"""
    session = requests.Session()

    # é…ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )

    # åˆ›å»ºè‡ªå®šä¹‰çš„HTTPAdapter
    class SSLAdapter(HTTPAdapter):
        def init_poolmanager(self, *args, **kwargs):
            # åˆ›å»ºæ›´å®½æ¾çš„SSLä¸Šä¸‹æ–‡
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            # æ”¯æŒæ›´å¤šSSLåè®®ç‰ˆæœ¬å’Œå¯†ç å¥—ä»¶
            try:
                ssl_context.minimum_version = ssl.TLSVersion.TLSv1
                ssl_context.maximum_version = ssl.TLSVersion.TLSv1_3
            except AttributeError:
                # å…¼å®¹æ—§ç‰ˆæœ¬Python
                pass

            # è®¾ç½®æ›´å®½æ¾çš„å¯†ç å¥—ä»¶
            try:
                ssl_context.set_ciphers('DEFAULT:@SECLEVEL=1')
            except ssl.SSLError:
                try:
                    ssl_context.set_ciphers('ALL:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!SRP:!CAMELLIA')
                except ssl.SSLError:
                    pass  # ä½¿ç”¨é»˜è®¤å¯†ç å¥—ä»¶

            # ç¦ç”¨å„ç§SSLæ£€æŸ¥
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            kwargs['ssl_context'] = ssl_context
            return super().init_poolmanager(*args, **kwargs)

    # åº”ç”¨é€‚é…å™¨
    adapter = SSLAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)

    # è®¾ç½®è¶…æ—¶å’Œå…¶ä»–é€‰é¡¹
    session.verify = False  # ç¦ç”¨SSLéªŒè¯

    return session

# å…¨å±€å¸¸é‡å’Œé…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SEEDREAM4_CONFIG_FILE = 'SeedReam4_config.json'

def _log_info(message):
    print(f"[SeedReam4API] ä¿¡æ¯ï¼š{message}")

def _log_warning(message):
    print(f"[SeedReam4API] è­¦å‘Šï¼š{message}")

def _log_error(message):
    print(f"[SeedReam4API] é”™è¯¯ï¼š{message}")

def get_seedream4_config():
    """è·å–SeedReam4é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(CURRENT_DIR, SEEDREAM4_CONFIG_FILE)
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        else:
            _log_warning(f"æœªæ‰¾åˆ°SeedReam4é…ç½®æ–‡ä»¶ {SEEDREAM4_CONFIG_FILE}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return get_default_config()
    except Exception as e:
        _log_error(f"è¯»å–SeedReam4é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return get_default_config()

def get_default_config():
    """è·å–é»˜è®¤é…ç½®"""
    return {
        "api_key": "",
        "base_url": "https://ai.comfly.chat/v1",
        "proxy": "None",
        "default_model": "doubao-seedream-4-0-250828",
        "timeout": 900,
        "max_retries": 3,
        "mirror_sites": {
            "comfly": {
                "url": "https://ai.comfly.chat/v1",
                "api_key": "",
                "api_format": "comfly",
                "models": ["doubao-seedream-4-0-250828"],
                "video_models": ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"],
                "description": "Comflyå®˜æ–¹APIï¼Œæ”¯æŒSeedReam4.0æ¨¡å‹å’ŒSeedanceè§†é¢‘ç”Ÿæˆ"
            },
            "t8_mirror": {
                "url": "https://ai.t8star.cn",
                "api_key": "",
                "api_format": "volcengine",
                "models": ["doubao-seedream-4-0-250828"],
                "video_models": ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"],
                "description": "T8é•œåƒç«™ï¼Œä½¿ç”¨ç«å±±å¼•æ“å®˜æ–¹æ ¼å¼API"
            },
            "volcengine": {
                "url": "https://ark.cn-beijing.volces.com",
                "api_key": "",
                "api_format": "volcengine",
                "models": ["doubao-seedream-4-0-250828"],
                "video_models": ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"],
                "description": "ç«å±±å¼•æ“å®˜æ–¹APIï¼Œæ”¯æŒå›¾åƒå’Œè§†é¢‘ç”Ÿæˆ"
            }
        },
        "size_mapping": {
            "1K": {
                "1:1": "1024x1024",
                "4:3": "1152x864",
                "3:4": "864x1152",
                "16:9": "1280x720",
                "9:16": "720x1280",
                "2:3": "832x1248",
                "3:2": "1248x832",
                "21:9": "1512x648",
                "9:21": "648x1512"
            },
            "2K": {
                "1:1": "2048x2048",
                "4:3": "2048x1536",
                "3:4": "1536x2048",
                "16:9": "2048x1152",
                "9:16": "1152x2048",
                "2:3": "1536x2048",
                "3:2": "2048x1536",
                "21:9": "2048x864",
                "9:21": "864x2048"
            },
            "4K": {
                "1:1": "4096x4096",
                "4:3": "4096x3072",
                "3:4": "3072x4096",
                "16:9": "4096x2304",
                "9:16": "2304x4096",
                "2:3": "3072x4096",
                "3:2": "4096x3072",
                "21:9": "4096x1728",
                "9:21": "1728x4096"
            }
        },
        "resolution_factors": {
            "1K": 1,
            "2K": 2,
            "4K": 4
        }
    }

def save_seedream4_config(config):
    """ä¿å­˜SeedReam4é…ç½®"""
    config_path = os.path.join(CURRENT_DIR, SEEDREAM4_CONFIG_FILE)
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=4, ensure_ascii=False)
        _log_info("SeedReam4é…ç½®ä¿å­˜æˆåŠŸ")
    except Exception as e:
        _log_error(f"ä¿å­˜SeedReam4é…ç½®å¤±è´¥: {e}")

def get_mirror_site_config(mirror_site_name: str) -> Dict[str, str]:
    """æ ¹æ®é•œåƒç«™åç§°æˆ–URLè·å–å¯¹åº”çš„é…ç½®"""
    config = get_seedream4_config()
    mirror_sites = config.get('mirror_sites', {})

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥çš„URL
    if validate_api_url(mirror_site_name):
        # ç›´æ¥ä½¿ç”¨æä¾›çš„URL
        api_format = "comfly"  # é»˜è®¤æ ¼å¼

        # æ ¹æ®URLç‰¹å¾åˆ¤æ–­APIæ ¼å¼
        if "t8star.cn" in mirror_site_name:
            api_format = "volcengine"  # T8é•œåƒç«™ä½¿ç”¨ç«å±±å¼•æ“å®˜æ–¹æ ¼å¼
        elif "volcengine" in mirror_site_name or "volces.com" in mirror_site_name:
            api_format = "volcengine"
        elif "openrouter" in mirror_site_name:
            api_format = "openrouter"
        elif "api4gpt" in mirror_site_name:
            api_format = "api4gpt"

        return {
            "url": mirror_site_name,
            "api_key": "",
            "api_format": api_format,
            "models": [],
            "video_models": ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"],
            "description": f"ç›´æ¥URL: {mirror_site_name}"
        }

    # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„å®šä¹‰çš„é•œåƒç«™åç§°
    if mirror_site_name in mirror_sites:
        site_config = mirror_sites[mirror_site_name]
        return {
            "url": site_config.get("url", ""),
            "api_key": site_config.get("api_key", ""),
            "api_format": site_config.get("api_format", "comfly"),
            "models": site_config.get("models", []),
            "video_models": site_config.get("video_models", ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"]),
            "description": site_config.get("description", "")
        }

    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤é…ç½®
    return {
        "url": "https://ai.comfly.chat/v1",
        "api_key": "",
        "api_format": "comfly",
        "models": ["doubao-seedream-4-0-250828"],
        "video_models": ["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"],
        "description": "é»˜è®¤Comflyé…ç½®"
    }

def validate_api_key(api_key):
    """éªŒè¯API keyæ ¼å¼"""
    return api_key and len(api_key.strip()) > 10

def validate_api_url(url):
    """éªŒè¯API URLæ ¼å¼"""
    if not url or not url.strip():
        return False
    url = url.strip().rstrip('/')
    return url.startswith('http://') or url.startswith('https://')

def tensor2pil(tensor):
    """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ - æ”¯æŒComfyUIçš„[B, H, W, C]æ ¼å¼"""
    if tensor is None:
        _log_warning("âš ï¸ tensor2pil: è¾“å…¥tensorä¸ºNone")
        return None
    if isinstance(tensor, list):
        return [tensor2pil(img) for img in tensor]

    try:
        # ç¡®ä¿tensoræ˜¯4ç»´çš„
        if len(tensor.shape) == 3:
            tensor = tensor.unsqueeze(0)

        # å¦‚æœæ˜¯batchï¼Œå¤„ç†å¤šå›¾æƒ…å†µï¼ˆè¿™é‡Œåªå¤„ç†å•å›¾è½¬æ¢ï¼Œå¤šå›¾æ‹¼æ¥åœ¨image_to_base64ä¸­å¤„ç†ï¼‰
        if len(tensor.shape) == 4 and tensor.shape[0] > 1:
            # å¯¹äºtensor2pilå‡½æ•°ï¼Œæˆ‘ä»¬åªè½¬æ¢ç¬¬ä¸€å¼ å›¾åƒ
            # å¤šå›¾æ‹¼æ¥é€»è¾‘åœ¨image_to_base64å‡½æ•°ä¸­å¤„ç†
            tensor = tensor[0:1]

        # ç°åœ¨åº”è¯¥æ˜¯ [1, H, W, C] æ ¼å¼ï¼Œå»æ‰batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor.squeeze(0)  # å˜æˆ [H, W, C]

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢é€šé“é¡ºåº
        if len(tensor.shape) == 3:
            # å¦‚æœæœ€åä¸€ä¸ªç»´åº¦ä¸æ˜¯3ï¼ˆRGBé€šé“ï¼‰ï¼Œå¯èƒ½æ˜¯[C, H, W]æ ¼å¼
            if tensor.shape[-1] != 3 and tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)  # [C, H, W] -> [H, W, C]

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if hasattr(tensor, 'cpu'):
            # PyTorch tensor
            np_image = tensor.cpu().numpy()
        else:
            # å·²ç»æ˜¯numpyæ•°ç»„
            np_image = tensor

        # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´æ­£ç¡®
        if np_image.dtype != np.uint8:
            if np_image.max() <= 1.0:
                np_image = (np_image * 255).astype(np.uint8)
            else:
                np_image = np.clip(np_image, 0, 255).astype(np.uint8)

        # å¦‚æœæ˜¯ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸ºRGB
        if len(np_image.shape) == 2:
            np_image = np.stack([np_image] * 3, axis=-1)
        elif np_image.shape[-1] == 1:
            np_image = np.repeat(np_image, 3, axis=-1)

        pil_image = Image.fromarray(np_image)

        return pil_image

    except Exception as e:
        _log_error(f"âŒ tensor2pilè½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def pil2tensor(image):
    """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    if image is None:
        return None
    if isinstance(image, list):
        if len(image) == 0:
            return torch.empty(0)
        return torch.cat([pil2tensor(img) for img in image], dim=0)
    
    # è½¬æ¢ä¸ºRGB
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    elif image.mode != 'RGB':
        image = image.convert('RGB')
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–åˆ°[0, 1]
    img_array = np.array(image).astype(np.float32) / 255.0
    
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(img_array)[None,]

def create_blank_tensor(width=1024, height=1024):
    """åˆ›å»ºæ­£ç¡®æ ¼å¼çš„ç©ºç™½tensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    blank_image = Image.new('RGB', (width, height), color='white')
    np_image = np.array(blank_image).astype(np.float32) / 255.0
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(np_image)[None,]

def ensure_tensor_format(tensor):
    """ç¡®ä¿tensoræ ¼å¼å®Œå…¨ç¬¦åˆComfyUIè¦æ±‚ - æ ¼å¼ä¸º[1, H, W, 3]"""
    if tensor is None:
        return create_blank_tensor()
    
    original_shape = tensor.shape
    _log_info(f"ğŸ” è¾“å…¥tensorå½¢çŠ¶: {original_shape}")
    
    # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœtensorå½¢çŠ¶æ˜¯ (1, 1, 2048) æˆ–ç±»ä¼¼æ ¼å¼
    if len(tensor.shape) == 3 and tensor.shape[1] == 1 and tensor.shape[2] > 1000:
        _log_warning(f"âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸tensorå½¢çŠ¶: {tensor.shape}ï¼Œå¯èƒ½æ˜¯1Dæ•°æ®è¢«é”™è¯¯reshape")
        return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯4ç»´tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3]
    if len(tensor.shape) != 4:
        if len(tensor.shape) == 3:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ (H, W, 3) æ ¼å¼
            if tensor.shape[-1] == 3:
                tensor = tensor.unsqueeze(0)
                _log_info(f"ğŸ”§ æ·»åŠ batchç»´åº¦: {tensor.shape}")
            else:
                _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
                return create_blank_tensor()
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯ (batch, height, width, channels) æ ¼å¼
    if tensor.shape[-1] != 3:
        if tensor.shape[1] == 3:  # å¦‚æœæ˜¯ (batch, channels, height, width) æ ¼å¼
            tensor = tensor.permute(0, 2, 3, 1)
            _log_info(f"ğŸ”§ é‡æ–°æ’åˆ—tensorç»´åº¦: {tensor.shape}")
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensoré€šé“ç»´åº¦: {tensor.shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    if tensor.dtype != torch.float32:
        tensor = tensor.float()
        _log_info(f"ğŸ”§ è½¬æ¢tensoræ•°æ®ç±»å‹: {tensor.dtype}")
    
    # ç¡®ä¿å€¼èŒƒå›´æ­£ç¡® (0-1)
    if tensor.min() < 0 or tensor.max() > 1:
        tensor = torch.clamp(tensor, 0, 1)
        _log_info(f"ğŸ”§ é™åˆ¶tensorå€¼èŒƒå›´: {tensor.min().item():.3f} åˆ° {tensor.max().item():.3f}")
    
    # ç¡®ä¿æ²¡æœ‰å¼‚å¸¸å€¼
    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
        _log_error("âŒ tensoråŒ…å«å¼‚å¸¸å€¼ï¼Œä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
        return create_blank_tensor()
    
    # æœ€ç»ˆéªŒè¯ - ç¡®ä¿æ˜¯[1, H, W, 3]æ ¼å¼
    if len(tensor.shape) != 4 or tensor.shape[-1] != 3:
        _log_error(f"âŒ æœ€ç»ˆtensoræ ¼å¼ä»ç„¶ä¸æ­£ç¡®: {tensor.shape}")
        return create_blank_tensor()
    
    _log_info(f"âœ… tensoræ ¼å¼éªŒè¯é€šè¿‡: {tensor.shape}")
    return tensor

def image_to_base64(image_tensor, max_size=2048, return_data_url=True):
    """å°†tensorè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²ï¼Œæ”¯æŒè‡ªåŠ¨å‹ç¼©å’Œå¤šå›¾æ‹¼æ¥

    Args:
        image_tensor: è¾“å…¥çš„å›¾åƒtensor
        max_size: æœ€å¤§å°ºå¯¸é™åˆ¶
        return_data_url: æ˜¯å¦è¿”å›å®Œæ•´çš„data URLæ ¼å¼ï¼ŒFalseåˆ™åªè¿”å›base64å­—ç¬¦ä¸²
    """
    if image_tensor is None:
        return None

    # å¦‚æœæ˜¯batchï¼Œå°†å¤šå¼ å›¾åƒæ°´å¹³æ‹¼æ¥æˆä¸€å¼ å¤§å›¾
    if len(image_tensor.shape) == 4 and image_tensor.shape[0] > 1:
        _log_info(f"ğŸ” æ£€æµ‹åˆ°å¤šå›¾batchè¾“å…¥ {image_tensor.shape}ï¼Œå°†æ‹¼æ¥æˆä¸€å¼ å¤§å›¾")

        # å°†æ¯å¼ å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_images = []
        for i in range(image_tensor.shape[0]):
            single_tensor = image_tensor[i:i+1]  # ä¿æŒ4Dæ ¼å¼
            pil_img = tensor2pil(single_tensor)
            if pil_img is not None:
                pil_images.append(pil_img)

        if not pil_images:
            return None

        # æ°´å¹³æ‹¼æ¥å›¾åƒ
        total_width = sum(img.width for img in pil_images)
        max_height = max(img.height for img in pil_images)

        # åˆ›å»ºæ‹¼æ¥åçš„å¤§å›¾
        combined_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))
        x_offset = 0
        for img in pil_images:
            combined_image.paste(img, (x_offset, 0))
            x_offset += img.width

        pil_image = combined_image
        _log_info(f"ğŸ”§ å¤šå›¾æ‹¼æ¥å®Œæˆ: {len(pil_images)}å¼ å›¾ -> {pil_image.size}")
    else:
        pil_image = tensor2pil(image_tensor)
        if pil_image is None:
            return None

    # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼Œå¦‚æœè¿‡å¤§åˆ™å‹ç¼©
    original_size = pil_image.size
    if max(original_size) > max_size:
        # è®¡ç®—æ–°å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
        ratio = max_size / max(original_size)
        new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))
        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
        _log_info(f"ğŸ”§ å›¾åƒå‹ç¼©: {original_size} -> {new_size}")

    buffered = io.BytesIO()
    # ä½¿ç”¨JPEGæ ¼å¼å‹ç¼©å¤§å›¾åƒï¼ŒPNGæ ¼å¼ä¿ç•™å°å›¾åƒ
    if max(pil_image.size) > 1024:
        # å¯¹äºå›¾åƒç¼–è¾‘ï¼Œä½¿ç”¨æ›´é«˜è´¨é‡çš„JPEG
        quality = 90 if max(original_size) > max_size else 85
        pil_image.save(buffered, format="JPEG", quality=quality, optimize=True)
        format_prefix = "data:image/jpeg;base64,"
    else:
        pil_image.save(buffered, format="PNG", optimize=True)
        format_prefix = "data:image/png;base64,"

    image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

    # éªŒè¯base64å­—ç¬¦ä¸²çš„æœ‰æ•ˆæ€§
    try:
        # å°è¯•è§£ç éªŒè¯
        base64.b64decode(image_base64)
    except Exception as e:
        _log_warning(f"âš ï¸ Base64ç¼–ç éªŒè¯å¤±è´¥: {e}")
        return None

    if return_data_url:
        return f"{format_prefix}{image_base64}"
    else:
        return image_base64

def download_video_from_url(video_url: str, output_dir: str = None) -> str:
    """ä»URLä¸‹è½½è§†é¢‘æ–‡ä»¶"""
    try:
        if not video_url or not video_url.strip():
            raise ValueError("è§†é¢‘URLä¸ºç©º")

        # è§£æURLè·å–æ–‡ä»¶å
        parsed_url = urlparse(video_url)
        filename = os.path.basename(parsed_url.path)
        if not filename or '.' not in filename:
            filename = f"video_{int(time.time())}.mp4"

        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir is None:
            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except:
                output_dir = tempfile.gettempdir()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # å®Œæ•´çš„è¾“å‡ºè·¯å¾„
        output_path = os.path.join(output_dir, filename)

        _log_info(f"ğŸ”½ å¼€å§‹ä¸‹è½½è§†é¢‘: {video_url}")
        _log_info(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")

        # ä¸‹è½½è§†é¢‘
        response = requests.get(video_url, stream=True, timeout=300)
        response.raise_for_status()

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        file_size = os.path.getsize(output_path)
        _log_info(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {filename} ({file_size / 1024 / 1024:.2f} MB)")

        return output_path

    except Exception as e:
        _log_error(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
        return None

def video_to_comfyui_video(video_path: str):
    """å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†VideoFromFile"""
    try:
        if not video_path or not os.path.exists(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        _log_info(f"ğŸ¬ å¼€å§‹åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡: {video_path}")

        # ä½¿ç”¨ComfyUIå®˜æ–¹æ ‡å‡†ï¼šç›´æ¥ä»æ–‡ä»¶è·¯å¾„åˆ›å»ºVideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(video_path)

        _log_info("âœ… åˆ›å»ºComfyUIæ ‡å‡†VideoFromFileå¯¹è±¡æˆåŠŸ")

        # æµ‹è¯•get_dimensionsæ–¹æ³•
        try:
            dimensions = video_obj.get_dimensions()
            _log_info(f"ğŸ“Š è§†é¢‘å°ºå¯¸: {dimensions}")
        except Exception as e:
            _log_warning(f"âš ï¸ æ— æ³•è·å–è§†é¢‘å°ºå¯¸: {e}")

        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºVideoFromFileå¯¹è±¡å¤±è´¥: {e}")
        return None

def create_video_path_wrapper(file_path):
    """åˆ›å»ºä¸€ä¸ªè§†é¢‘è·¯å¾„åŒ…è£…å™¨ï¼Œç”¨äºUtilNodeså…¼å®¹æ€§"""
    # ç›´æ¥è¿”å›æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ï¼Œè®©UtilNodesçš„os.path.basename()èƒ½æ­£å¸¸å·¥ä½œ
    return file_path

def extract_video_last_frame(video_path, output_path=None):
    """
    æå–è§†é¢‘çš„æœ€åä¸€å¸§å›¾åƒ

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        str: è¾“å‡ºå›¾ç‰‡çš„è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        import subprocess
        import tempfile
        from pathlib import Path

        if not os.path.exists(video_path):
            _log_error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if output_path is None:
            video_name = Path(video_path).stem
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{video_name}_last_frame_{int(time.time())}.jpg")

        _log_info(f"ğŸ¬ æ­£åœ¨æå–è§†é¢‘å°¾å¸§: {video_path}")

        # æ–¹æ³•1ï¼šä½¿ç”¨FFmpegçš„select=eofè¿‡æ»¤å™¨
        cmd1 = [
            'ffmpeg',
            '-i', video_path,           # è¾“å…¥è§†é¢‘
            '-vf', 'select=eof',        # é€‰æ‹©æœ€åä¸€å¸§
            '-vsync', 'vfr',            # å¯å˜å¸§ç‡
            '-frames:v', '1',           # åªè¾“å‡º1å¸§
            '-y',                       # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]

        try:
            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {output_path}")
                return output_path
        except:
            pass

        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
        _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•æå–å°¾å¸§...")

        # è·å–è§†é¢‘æ—¶é•¿
        duration_cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-show_entries', 'format=duration',
            '-of', 'csv=p=0',
            video_path
        ]

        duration_result = subprocess.run(
            duration_cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        if duration_result.returncode == 0:
            try:
                duration = float(duration_result.stdout.strip())
                seek_time = max(0, duration - 0.1)  # æå–æœ€å0.1ç§’å‰çš„å¸§

                cmd2 = [
                    'ffmpeg',
                    '-ss', str(seek_time),
                    '-i', video_path,
                    '-frames:v', '1',
                    '-y',
                    output_path
                ]

                result = subprocess.run(
                    cmd2,
                    capture_output=True,
                    text=True,
                    timeout=60
                )

                if result.returncode == 0 and os.path.exists(output_path):
                    _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ (å¤‡ç”¨æ–¹æ³•): {output_path}")
                    return output_path
            except:
                pass

        _log_error("âŒ æ‰€æœ‰å°¾å¸§æå–æ–¹æ³•éƒ½å¤±è´¥äº†")
        return None

    except Exception as e:
        _log_error(f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}")
        return None

def merge_videos_with_ffmpeg(video_paths, output_path=None):
    """ä½¿ç”¨ffmpegåˆå¹¶å¤šä¸ªè§†é¢‘æ–‡ä»¶"""
    try:
        import subprocess
        import tempfile

        if not video_paths or len(video_paths) < 2:
            _log_warning("âš ï¸ è§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return video_paths[0] if video_paths else None

        # éªŒè¯æ‰€æœ‰è§†é¢‘æ–‡ä»¶å­˜åœ¨
        valid_paths = []
        for path in video_paths:
            if path and os.path.exists(path):
                valid_paths.append(path)
            else:
                _log_warning(f"âš ï¸ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")

        if len(valid_paths) < 2:
            _log_warning("âš ï¸ æœ‰æ•ˆè§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return valid_paths[0] if valid_paths else None

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•
        if not output_path:
            timestamp = int(time.time())
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except ImportError:
                # æ¨æ–­ComfyUIè¾“å‡ºç›®å½•
                current_dir = os.path.dirname(os.path.abspath(__file__))
                path_parts = current_dir.split(os.sep)
                comfyui_root = None

                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
            except:
                import tempfile
                output_dir = tempfile.gettempdir()
            output_path = os.path.join(output_dir, f"merged_continuous_video_{timestamp}.mp4")

        _log_info(f"ğŸ¬ å¼€å§‹åˆå¹¶{len(valid_paths)}ä¸ªè§†é¢‘æ–‡ä»¶...")
        _log_info(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")

        # åˆ›å»ºffmpegè¾“å…¥æ–‡ä»¶åˆ—è¡¨
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            for path in valid_paths:
                # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                abs_path = os.path.abspath(path).replace('\\', '/')
                f.write(f"file '{abs_path}'\n")
            input_list_path = f.name

        try:
            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', input_list_path,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç 
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œffmpegå‘½ä»¤: {' '.join(cmd)}")

            # æ‰§è¡Œffmpegå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    _log_info(f"âœ… è§†é¢‘åˆå¹¶æˆåŠŸ: {output_path} (å¤§å°: {file_size} bytes)")
                    return output_path
                else:
                    _log_error("âŒ ffmpegæ‰§è¡ŒæˆåŠŸä½†è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    return None
            else:
                _log_error(f"âŒ ffmpegæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return None

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(input_list_path)
            except:
                pass

    except subprocess.TimeoutExpired:
        _log_error("âŒ ffmpegæ‰§è¡Œè¶…æ—¶")
        return None
    except FileNotFoundError:
        _log_error("âŒ æœªæ‰¾åˆ°ffmpegï¼Œè¯·ç¡®ä¿å·²å®‰è£…ffmpegå¹¶æ·»åŠ åˆ°PATH")
        return None
    except Exception as e:
        _log_error(f"âŒ è§†é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return None

def get_resolution_dimensions(resolution, aspect_ratio):
    """æ ¹æ®åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”è·å–å®é™…åƒç´ å°ºå¯¸

    Args:
        resolution: "480p", "720p", "1080p"
        aspect_ratio: "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"

    Returns:
        tuple: (width, height) æˆ– None
    """
    # Seedance 1.0 pro æ”¯æŒçš„åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”å¯¹åº”è¡¨
    resolution_map = {
        "480p": {
            "16:9": (864, 480),
            "4:3": (736, 544),
            "1:1": (640, 640),
            "3:4": (544, 736),
            "9:16": (480, 864),
            "21:9": (960, 416)
        },
        "720p": {
            "16:9": (1248, 704),
            "4:3": (1120, 832),
            "1:1": (960, 960),
            "3:4": (832, 1120),
            "9:16": (704, 1248),
            "21:9": (1504, 640)
        },
        "1080p": {
            "16:9": (1920, 1088),
            "4:3": (1664, 1248),
            "1:1": (1440, 1440),
            "3:4": (1248, 1664),
            "9:16": (1088, 1920),
            "21:9": (2176, 928)
        }
    }

    if resolution in resolution_map and aspect_ratio in resolution_map[resolution]:
        dimensions = resolution_map[resolution][aspect_ratio]
        _log_info(f"ğŸ” åˆ†è¾¨ç‡è®¡ç®—: {resolution} + {aspect_ratio} = {dimensions[0]}x{dimensions[1]}")
        return dimensions
    else:
        _log_warning(f"âš ï¸ ä¸æ”¯æŒçš„åˆ†è¾¨ç‡æˆ–å®½é«˜æ¯”ç»„åˆ: {resolution} + {aspect_ratio}")
        # è¿”å›é»˜è®¤å€¼
        default_dimensions = (1248, 704)  # 720p 16:9
        _log_info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {default_dimensions[0]}x{default_dimensions[1]}")
        return default_dimensions

def create_blank_video_object(frames=30, height=512, width=512):
    """åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡ - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åˆ›å»ºVideoFromFile"""
    try:
        _log_info(f"ğŸ¬ åˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶: {frames}å¸§, {width}x{height}")

        # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶
        temp_video_path = os.path.join(tempfile.gettempdir(), f"blank_video_{int(time.time())}.mp4")

        # ä½¿ç”¨OpenCVåˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶
        if HAS_CV2:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_video_path, fourcc, 30.0, (width, height))

            # åˆ›å»ºé»‘è‰²å¸§
            blank_frame = np.zeros((height, width, 3), dtype=np.uint8)

            for _ in range(frames):
                out.write(blank_frame)

            out.release()
            _log_info(f"âœ… ç©ºç™½è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {temp_video_path}")
        else:
            # å¦‚æœæ²¡æœ‰OpenCVï¼Œåˆ›å»ºä¸€ä¸ªæœ€å°çš„MP4æ–‡ä»¶
            _log_warning("âš ï¸ æ²¡æœ‰OpenCVï¼Œåˆ›å»ºç®€å•çš„ç©ºç™½è§†é¢‘å¯¹è±¡")
            # è¿™é‡Œæˆ‘ä»¬ä»ç„¶éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
            # ä½œä¸ºå›é€€ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè·¯å¾„
            temp_video_path = "blank_video.mp4"

        # åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(temp_video_path)
        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡å¤±è´¥: {e}")
        # æœ€åçš„å›é€€ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„VideoFromFileå¯¹è±¡
        return VideoFromFile("blank_video.mp4")

def call_comfly_api(api_url, api_key, payload, timeout=900):
    """è°ƒç”¨Comfly API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    # è°ƒè¯•ä¿¡æ¯
    _log_info(f"ğŸ” Comfly APIè°ƒç”¨:")
    _log_info(f"   - ç«¯ç‚¹: {api_url}/images/generations")
    _log_info(f"   - æ¨¡å‹: {payload.get('model', 'N/A')}")
    _log_info(f"   - åŒ…å«å›¾åƒ: {'image' in payload and bool(payload.get('image'))}")
    if 'image' in payload and payload.get('image'):
        _log_info(f"   - å›¾åƒæ•°é‡: {len(payload['image'])}")
        _log_info(f"   - ç¬¬ä¸€å¼ å›¾åƒé•¿åº¦: {len(payload['image'][0]) if payload['image'] else 0}")

    try:
        # ä½¿ç”¨SSLå…¼å®¹çš„session
        session = create_ssl_compatible_session()
        response = session.post(
            f"{api_url}/images/generations",
            headers=headers,
            json=payload,
            timeout=timeout
        )
        return response
    except Exception as e:
        _log_error(f"Comfly APIè°ƒç”¨å¤±è´¥: {e}")
        return None

def call_openai_compatible_api(api_url, api_key, payload, timeout=900):
    """è°ƒç”¨OpenAIå…¼å®¹API - æ”¯æŒT8å›¾åƒç¼–è¾‘"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯T8é•œåƒç«™
        if "t8star.cn" in api_url or "ai.t8star.cn" in api_url:
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒè¾“å…¥
            has_images = "image" in payload and payload["image"]

            # å¯¹äºT8ï¼Œå›¾ç”Ÿå›¾ä¹Ÿä½¿ç”¨images/generationsç«¯ç‚¹ï¼Œè€Œä¸æ˜¯chat/completions
            # åªæœ‰ç‰¹å®šçš„å›¾åƒç¼–è¾‘ä»»åŠ¡æ‰ä½¿ç”¨chat/completions
            use_chat_endpoint = False  # æš‚æ—¶ç¦ç”¨chatç«¯ç‚¹ï¼Œç»Ÿä¸€ä½¿ç”¨images/generations

            if has_images and use_chat_endpoint:
                # å›¾åƒç¼–è¾‘ï¼šä½¿ç”¨chat/completionsç«¯ç‚¹ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
                url = "https://ai.t8star.cn/v1/chat/completions"
                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘ç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç¼–è¾‘çš„payloadæ ¼å¼
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": payload.get("prompt", "")
                            }
                        ]
                    }
                ]

                # æ·»åŠ å›¾åƒåˆ°æ¶ˆæ¯ä¸­
                image_urls = payload.get("image", [])
                if isinstance(image_urls, str):
                    image_urls = [image_urls]

                for image_url in image_urls:
                    messages[0]["content"].append({
                        "type": "image_url",
                        "image_url": {
                            "url": image_url
                        }
                    })

                t8_payload = {
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "messages": messages,
                    "max_tokens": 4096,
                    "temperature": 0.7
                }

                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘è¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æ¶ˆæ¯æ•°={len(t8_payload.get('messages', []))}")

            else:
                # å›¾åƒç”Ÿæˆï¼šä½¿ç”¨images/generationsç«¯ç‚¹
                url = "https://ai.t8star.cn/v1/images/generations"
                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç”Ÿæˆçš„payloadæ ¼å¼
                t8_payload = {
                    "prompt": payload.get("prompt", ""),
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "response_format": payload.get("response_format", "url")
                }

                # æ·»åŠ å¯é€‰å‚æ•°
                if "size" in payload:
                    t8_payload["size"] = payload["size"]
                if "n" in payload:
                    t8_payload["n"] = payload["n"]
                if "seed" in payload and payload["seed"] != -1:
                    t8_payload["seed"] = payload["seed"]
                if "watermark" in payload:
                    t8_payload["watermark"] = payload["watermark"]
                if "tail_on_partial" in payload:
                    t8_payload["tail_on_partial"] = payload["tail_on_partial"]

                # æ·»åŠ å›¾åƒè¾“å…¥æ”¯æŒï¼ˆå›¾ç”Ÿå›¾ï¼‰
                if has_images:
                    t8_payload["image"] = payload["image"]
                    _log_info(f"ğŸ–¼ï¸ T8å›¾ç”Ÿå›¾è¯·æ±‚: åŒ…å« {len(payload['image'])} å¼ è¾“å…¥å›¾åƒ")
                    _log_info(f"ğŸ” å›¾åƒæ•°æ®ç±»å‹: {type(payload['image'])}")
                    if payload['image']:
                        _log_info(f"ğŸ” ç¬¬ä¸€å¼ å›¾åƒæ•°æ®é•¿åº¦: {len(payload['image'][0]) if payload['image'][0] else 0} å­—ç¬¦")

                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆè¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æç¤ºè¯é•¿åº¦={len(t8_payload.get('prompt', ''))}")

        elif api_url.endswith('/v1/chat/completions'):
            url = api_url.replace('/v1/chat/completions', '/v1/images/generations')
            _log_info(f"ğŸ”— è½¬æ¢èŠå¤©ç«¯ç‚¹ä¸ºå›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")
            t8_payload = payload
        else:
            # å…¶ä»–OpenAIå…¼å®¹API
            url = f"{api_url}/v1/images/generations"
            _log_info(f"ğŸ”— ä½¿ç”¨æ ‡å‡†OpenAIç«¯ç‚¹: {url}")
            t8_payload = payload

        # å°è¯•å¤šç§è¿æ¥æ–¹å¼è§£å†³SSLé—®é¢˜
        response = None
        last_error = None

        # æ–¹æ³•1ï¼šç¦ç”¨æ‰€æœ‰SSLéªŒè¯çš„ç®€å•æ–¹å¼
        try:
            import urllib3
            urllib3.disable_warnings()

            # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨SSLéªŒè¯
            import os
            os.environ['PYTHONHTTPSVERIFY'] = '0'
            os.environ['CURL_CA_BUNDLE'] = ''

            response = requests.post(
                url,
                headers=headers,
                json=t8_payload,
                timeout=timeout,
                verify=False,
                stream=False
            )
            _log_info(f"âœ… ç®€å•SSLç¦ç”¨æ–¹å¼æˆåŠŸ")

        except Exception as simple_error:
            last_error = simple_error
            _log_warning(f"ç®€å•SSLç¦ç”¨å¤±è´¥: {simple_error}")

            # æ–¹æ³•2ï¼šä½¿ç”¨SSLå…¼å®¹çš„session
            try:
                session = create_ssl_compatible_session()
                response = session.post(
                    url,
                    headers=headers,
                    json=t8_payload,
                    timeout=timeout
                )
                _log_info(f"âœ… SSLå…¼å®¹sessionæˆåŠŸ")

            except Exception as ssl_error:
                last_error = ssl_error
                _log_warning(f"SSLå…¼å®¹sessionå¤±è´¥: {ssl_error}")

                # æ–¹æ³•3ï¼šä½¿ç”¨curlä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                try:
                    import subprocess
                    import tempfile

                    # å°†payloadå†™å…¥ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                        json.dump(t8_payload, f)
                        temp_file = f.name

                    # æ„å»ºcurlå‘½ä»¤
                    curl_cmd = [
                        'curl', '-k', '-X', 'POST',
                        '-H', 'Content-Type: application/json',
                        '-H', f'Authorization: Bearer {headers["Authorization"].split(" ")[1]}',
                        '-d', f'@{temp_file}',
                        '--connect-timeout', '30',
                        '--max-time', str(timeout),
                        url
                    ]

                    result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=timeout)

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(temp_file)

                    if result.returncode == 0:
                        # åˆ›å»ºæ¨¡æ‹Ÿresponseå¯¹è±¡
                        class MockResponse:
                            def __init__(self, text, status_code=200):
                                self.text = text
                                self.status_code = status_code
                            def json(self):
                                return json.loads(self.text)

                        response = MockResponse(result.stdout)
                        _log_info(f"âœ… curlå¤‡ç”¨æ–¹æ¡ˆæˆåŠŸ")
                    else:
                        raise Exception(f"curlå¤±è´¥: {result.stderr}")

                except Exception as curl_error:
                    _log_warning(f"curlå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {curl_error}")
                    raise last_error  # æŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯

        _log_info(f"ğŸ” T8 APIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ T8 APIé”™è¯¯: {response.status_code} - {response.text}")

        return response

    except Exception as e:
        _log_error(f"OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥: {e}")
        return None

def call_api4gpt_api(api_url, api_key, payload, timeout=900):
    """è°ƒç”¨API4GPT API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    try:
        response = requests.post(
            f"{api_url}/v1/images/generations",
            headers=headers,
            json=payload,
            timeout=timeout,
            verify=False
        )
        return response
    except Exception as e:
        _log_error(f"API4GPT APIè°ƒç”¨å¤±è´¥: {e}")
        return None

def call_openrouter_api(api_url, api_key, payload, timeout=900):
    """è°ƒç”¨OpenRouter API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    try:
        response = requests.post(
            f"{api_url}/images/generations",
            headers=headers,
            json=payload,
            timeout=timeout,
            verify=False
        )
        return response
    except Exception as e:
        _log_error(f"OpenRouter APIè°ƒç”¨å¤±è´¥: {e}")
        return None


def call_volcengine_api(api_url, api_key, payload, timeout=900):
    """è°ƒç”¨ç«å±±å¼•æ“API"""
    try:
        # ç«å±±å¼•æ“APIä½¿ç”¨ç‰¹å®šçš„è®¤è¯æ–¹å¼
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-SeedReam4API/1.0"
        }
        
        # ç«å±±å¼•æ“çš„å›¾åƒç”ŸæˆAPIç«¯ç‚¹
        endpoint = f"{api_url}/images/generations"
        
        # æ„å»ºç«å±±å¼•æ“ç‰¹å®šçš„è¯·æ±‚è½½è·
        volcengine_payload = {
            "model": payload.get("model", "doubao-seedream-4-0-250828"),
            "prompt": payload.get("prompt", ""),
            "size": payload.get("size", "1024x1024"),
            "n": payload.get("n", 1),
            "response_format": payload.get("response_format", "url"),
            "quality": "hd",  # ç«å±±å¼•æ“æ”¯æŒhdè´¨é‡
            "style": "vivid"  # ç«å±±å¼•æ“æ”¯æŒvividé£æ ¼
        }
        
        # æ·»åŠ å¯é€‰å‚æ•°
        if "seed" in payload and payload["seed"] != -1:
            volcengine_payload["seed"] = payload["seed"]
        
        if "watermark" in payload:
            volcengine_payload["watermark"] = payload["watermark"]

        if "tail_on_partial" in payload:
            volcengine_payload["tail_on_partial"] = payload["tail_on_partial"]
        
        # å¤„ç†å›¾åƒè¾“å…¥ï¼ˆç”¨äºå›¾åƒç¼–è¾‘ï¼‰
        if "image" in payload and payload["image"]:
            volcengine_payload["image"] = payload["image"]
            _log_info(f"ğŸ” ç«å±±å¼•æ“å›¾åƒè¾“å…¥: æ•°é‡={len(payload['image'])}, ç¬¬ä¸€å¼ é•¿åº¦={len(payload['image'][0]) if payload['image'] else 0}")

        _log_info(f"ğŸ”— è°ƒç”¨ç«å±±å¼•æ“API: {endpoint}")
        _log_info(f"ğŸ” ç«å±±å¼•æ“è¯·æ±‚: æ¨¡å‹={volcengine_payload.get('model')}, æç¤ºè¯é•¿åº¦={len(volcengine_payload.get('prompt', ''))}")
        _log_info(f"ğŸ” ç«å±±å¼•æ“payloadåŒ…å«å›¾åƒ: {'image' in volcengine_payload}")
        
        response = requests.post(
            endpoint,
            headers=headers,
            json=volcengine_payload,
            timeout=timeout,
            verify=False
        )
        
        _log_info(f"ğŸ” ç«å±±å¼•æ“APIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ ç«å±±å¼•æ“APIé”™è¯¯: {response.text}")
        
        return response
    except Exception as e:
        _log_error(f"ç«å±±å¼•æ“APIè°ƒç”¨å¼‚å¸¸: {e}")
        return None

def call_video_api(api_url, api_key, payload, api_format="comfly", timeout=900):
    """è°ƒç”¨è§†é¢‘ç”ŸæˆAPI"""
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-SeedanceAPI/1.0"
        }

        # æ ¹æ®APIæ ¼å¼ç¡®å®šç«¯ç‚¹ - ä½¿ç”¨å„é•œåƒç«™çš„å®é™…ç«¯ç‚¹
        if api_format == "comfly":
            # Comflyçš„è§†é¢‘ç«¯ç‚¹ï¼Œä½¿ç”¨v2/videos/generations
            if api_url.endswith('/v1'):
                endpoint = f"{api_url[:-3]}/v2/videos/generations"  # ä½¿ç”¨ /v2/videos/generations
            else:
                endpoint = f"{api_url}/v2/videos/generations"
        elif api_format == "openai":
            # T8é•œåƒç«™ä½¿ç”¨v2ç«¯ç‚¹
            if "t8star.cn" in api_url:
                # T8çš„è§†é¢‘ç«¯ç‚¹ï¼Œå¤„ç†URLç‰ˆæœ¬å·
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations"  # æ›¿æ¢v1ä¸ºv2
                else:
                    endpoint = f"{api_url}/v2/videos/generations"
            else:
                endpoint = f"{api_url}/v1/videos/generations"

        elif api_format == "volcengine":
            # ç«å±±å¼•æ“å®˜æ–¹APIã€T8é•œåƒç«™å’ŒComflyé•œåƒç«™
            if "t8star.cn" in api_url:
                # T8é•œåƒç«™ä½¿ç”¨ç‰¹æ®Šçš„ç«¯ç‚¹è·¯å¾„
                endpoint = f"{api_url}/seedance/v3/contents/generations/tasks"
            elif "comfly.chat" in api_url:
                # Comflyé•œåƒç«™ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹
                endpoint = f"{api_url.replace('/v1', '').replace('/v2', '')}/seedance/v3/contents/generations/tasks"
            else:
                # ç«å±±å¼•æ“å®˜æ–¹API
                endpoint = f"{api_url}/contents/generations/tasks"
        else:
            # é»˜è®¤å¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯T8æˆ–Comfly
            if "t8star.cn" in api_url:
                # T8ä½¿ç”¨v2ç«¯ç‚¹
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations"
                else:
                    endpoint = f"{api_url}/v2/videos/generations"
            else:
                # é»˜è®¤ä½¿ç”¨Comflyæ ¼å¼
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations"
                else:
                    endpoint = f"{api_url}/v2/videos/generations"

        _log_info(f"ğŸ¬ è°ƒç”¨è§†é¢‘ç”ŸæˆAPI: {endpoint}")
        _log_info(f"ğŸ” è§†é¢‘APIæ ¼å¼: {api_format}")

        # æ ¹æ®ä¸åŒæ ¼å¼æå–æç¤ºè¯é•¿åº¦
        prompt_length = 0
        if "prompt" in payload:
            prompt_length = len(payload.get('prompt', ''))
        elif "content" in payload:
            # ç«å±±å¼•æ“æ ¼å¼ï¼šä»contentæ•°ç»„ä¸­æå–text
            for item in payload.get('content', []):
                if item.get('type') == 'text':
                    prompt_length = len(item.get('text', ''))
                    break

        _log_info(f"ğŸ” è§†é¢‘è¯·æ±‚: æ¨¡å‹={payload.get('model')}, æç¤ºè¯é•¿åº¦={prompt_length}")

        if "image" in payload and payload["image"]:
            _log_info(f"ğŸ” è§†é¢‘è¾“å…¥å›¾åƒ: æ•°é‡={len(payload['image'])}")
        elif "first_frame" in payload and "last_frame" in payload:
            _log_info(f"ğŸ” è§†é¢‘é¦–å°¾å¸§æ¨¡å¼")
        elif "content" in payload:
            _log_info(f"ğŸ” è§†é¢‘contentæ¨¡å¼: å†…å®¹æ•°é‡={len(payload['content'])}")

        # è°ƒè¯•ï¼šæ‰“å°å®é™…å‘é€çš„payloadç»“æ„
        _log_info(f"ğŸ” å®é™…å‘é€çš„payloadé”®: {list(payload.keys())}")
        if "content" in payload:
            _log_info(f"ğŸ” contentæ•°ç»„é•¿åº¦: {len(payload['content'])}")
            for i, item in enumerate(payload['content']):
                _log_info(f"ğŸ” content[{i}]: type={item.get('type')}, role={item.get('role', 'N/A')}")

        # è°ƒè¯•ï¼šæµ‹è¯•JSONåºåˆ—åŒ–
        try:
            import json
            json_str = json.dumps(payload, ensure_ascii=False)
            _log_info(f"ğŸ” JSONåºåˆ—åŒ–æˆåŠŸï¼Œé•¿åº¦: {len(json_str)}")
            # é‡æ–°è§£æéªŒè¯
            parsed_payload = json.loads(json_str)
            _log_info(f"ğŸ” JSONè§£æåçš„é”®: {list(parsed_payload.keys())}")
            if "content" in parsed_payload:
                _log_info(f"ğŸ” è§£æåcontentæ•°ç»„é•¿åº¦: {len(parsed_payload['content'])}")
        except Exception as json_e:
            _log_error(f"âŒ JSONåºåˆ—åŒ–å¤±è´¥: {json_e}")

        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            timeout=timeout,
            verify=False
        )

        _log_info(f"ğŸ” è§†é¢‘APIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ è§†é¢‘APIé”™è¯¯: {response.text}")

        return response

    except Exception as e:
        _log_error(f"è§†é¢‘ç”ŸæˆAPIè°ƒç”¨å¤±è´¥: {e}")
        return None

def call_multi_ref_video_api(api_url, api_key, payload, api_format="comfly", timeout=900):
    """è°ƒç”¨å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPI - ç»Ÿä¸€ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹"""
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-SeedanceAPI/1.0"
        }

        # å¤šå›¾å‚è€ƒåŠŸèƒ½ç»Ÿä¸€ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼çš„ç«¯ç‚¹
        if api_format == "volcengine":
            # ç«å±±å¼•æ“å®˜æ–¹API
            endpoint = f"{api_url}/contents/generations/tasks"
        elif api_format == "comfly":
            # Comflyé•œåƒç«™ä½¿ç”¨ç«å±±å¼•æ“å®˜æ–¹æ ¼å¼ç«¯ç‚¹
            if "comfly.chat" in api_url:
                # Comflyçš„ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹
                endpoint = f"{api_url.replace('/v1', '').replace('/v2', '')}/seedance/v3/contents/generations/tasks"
            else:
                endpoint = f"{api_url}/seedance/v3/contents/generations/tasks"
        else:
            # å…¶ä»–æ ¼å¼é»˜è®¤ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼
            endpoint = f"{api_url}/contents/generations/tasks"

        _log_info(f"ğŸ¬ è°ƒç”¨å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPI: {endpoint}")
        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒAPIæ ¼å¼: {api_format}")

        # æ ¹æ®ä¸åŒæ ¼å¼æå–æç¤ºè¯é•¿åº¦
        prompt_length = 0
        if "content" in payload:
            # ç«å±±å¼•æ“æ ¼å¼ï¼šä»contentæ•°ç»„ä¸­æå–text
            for item in payload.get('content', []):
                if item.get('type') == 'text':
                    prompt_length = len(item.get('text', ''))
                    break

        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒè¯·æ±‚: æ¨¡å‹={payload.get('model')}, æç¤ºè¯é•¿åº¦={prompt_length}")
        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒcontentæ¨¡å¼: å†…å®¹æ•°é‡={len(payload.get('content', []))}")

        # è°ƒè¯•ï¼šæ‰“å°å®é™…å‘é€çš„payloadç»“æ„
        _log_info(f"ğŸ” å®é™…å‘é€çš„payloadé”®: {list(payload.keys())}")
        if "content" in payload:
            _log_info(f"ğŸ” contentæ•°ç»„é•¿åº¦: {len(payload['content'])}")
            for i, item in enumerate(payload['content']):
                _log_info(f"ğŸ” content[{i}]: type={item.get('type')}, role={item.get('role', 'N/A')}")

        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            timeout=timeout,
            verify=False
        )

        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒAPIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ å¤šå›¾å‚è€ƒAPIé”™è¯¯: {response.text}")

        return response

    except Exception as e:
        _log_error(f"å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPIè°ƒç”¨å¤±è´¥: {e}")
        return None

def call_video_task_status(api_url, api_key, task_id, api_format="comfly", timeout=60):
    """æŸ¥è¯¢è§†é¢‘ç”Ÿæˆä»»åŠ¡çŠ¶æ€"""
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-SeedanceAPI/1.0"
        }

        # æ ¹æ®APIæ ¼å¼ç¡®å®šæŸ¥è¯¢ç«¯ç‚¹
        if api_format == "comfly":
            # Comflyçš„æŸ¥è¯¢ç«¯ç‚¹ï¼Œä½¿ç”¨v2/videos/generations
            if api_url.endswith('/v1'):
                endpoint = f"{api_url[:-3]}/v2/videos/generations/{task_id}"
            else:
                endpoint = f"{api_url}/v2/videos/generations/{task_id}"
        elif api_format == "openai":
            # T8é•œåƒç«™ä½¿ç”¨v2ç«¯ç‚¹
            if "t8star.cn" in api_url:
                # T8çš„æŸ¥è¯¢ç«¯ç‚¹ï¼Œå¤„ç†URLç‰ˆæœ¬å·
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations/{task_id}"  # æ›¿æ¢v1ä¸ºv2
                else:
                    endpoint = f"{api_url}/v2/videos/generations/{task_id}"
            else:
                endpoint = f"{api_url}/v1/videos/generations/{task_id}"

        elif api_format == "volcengine":
            # ç«å±±å¼•æ“å®˜æ–¹APIã€T8é•œåƒç«™å’ŒComflyé•œåƒç«™
            if "t8star.cn" in api_url:
                # T8é•œåƒç«™ä½¿ç”¨ç‰¹æ®Šçš„æŸ¥è¯¢ç«¯ç‚¹è·¯å¾„
                endpoint = f"{api_url}/seedance/v3/contents/generations/tasks/{task_id}"
            elif "comfly.chat" in api_url:
                # Comflyé•œåƒç«™ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼æŸ¥è¯¢ç«¯ç‚¹
                endpoint = f"{api_url.replace('/v1', '').replace('/v2', '')}/seedance/v3/contents/generations/tasks/{task_id}"
            else:
                # ç«å±±å¼•æ“å®˜æ–¹API
                endpoint = f"{api_url}/contents/generations/tasks/{task_id}"
        else:
            # é»˜è®¤å¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯T8æˆ–Comfly
            if "t8star.cn" in api_url:
                # T8ä½¿ç”¨v2ç«¯ç‚¹
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations/{task_id}"
                else:
                    endpoint = f"{api_url}/v2/videos/generations/{task_id}"
            else:
                # é»˜è®¤ä½¿ç”¨Comflyæ ¼å¼
                if api_url.endswith('/v1'):
                    endpoint = f"{api_url[:-3]}/v2/videos/generations/{task_id}"
                else:
                    endpoint = f"{api_url}/v2/videos/generations/{task_id}"

        _log_info(f"ğŸ” æŸ¥è¯¢è§†é¢‘ä»»åŠ¡çŠ¶æ€: {endpoint}")

        response = requests.get(
            endpoint,
            headers=headers,
            timeout=timeout,
            verify=False
        )

        return response

    except requests.exceptions.SSLError as e:
        _log_warning(f"SSLé”™è¯¯ï¼Œå°è¯•å¿½ç•¥SSLéªŒè¯: {e}")
        try:
            # å°è¯•ä½¿ç”¨æ›´å®½æ¾çš„SSLè®¾ç½®
            import urllib3
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            response = requests.get(
                endpoint,
                headers=headers,
                timeout=timeout,
                verify=False
            )
            return response
        except Exception as e2:
            _log_error(f"æŸ¥è¯¢è§†é¢‘ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼ˆSSLé‡è¯•åï¼‰: {e2}")
            return None
    except Exception as e:
        _log_error(f"æŸ¥è¯¢è§†é¢‘ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return None

class SeedReam4APINode:
    """SeedReam4API èŠ‚ç‚¹ç±»"""
    
    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())
        
        if not mirror_options:
            mirror_options = ["comfly", "t8_mirror"]
        
        # ä¿ç•™å‰ä¸‰ä¸ªé•œåƒç«™é€‰é¡¹ï¼ˆåŒ…æ‹¬ç«å±±å¼•æ“ï¼‰
        mirror_options = [opt for opt in mirror_options if opt in ["comfly", "t8_mirror", "volcengine"]]
        
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "A beautiful landscape"}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedream-4-0-250828"], {"default": "doubao-seedream-4-0-250828"}),
                "response_format": (["url", "b64_json"], {"default": "url"}),
                "resolution": (["1K", "2K", "4K"], {"default": "1K"}),
                "aspect_ratio": (["1:1", "4:3", "3:4", "16:9", "9:16", "2:3", "3:2", "21:9", "9:21", "Custom"], {"default": "1:1"}),
                "width": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 1}),
                "height": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 1}),
                "api_key": ("STRING", {"default": ""}),
                "max_images": ("INT", {"default": 1, "min": 1, "max": 15, "step": 1}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
                "watermark": ("BOOLEAN", {"default": True}),
                "stream": ("BOOLEAN", {"default": False}),
                "tail_on_partial": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "image1": ("IMAGE",),
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
                "image5": ("IMAGE",),
                "sequential_image_generation": (["disabled", "auto"], {"default": "disabled"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "response", "image_url")
    FUNCTION = "generate_image"
    CATEGORY = "Ken-Chen/Doubao"
    
    def __init__(self):
        self.config = get_seedream4_config()
        self.timeout = self.config.get('timeout', 900)
        self.max_retries = self.config.get('max_retries', 3)
        self.size_mapping = self.config.get('size_mapping', {})
        self.resolution_factors = self.config.get('resolution_factors', {})
    
    def get_headers(self, api_key):
        """è·å–è¯·æ±‚å¤´"""
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
    
    def generate_image(self, prompt, mirror_site, model, response_format="url", resolution="1K",
                      aspect_ratio="1:1", width=1024, height=1024, api_key="",
                      max_images=1, seed=-1, watermark=True, stream=False, tail_on_partial=True,
                      image1=None, image2=None, image3=None, image4=None, image5=None,
                      sequential_image_generation="disabled"):
        """ç”Ÿæˆå›¾åƒ"""
        
        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")
        
        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")
        
        if not api_key.strip():
            error_message = "API key not found"
            _log_error(error_message)
            blank_tensor = create_blank_tensor()
            return (blank_tensor, error_message, "")
        
        if not validate_api_url(api_url):
            error_message = "Invalid API URL"
            _log_error(error_message)
            blank_tensor = create_blank_tensor()
            return (blank_tensor, error_message, "")
        
        _log_info(f"ğŸ”— ä½¿ç”¨é•œåƒç«™: {mirror_site} ({api_url})")
        
        try:
            # è®¡ç®—æœ€ç»ˆå°ºå¯¸
            if aspect_ratio == "Custom":
                scale_factor = self.resolution_factors.get(resolution, 1)
                scaled_width = int(width * scale_factor)
                scaled_height = int(height * scale_factor)
                final_size = f"{scaled_width}x{scaled_height}"
                _log_info(f"ä½¿ç”¨è‡ªå®šä¹‰å°ºå¯¸: {final_size}")
            else:
                if resolution in self.size_mapping and aspect_ratio in self.size_mapping[resolution]:
                    final_size = self.size_mapping[resolution][aspect_ratio]
                else:
                    final_size = "1024x1024"
                    _log_warning(f"æœªæ‰¾åˆ° {resolution} å’Œ {aspect_ratio} çš„ç»„åˆï¼Œä½¿ç”¨ {final_size}")
            
            # æ„å»ºè¯·æ±‚è½½è·
            payload = {
                "model": model,
                "prompt": prompt,
                "response_format": response_format,
                "size": final_size,
                "watermark": watermark,
                "stream": stream,
                "tail_on_partial": tail_on_partial
            }
            
            if sequential_image_generation == "auto":
                payload["sequential_image_generation"] = sequential_image_generation
                payload["n"] = max_images
                
            if seed != -1:
                payload["seed"] = seed
            
            # å¤„ç†è¾“å…¥å›¾åƒ
            image_urls = []
            for img in [image1, image2, image3, image4, image5]:
                if img is not None:
                    batch_size = img.shape[0]
                    for i in range(batch_size):
                        single_image = img[i:i+1]
                        image_base64 = image_to_base64(single_image)
                        if image_base64:
                            image_urls.append(image_base64)
            
            if image_urls:
                payload["image"] = image_urls
            
            # æ ¹æ®APIæ ¼å¼è°ƒç”¨ç›¸åº”çš„API
            response = None
            for attempt in range(self.max_retries):
                try:
                    if api_format == "comfly":
                        response = call_comfly_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "openai":
                        response = call_openai_compatible_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "api4gpt":
                        response = call_api4gpt_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "openrouter":
                        response = call_openrouter_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "volcengine":
                        response = call_volcengine_api(api_url, api_key, payload, self.timeout)
                    else:
                        response = call_comfly_api(api_url, api_key, payload, self.timeout)
                    
                    if response and response.status_code == 200:
                        break
                    elif response:
                        _log_warning(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {response.status_code} - {response.text}")
                    else:
                        _log_warning(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): æ— å“åº”")
                    
                    if attempt < self.max_retries - 1:
                        time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                        
                except Exception as e:
                    _log_warning(f"APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                    if attempt < self.max_retries - 1:
                        time.sleep(2 ** attempt)
            
            if not response or response.status_code != 200:
                error_message = f"API Error: {response.status_code if response else 'No response'} - {response.text if response else 'Connection failed'}"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            result = response.json()
            # åªè®°å½•å“åº”çš„åŸºæœ¬ç»“æ„ï¼Œé¿å…æ˜¾ç¤ºå¤§é‡base64æ•°æ®
            if "choices" in result:
                _log_info("ğŸ” APIå“åº”æ ¼å¼: T8å›¾åƒç¼–è¾‘æ ¼å¼ (choices)")
            elif "data" in result:
                _log_info(f"ğŸ” APIå“åº”æ ¼å¼: æ ‡å‡†å›¾åƒç”Ÿæˆæ ¼å¼ (data, {len(result['data'])} é¡¹)")
            else:
                _log_info(f"ğŸ” APIå“åº”æ ¼å¼: æœªçŸ¥æ ¼å¼ï¼ŒåŒ…å«é”®: {list(result.keys())}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯T8å›¾åƒç¼–è¾‘å“åº”ï¼ˆchat/completionsæ ¼å¼ï¼‰
            if "choices" in result and result["choices"]:
                # T8å›¾åƒç¼–è¾‘å“åº”æ ¼å¼
                _log_info("ğŸ¨ æ£€æµ‹åˆ°T8å›¾åƒç¼–è¾‘å“åº”æ ¼å¼")
                choice = result["choices"][0]
                content = choice.get("message", {}).get("content", "")

                # ä»å“åº”ä¸­æå–å›¾åƒURLï¼ˆT8å›¾åƒç¼–è¾‘ä¼šåœ¨æ–‡æœ¬ä¸­è¿”å›å›¾åƒURLï¼‰
                import re

                # å°è¯•å¤šç§URLæå–æ¨¡å¼
                image_urls_found = []

                # æ¨¡å¼1ï¼šMarkdownæ ¼å¼ ![alt](url)
                markdown_pattern = r'!\[.*?\]\((https?://[^\s\)]+)\)'
                markdown_urls = re.findall(markdown_pattern, content)
                image_urls_found.extend(markdown_urls)

                # æ¨¡å¼2ï¼šç›´æ¥çš„å›¾åƒURL
                direct_pattern = r'https?://[^\s<>"]+\.(?:jpg|jpeg|png|gif|webp)'
                direct_urls = re.findall(direct_pattern, content)
                image_urls_found.extend(direct_urls)

                # æ¨¡å¼3ï¼šä»»ä½•åŒ…å«å›¾åƒç›¸å…³åŸŸåçš„URLï¼ˆæ›´å®½æ³›çš„åŒ¹é…ï¼‰
                domain_pattern = r'https?://[^\s<>"\)]+(?:tos-cn-beijing\.volces\.com|ark-content-generation)[^\s<>"\)]*'
                domain_urls = re.findall(domain_pattern, content)
                image_urls_found.extend(domain_urls)

                # å»é‡
                image_urls_found = list(set(image_urls_found))

                _log_info(f"ğŸ” æå–åˆ°çš„å›¾åƒURL: {image_urls_found}")

                generated_images = []
                image_urls = []

                if image_urls_found:
                    for image_url in image_urls_found:
                        try:
                            img_response = requests.get(image_url, timeout=60)
                            if img_response.status_code == 200:
                                image = Image.open(io.BytesIO(img_response.content))
                                generated_images.append(image)
                                image_urls.append(image_url)
                                _log_info(f"âœ… æˆåŠŸä¸‹è½½T8ç¼–è¾‘å›¾åƒ: {image_url}")
                        except Exception as e:
                            _log_warning(f"ä¸‹è½½T8ç¼–è¾‘å›¾åƒå¤±è´¥: {e}")
                            continue

                if not generated_images:
                    error_message = f"T8å›¾åƒç¼–è¾‘å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå›¾åƒURLã€‚å“åº”å†…å®¹: {content}"
                    _log_error(error_message)
                    blank_tensor = create_blank_tensor()
                    return (blank_tensor, error_message, content)

            elif "data" in result and result["data"]:
                # æ ‡å‡†å›¾åƒç”Ÿæˆå“åº”æ ¼å¼
                _log_info("ğŸ–¼ï¸ æ£€æµ‹åˆ°æ ‡å‡†å›¾åƒç”Ÿæˆå“åº”æ ¼å¼")
                generated_images = []
                image_urls = []

                for item in result["data"]:
                    if response_format == "url":
                        image_url = item.get("url")
                        if not image_url:
                            continue

                        try:
                            img_response = requests.get(image_url, timeout=60)
                            if img_response.status_code == 200:
                                image = Image.open(io.BytesIO(img_response.content))
                                generated_images.append(image)
                                image_urls.append(image_url)
                        except Exception as e:
                            _log_warning(f"ä¸‹è½½å›¾åƒå¤±è´¥: {e}")
                            continue

                    elif response_format == "b64_json":
                        b64_data = item.get("b64_json")
                        if not b64_data:
                            continue

                        try:
                            image_data = base64.b64decode(b64_data)
                            image = Image.open(io.BytesIO(image_data))
                            generated_images.append(image)
                            image_urls.append("base64_data")
                        except Exception as e:
                            _log_warning(f"è§£ç base64å›¾åƒå¤±è´¥: {e}")
                            continue
            else:
                error_message = "å“åº”æ ¼å¼ä¸æ”¯æŒæˆ–æ— å›¾åƒæ•°æ®"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            if not generated_images:
                error_message = "No valid images generated"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            # è½¬æ¢ä¸ºtensor - ä½¿ç”¨ComfyUI_Comflyçš„æ–¹å¼
            image_tensors = []
            for i, img in enumerate(generated_images):
                _log_info(f"ğŸ” å¤„ç†å›¾åƒ {i+1}: åŸå§‹å°ºå¯¸ {img.size}, æ¨¡å¼ {img.mode}")
                
                # ä½¿ç”¨pil2tensorå‡½æ•°ï¼Œæ ¼å¼ä¸º[1, H, W, 3]
                tensor = pil2tensor(img)
                _log_info(f"ğŸ” tensorå½¢çŠ¶: {tensor.shape}, å€¼èŒƒå›´: {tensor.min().item():.3f} åˆ° {tensor.max().item():.3f}")
                
                # æ£€æŸ¥tensoræ˜¯å¦æœ‰å¼‚å¸¸
                if len(tensor.shape) != 4 or tensor.shape[-1] != 3:
                    _log_error(f"âŒ å›¾åƒ {i+1} tensorå½¢çŠ¶å¼‚å¸¸: {tensor.shape}")
                    continue
                
                image_tensors.append(tensor)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å›¾åƒtensor
            if not image_tensors:
                _log_error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒtensorï¼Œä½¿ç”¨ç©ºç™½tensor")
                final_tensor = create_blank_tensor()
            else:
                # å †å æ‰€æœ‰å›¾åƒï¼Œæ ¼å¼ä¸º [batch, H, W, 3] - å‚è€ƒComfyUI_Comfly
                if len(image_tensors) == 1:
                    final_tensor = image_tensors[0]
                else:
                    final_tensor = torch.cat(image_tensors, dim=0)
                _log_info(f"ğŸ” å †å åtensorå½¢çŠ¶: {final_tensor.shape}")
            
            # è°ƒè¯•ä¿¡æ¯
            _log_info(f"ğŸ” æœ€ç»ˆtensorå½¢çŠ¶: {final_tensor.shape}")
            _log_info(f"ğŸ” æœ€ç»ˆtensoræ•°æ®ç±»å‹: {final_tensor.dtype}")
            _log_info(f"ğŸ” æœ€ç»ˆtensorå€¼èŒƒå›´: {final_tensor.min().item():.3f} åˆ° {final_tensor.max().item():.3f}")
            
            # æ£€æŸ¥tensoræ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(final_tensor).any():
                _log_error("âŒ tensoråŒ…å«NaNå€¼")
            if torch.isinf(final_tensor).any():
                _log_error("âŒ tensoråŒ…å«æ— ç©·å€¼")
            
            # æ£€æŸ¥æ¯ä¸ªç»´åº¦çš„å€¼
            for i in range(min(final_tensor.shape[0], 2)):  # é™åˆ¶è¾“å‡ºæ•°é‡
                for j in range(min(final_tensor.shape[1], 3)):  # é™åˆ¶è¾“å‡ºæ•°é‡
                    _log_info(f"ğŸ” å›¾åƒ{i}é€šé“{j}å½¢çŠ¶: {final_tensor[i,j].shape}, å€¼èŒƒå›´: {final_tensor[i,j].min().item():.3f} åˆ° {final_tensor[i,j].max().item():.3f}")
            
            # ç‰¹åˆ«æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çš„ç»´åº¦
            if final_tensor.shape[1] == 1 and final_tensor.shape[2] > 1000:
                _log_error(f"âŒ æ£€æµ‹åˆ°å¼‚å¸¸tensorå½¢çŠ¶: {final_tensor.shape} - è¿™å¯èƒ½å¯¼è‡´PILé”™è¯¯")
                _log_error(f"âŒ é€šé“æ•°: {final_tensor.shape[1]}, é«˜åº¦: {final_tensor.shape[2]}, å®½åº¦: {final_tensor.shape[3]}")
                # å¼ºåˆ¶ä¿®å¤
                _log_info("ğŸ”§ å¼ºåˆ¶ä¿®å¤tensoræ ¼å¼...")
                final_tensor = create_blank_tensor()
            
            # ç¡®ä¿tensoræ ¼å¼æ­£ç¡®
            if len(final_tensor.shape) != 4:
                _log_error(f"âŒ tensorç»´åº¦é”™è¯¯: {final_tensor.shape}, åº”è¯¥æ˜¯4ç»´ (batch, channels, height, width)")
                # å°è¯•ä¿®å¤
                if len(final_tensor.shape) == 3:
                    final_tensor = final_tensor.unsqueeze(0)
                    _log_info(f"ğŸ”§ ä¿®å¤åtensorå½¢çŠ¶: {final_tensor.shape}")
            
            # ä½¿ç”¨ensure_tensor_formatç¡®ä¿tensoræ ¼å¼å®Œå…¨æ­£ç¡®
            final_tensor = ensure_tensor_format(final_tensor)
            _log_info(f"ğŸ”§ æœ€ç»ˆtensoræ ¼å¼éªŒè¯å®Œæˆ: {final_tensor.shape}")
            
            # æœ€ç»ˆå¼ºåˆ¶æ£€æŸ¥ - ç¡®ä¿tensoræ ¼å¼ä¸º[batch, H, W, 3]
            if (len(final_tensor.shape) != 4 or 
                final_tensor.shape[-1] != 3):
                _log_error(f"âŒ æœ€ç»ˆæ£€æŸ¥å¤±è´¥ï¼Œtensoræ ¼å¼ä»ç„¶ä¸æ­£ç¡®: {final_tensor.shape}")
                _log_info("ğŸ”§ ä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
                final_tensor = create_blank_tensor()
            
            # æœ€ç»ˆéªŒè¯tensoræ˜¯å¦å¯ä»¥è¢«PILå¤„ç†
            try:
                # å°è¯•è½¬æ¢ä¸ºnumpyæ•°ç»„æ¥éªŒè¯ - æ ¼å¼ä¸º[H, W, 3]
                test_array = final_tensor[0].cpu().numpy()
                test_array = np.clip(test_array, 0, 1)
                test_array = (test_array * 255).astype(np.uint8)
                _log_info(f"ğŸ” PILå…¼å®¹æ€§æµ‹è¯•é€šè¿‡: {test_array.shape}")
            except Exception as e:
                _log_error(f"âŒ PILå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
                _log_info("ğŸ”§ ä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
                final_tensor = create_blank_tensor()
            
            response_text = f"Successfully generated {len(generated_images)} image(s)"
            image_url_text = image_urls[0] if image_urls else ""
            
            _log_info(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_images)} å¼ å›¾åƒ")
            return (final_tensor, response_text, image_url_text)
            
        except Exception as e:
            error_message = f"Generation failed: {str(e)}"
            _log_error(error_message)
            blank_tensor = ensure_tensor_format(create_blank_tensor())
            _log_info(f"ğŸ” é”™è¯¯å¤„ç†tensorå½¢çŠ¶: {blank_tensor.shape}")
            
            return (blank_tensor, error_message, "")

class SeedReam4APISingleNode:
    """SeedReam4API å•å›¾åƒç”ŸæˆåŠç¼–è¾‘èŠ‚ç‚¹ç±»"""
    
    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())
        
        if not mirror_options:
            mirror_options = ["comfly", "t8_mirror"]
        
        # ä¿ç•™å‰ä¸‰ä¸ªé•œåƒç«™é€‰é¡¹ï¼ˆåŒ…æ‹¬ç«å±±å¼•æ“ï¼‰
        mirror_options = [opt for opt in mirror_options if opt in ["comfly", "t8_mirror", "volcengine"]]
        
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "A beautiful landscape"}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedream-4-0-250828"], {"default": "doubao-seedream-4-0-250828"}),
                "response_format": (["url", "b64_json"], {"default": "url"}),
                "resolution": (["1K", "2K", "4K"], {"default": "1K"}),
                "aspect_ratio": (["1:1", "4:3", "3:4", "16:9", "9:16", "2:3", "3:2", "21:9", "9:21", "Custom"], {"default": "1:1"}),
                "width": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 1}),
                "height": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 1}),
                "api_key": ("STRING", {"default": ""}),
                "max_images": ("INT", {"default": 1, "min": 1, "max": 15, "step": 1}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
                "watermark": ("BOOLEAN", {"default": True}),
                "stream": ("BOOLEAN", {"default": False}),
                "tail_on_partial": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "image": ("IMAGE",),  # å•å›¾åƒè¾“å…¥ï¼Œç”¨äºå›¾åƒç¼–è¾‘
                "sequential_image_generation": (["disabled", "auto"], {"default": "disabled"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")
    RETURN_NAMES = ("image", "response", "image_url")
    FUNCTION = "generate_image"
    CATEGORY = "Ken-Chen/Doubao"
    
    def __init__(self):
        self.config = get_seedream4_config()
        self.timeout = self.config.get('timeout', 900)
        self.max_retries = self.config.get('max_retries', 3)
        self.size_mapping = self.config.get('size_mapping', {})
        self.resolution_factors = self.config.get('resolution_factors', {})
    
    def get_headers(self, api_key):
        """è·å–è¯·æ±‚å¤´"""
        return {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
    
    def generate_image(self, prompt, mirror_site, model, response_format="url", resolution="1K",
                      aspect_ratio="1:1", width=1024, height=1024, api_key="",
                      max_images=1, seed=-1, watermark=True, stream=False, tail_on_partial=True,
                      image=None, sequential_image_generation="disabled"):
        """ç”Ÿæˆå›¾åƒ - å•å›¾åƒç‰ˆæœ¬"""
        
        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")
        
        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")
        
        if not api_key.strip():
            error_message = "API key not found"
            _log_error(error_message)
            blank_tensor = create_blank_tensor()
            return (blank_tensor, error_message, "")
        
        if not validate_api_url(api_url):
            error_message = "Invalid API URL"
            _log_error(error_message)
            blank_tensor = create_blank_tensor()
            return (blank_tensor, error_message, "")
        
        _log_info(f"ğŸ”— ä½¿ç”¨é•œåƒç«™: {mirror_site} ({api_url})")
        
        try:
            # è®¡ç®—æœ€ç»ˆå°ºå¯¸
            if aspect_ratio == "Custom":
                scale_factor = self.resolution_factors.get(resolution, 1)
                scaled_width = int(width * scale_factor)
                scaled_height = int(height * scale_factor)
                final_size = f"{scaled_width}x{scaled_height}"
                _log_info(f"ä½¿ç”¨è‡ªå®šä¹‰å°ºå¯¸: {final_size}")
            else:
                if resolution in self.size_mapping and aspect_ratio in self.size_mapping[resolution]:
                    final_size = self.size_mapping[resolution][aspect_ratio]
                else:
                    final_size = "1024x1024"
                    _log_warning(f"æœªæ‰¾åˆ° {resolution} å’Œ {aspect_ratio} çš„ç»„åˆï¼Œä½¿ç”¨ {final_size}")
            
            # æ„å»ºè¯·æ±‚è½½è·
            payload = {
                "model": model,
                "prompt": prompt,
                "response_format": response_format,
                "size": final_size,
                "watermark": watermark,  # å§‹ç»ˆæ·»åŠ watermarkå‚æ•°
                "stream": stream,  # å§‹ç»ˆæ·»åŠ streamå‚æ•°
                "tail_on_partial": tail_on_partial  # å§‹ç»ˆæ·»åŠ tail_on_partialå‚æ•°
            }
            
            if sequential_image_generation == "auto":
                payload["sequential_image_generation"] = sequential_image_generation
                payload["n"] = max_images
                
            if seed != -1:
                payload["seed"] = seed
            
            # å¤„ç†å•å›¾åƒè¾“å…¥
            if image is not None:
                _log_info(f"ğŸ” å¤„ç†è¾“å…¥å›¾åƒ: {image.shape}")
                image_base64 = image_to_base64(image)
                if image_base64:
                    base64_size_mb = len(image_base64) / (1024 * 1024)
                    _log_info(f"ğŸ”§ æ·»åŠ å›¾åƒåˆ°è¯·æ±‚è½½è· (base64: {len(image_base64):,} å­—ç¬¦, {base64_size_mb:.2f}MB)")
                    payload["image"] = [image_base64]
                    _log_info(f"ğŸ” å•å›¾èŠ‚ç‚¹å›¾åƒæ•°æ®: æ•°ç»„é•¿åº¦={len(payload['image'])}, base64é•¿åº¦={len(image_base64)}")
                else:
                    _log_error("âŒ å›¾åƒè½¬æ¢ä¸ºbase64å¤±è´¥")
            
            # æ ¹æ®APIæ ¼å¼è°ƒç”¨ç›¸åº”çš„API
            _log_info(f"ğŸ” å•å›¾èŠ‚ç‚¹APIè°ƒç”¨è¯¦æƒ…:")
            _log_info(f"   - APIæ ¼å¼: {api_format}")
            _log_info(f"   - APIåœ°å€: {api_url}")
            _log_info(f"   - æ¨¡å‹: {payload.get('model', 'N/A')}")
            _log_info(f"   - æ˜¯å¦åŒ…å«å›¾åƒ: {'image' in payload and bool(payload.get('image'))}")
            if 'image' in payload and payload.get('image'):
                _log_info(f"   - å›¾åƒæ•°é‡: {len(payload['image'])}")

            response = None
            for attempt in range(self.max_retries):
                try:
                    if api_format == "comfly":
                        response = call_comfly_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "openai":
                        response = call_openai_compatible_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "api4gpt":
                        response = call_api4gpt_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "openrouter":
                        response = call_openrouter_api(api_url, api_key, payload, self.timeout)
                    elif api_format == "volcengine":
                        response = call_volcengine_api(api_url, api_key, payload, self.timeout)
                    else:
                        response = call_comfly_api(api_url, api_key, payload, self.timeout)
                    
                    if response and response.status_code == 200:
                        break
                    elif response:
                        error_text = response.text[:500] if response.text else "æ— é”™è¯¯ä¿¡æ¯"
                        _log_warning(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {response.status_code}")
                        _log_warning(f"é”™è¯¯è¯¦æƒ…: {error_text}")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒè¿‡å¤§çš„é”™è¯¯
                        if "too large" in error_text.lower() or "payload too large" in error_text.lower():
                            _log_error("âŒ å›¾åƒæ•°æ®è¿‡å¤§ï¼Œè¯·å°è¯•ä½¿ç”¨è¾ƒå°çš„å›¾åƒ")
                        elif "invalid" in error_text.lower() and "image" in error_text.lower():
                            _log_error("âŒ å›¾åƒæ ¼å¼æ— æ•ˆï¼Œè¯·æ£€æŸ¥è¾“å…¥å›¾åƒ")
                    else:
                        _log_warning(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): æ— å“åº”")
                    
                    if attempt < self.max_retries - 1:
                        time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                        
                except Exception as e:
                    _log_warning(f"APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                    if attempt < self.max_retries - 1:
                        time.sleep(2 ** attempt)
            
            if not response or response.status_code != 200:
                error_message = f"API Error: {response.status_code if response else 'No response'} - {response.text if response else 'Connection failed'}"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            result = response.json()
            # åªè®°å½•å“åº”çš„åŸºæœ¬ç»“æ„ï¼Œé¿å…æ˜¾ç¤ºå¤§é‡base64æ•°æ®
            if "choices" in result:
                _log_info("ğŸ” APIå“åº”æ ¼å¼: T8å›¾åƒç¼–è¾‘æ ¼å¼ (choices)")
            elif "data" in result:
                _log_info(f"ğŸ” APIå“åº”æ ¼å¼: æ ‡å‡†å›¾åƒç”Ÿæˆæ ¼å¼ (data, {len(result['data'])} é¡¹)")
            else:
                _log_info(f"ğŸ” APIå“åº”æ ¼å¼: æœªçŸ¥æ ¼å¼ï¼ŒåŒ…å«é”®: {list(result.keys())}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯T8å›¾åƒç¼–è¾‘å“åº”ï¼ˆchat/completionsæ ¼å¼ï¼‰
            if "choices" in result and result["choices"]:
                # T8å›¾åƒç¼–è¾‘å“åº”æ ¼å¼
                _log_info("ğŸ¨ æ£€æµ‹åˆ°T8å›¾åƒç¼–è¾‘å“åº”æ ¼å¼")
                choice = result["choices"][0]
                content = choice.get("message", {}).get("content", "")

                # ä»å“åº”ä¸­æå–å›¾åƒURLï¼ˆT8å›¾åƒç¼–è¾‘ä¼šåœ¨æ–‡æœ¬ä¸­è¿”å›å›¾åƒURLï¼‰
                import re

                # å°è¯•å¤šç§URLæå–æ¨¡å¼
                image_urls_found = []

                # æ¨¡å¼1ï¼šMarkdownæ ¼å¼ ![alt](url)
                markdown_pattern = r'!\[.*?\]\((https?://[^\s\)]+)\)'
                markdown_urls = re.findall(markdown_pattern, content)
                image_urls_found.extend(markdown_urls)

                # æ¨¡å¼2ï¼šç›´æ¥çš„å›¾åƒURL
                direct_pattern = r'https?://[^\s<>"]+\.(?:jpg|jpeg|png|gif|webp)'
                direct_urls = re.findall(direct_pattern, content)
                image_urls_found.extend(direct_urls)

                # æ¨¡å¼3ï¼šä»»ä½•åŒ…å«å›¾åƒç›¸å…³åŸŸåçš„URLï¼ˆæ›´å®½æ³›çš„åŒ¹é…ï¼‰
                domain_pattern = r'https?://[^\s<>"\)]+(?:tos-cn-beijing\.volces\.com|ark-content-generation)[^\s<>"\)]*'
                domain_urls = re.findall(domain_pattern, content)
                image_urls_found.extend(domain_urls)

                # å»é‡
                image_urls_found = list(set(image_urls_found))

                _log_info(f"ğŸ” æå–åˆ°çš„å›¾åƒURL: {image_urls_found}")

                generated_images = []
                image_urls = []

                if image_urls_found:
                    for image_url in image_urls_found:
                        try:
                            img_response = requests.get(image_url, timeout=60)
                            if img_response.status_code == 200:
                                image = Image.open(io.BytesIO(img_response.content))
                                generated_images.append(image)
                                image_urls.append(image_url)
                                _log_info(f"âœ… æˆåŠŸä¸‹è½½T8ç¼–è¾‘å›¾åƒ: {image_url}")
                        except Exception as e:
                            _log_warning(f"ä¸‹è½½T8ç¼–è¾‘å›¾åƒå¤±è´¥: {e}")
                            continue

                if not generated_images:
                    error_message = f"T8å›¾åƒç¼–è¾‘å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå›¾åƒURLã€‚å“åº”å†…å®¹: {content}"
                    _log_error(error_message)
                    blank_tensor = create_blank_tensor()
                    return (blank_tensor, error_message, content)

            elif "data" in result and result["data"]:
                # æ ‡å‡†å›¾åƒç”Ÿæˆå“åº”æ ¼å¼
                _log_info("ğŸ–¼ï¸ æ£€æµ‹åˆ°æ ‡å‡†å›¾åƒç”Ÿæˆå“åº”æ ¼å¼")
                generated_images = []
                image_urls = []

                for item in result["data"]:
                    if response_format == "url":
                        image_url = item.get("url")
                        if not image_url:
                            continue

                        try:
                            img_response = requests.get(image_url, timeout=60)
                            if img_response.status_code == 200:
                                image = Image.open(io.BytesIO(img_response.content))
                                generated_images.append(image)
                                image_urls.append(image_url)
                        except Exception as e:
                            _log_warning(f"ä¸‹è½½å›¾åƒå¤±è´¥: {e}")
                            continue

                    elif response_format == "b64_json":
                        b64_data = item.get("b64_json")
                        if not b64_data:
                            continue

                        try:
                            image_data = base64.b64decode(b64_data)
                            image = Image.open(io.BytesIO(image_data))
                            generated_images.append(image)
                            image_urls.append("base64_data")
                        except Exception as e:
                            _log_warning(f"è§£ç base64å›¾åƒå¤±è´¥: {e}")
                            continue
            else:
                error_message = "å“åº”æ ¼å¼ä¸æ”¯æŒæˆ–æ— å›¾åƒæ•°æ®"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            if not generated_images:
                error_message = "No valid images generated"
                _log_error(error_message)
                blank_tensor = create_blank_tensor()
                return (blank_tensor, error_message, "")
            
            # è½¬æ¢ä¸ºtensor - ä½¿ç”¨ComfyUI_Comflyçš„æ–¹å¼
            image_tensors = []
            for i, img in enumerate(generated_images):
                _log_info(f"ğŸ” å¤„ç†å›¾åƒ {i+1}: åŸå§‹å°ºå¯¸ {img.size}, æ¨¡å¼ {img.mode}")
                
                # ä½¿ç”¨pil2tensorå‡½æ•°ï¼Œæ ¼å¼ä¸º[1, H, W, 3]
                tensor = pil2tensor(img)
                _log_info(f"ğŸ” tensorå½¢çŠ¶: {tensor.shape}, å€¼èŒƒå›´: {tensor.min().item():.3f} åˆ° {tensor.max().item():.3f}")
                
                # æ£€æŸ¥tensoræ˜¯å¦æœ‰å¼‚å¸¸
                if len(tensor.shape) != 4 or tensor.shape[-1] != 3:
                    _log_error(f"âŒ å›¾åƒ {i+1} tensorå½¢çŠ¶å¼‚å¸¸: {tensor.shape}")
                    continue
                
                image_tensors.append(tensor)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å›¾åƒtensor
            if not image_tensors:
                _log_error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒtensorï¼Œä½¿ç”¨ç©ºç™½tensor")
                final_tensor = create_blank_tensor()
            else:
                # å †å æ‰€æœ‰å›¾åƒï¼Œæ ¼å¼ä¸º [batch, H, W, 3] - å‚è€ƒComfyUI_Comfly
                if len(image_tensors) == 1:
                    final_tensor = image_tensors[0]
                else:
                    final_tensor = torch.cat(image_tensors, dim=0)
                _log_info(f"ğŸ” å †å åtensorå½¢çŠ¶: {final_tensor.shape}")
            
            # è°ƒè¯•ä¿¡æ¯
            _log_info(f"ğŸ” æœ€ç»ˆtensorå½¢çŠ¶: {final_tensor.shape}")
            _log_info(f"ğŸ” æœ€ç»ˆtensoræ•°æ®ç±»å‹: {final_tensor.dtype}")
            _log_info(f"ğŸ” æœ€ç»ˆtensorå€¼èŒƒå›´: {final_tensor.min().item():.3f} åˆ° {final_tensor.max().item():.3f}")
            
            # æ£€æŸ¥tensoræ˜¯å¦æœ‰å¼‚å¸¸å€¼
            if torch.isnan(final_tensor).any():
                _log_error("âŒ tensoråŒ…å«NaNå€¼")
            if torch.isinf(final_tensor).any():
                _log_error("âŒ tensoråŒ…å«æ— ç©·å€¼")
            
            # æ£€æŸ¥æ¯ä¸ªç»´åº¦çš„å€¼
            for i in range(min(final_tensor.shape[0], 2)):  # é™åˆ¶è¾“å‡ºæ•°é‡
                for j in range(min(final_tensor.shape[1], 3)):  # é™åˆ¶è¾“å‡ºæ•°é‡
                    _log_info(f"ğŸ” å›¾åƒ{i}é€šé“{j}å½¢çŠ¶: {final_tensor[i,j].shape}, å€¼èŒƒå›´: {final_tensor[i,j].min().item():.3f} åˆ° {final_tensor[i,j].max().item():.3f}")
            
            # ç‰¹åˆ«æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çš„ç»´åº¦
            if final_tensor.shape[1] == 1 and final_tensor.shape[2] > 1000:
                _log_error(f"âŒ æ£€æµ‹åˆ°å¼‚å¸¸tensorå½¢çŠ¶: {final_tensor.shape} - è¿™å¯èƒ½å¯¼è‡´PILé”™è¯¯")
                _log_error(f"âŒ é€šé“æ•°: {final_tensor.shape[1]}, é«˜åº¦: {final_tensor.shape[2]}, å®½åº¦: {final_tensor.shape[3]}")
                # å¼ºåˆ¶ä¿®å¤
                _log_info("ğŸ”§ å¼ºåˆ¶ä¿®å¤tensoræ ¼å¼...")
                final_tensor = create_blank_tensor()
            
            # ç¡®ä¿tensoræ ¼å¼æ­£ç¡®
            if len(final_tensor.shape) != 4:
                _log_error(f"âŒ tensorç»´åº¦é”™è¯¯: {final_tensor.shape}, åº”è¯¥æ˜¯4ç»´ (batch, height, width, channels)")
                # å°è¯•ä¿®å¤
                if len(final_tensor.shape) == 3:
                    final_tensor = final_tensor.unsqueeze(0)
                    _log_info(f"ğŸ”§ ä¿®å¤åtensorå½¢çŠ¶: {final_tensor.shape}")
            
            # ä½¿ç”¨ensure_tensor_formatç¡®ä¿tensoræ ¼å¼å®Œå…¨æ­£ç¡®
            final_tensor = ensure_tensor_format(final_tensor)
            _log_info(f"ğŸ”§ æœ€ç»ˆtensoræ ¼å¼éªŒè¯å®Œæˆ: {final_tensor.shape}")
            
            # æœ€ç»ˆå¼ºåˆ¶æ£€æŸ¥ - ç¡®ä¿tensoræ ¼å¼ä¸º[batch, H, W, 3]
            if (len(final_tensor.shape) != 4 or 
                final_tensor.shape[-1] != 3):
                _log_error(f"âŒ æœ€ç»ˆæ£€æŸ¥å¤±è´¥ï¼Œtensoræ ¼å¼ä»ç„¶ä¸æ­£ç¡®: {final_tensor.shape}")
                _log_info("ğŸ”§ ä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
                final_tensor = create_blank_tensor()
            
            # æœ€ç»ˆéªŒè¯tensoræ˜¯å¦å¯ä»¥è¢«PILå¤„ç†
            try:
                # å°è¯•è½¬æ¢ä¸ºnumpyæ•°ç»„æ¥éªŒè¯ - æ ¼å¼ä¸º[H, W, 3]
                test_array = final_tensor[0].cpu().numpy()
                test_array = np.clip(test_array, 0, 1)
                test_array = (test_array * 255).astype(np.uint8)
                _log_info(f"ğŸ” PILå…¼å®¹æ€§æµ‹è¯•é€šè¿‡: {test_array.shape}")
            except Exception as e:
                _log_error(f"âŒ PILå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
                _log_info("ğŸ”§ ä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
                final_tensor = create_blank_tensor()
            
            response_text = f"Successfully generated {len(generated_images)} image(s)"
            image_url_text = image_urls[0] if image_urls else ""
            
            _log_info(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_images)} å¼ å›¾åƒ")
            return (final_tensor, response_text, image_url_text)
            
        except Exception as e:
            error_message = f"Generation failed: {str(e)}"
            _log_error(error_message)
            blank_tensor = ensure_tensor_format(create_blank_tensor())
            _log_info(f"ğŸ” é”™è¯¯å¤„ç†tensorå½¢çŠ¶: {blank_tensor.shape}")
            
            return (blank_tensor, error_message, "")

class DoubaoSeedanceVideoNode:
    """Doubao-Seedanceè§†é¢‘ç”ŸæˆèŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())

        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "A beautiful video scene"}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"], {"default": "doubao-seedance-1-0-pro-250528"}),
                "video_mode": (["text_to_video", "image_to_video", "first_last_frame"], {"default": "text_to_video"}),
                "duration": (["3s", "5s", "10s", "12s"], {"default": "5s"}),
                "resolution": (["480p", "720p", "1080p"], {"default": "720p"}),
                "aspect_ratio": (["16:9", "4:3", "1:1", "3:4", "9:16", "21:9", "adaptive"], {"default": "16:9"}),
                "fps": ([24, 30], {"default": 30}),
                "watermark": ("BOOLEAN", {"default": False}),
                "camera_fixed": ("BOOLEAN", {"default": False}),
                "api_key": ("STRING", {"default": ""}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            },
            "optional": {
                "input_image": ("IMAGE",),
                "first_frame": ("IMAGE",),
                "last_frame": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "STRING", "STRING", "VIDEO")
    RETURN_NAMES = ("video", "video_url", "response_text", "video_info", "AFVIDEO")
    FUNCTION = "generate_video"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 900  # 15åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
        self.max_retries = 3

    def generate_video(self, prompt, mirror_site, model, video_mode, duration, resolution, aspect_ratio, fps, watermark=False, camera_fixed=False, api_key="", seed=-1,
                      input_image=None, first_frame=None, last_frame=None):
        """ç”Ÿæˆè§†é¢‘"""

        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")

        # å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™çš„APIæ ¼å¼ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
        if mirror_site == "t8_mirror" or "t8star.cn" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")

        if not api_key.strip():
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªæä¾›API Key", "", blank_video_path)

        if not api_url:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªé…ç½®API URL", "", blank_video_path)

        _log_info(f"ğŸ”— ä½¿ç”¨é•œåƒç«™: {mirror_site} ({api_url})")

        try:
            # æ ¹æ®APIæ ¼å¼æ„å»ºä¸åŒçš„payload
            _log_info(f"ğŸ” APIæ ¼å¼åˆ¤æ–­ç»“æœ: {api_format}")
            _log_info(f"ğŸ” API URL: {api_url}")
            _log_info(f"ğŸ” æ˜¯å¦åŒ…å«t8star.cn: {'t8star.cn' in api_url}")

            if api_format == "volcengine":
                # ç«å±±å¼•æ“ä½¿ç”¨contentæ•°ç»„æ ¼å¼
                _log_info(f"ğŸ”§ æ„å»ºç«å±±å¼•æ“æ ¼å¼payload")

                # æ ¹æ®å®˜æ–¹æ–‡æ¡£æ„å»ºæ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨æ­£ç¡®çš„å‚æ•°æ ¼å¼
                if video_mode == "first_last_frame":
                    # é¦–å°¾å¸§æ¨¡å¼ï¼šæ ¹æ®å®˜æ–¹ç¤ºä¾‹ï¼Œåªä½¿ç”¨ --rs --dur --cf å‚æ•°
                    text_content = f"{prompt} --rs {resolution} --dur {duration.replace('s', '')} --cf {str(camera_fixed).lower()}"
                    if seed != -1:
                        text_content += f" --seed {seed}"
                    # æ·»åŠ watermarkå‚æ•°
                    text_content += f" --wm {str(watermark).lower()}"
                    _log_info(f"ğŸ”§ é¦–å°¾å¸§æ¨¡å¼æ–‡æœ¬å†…å®¹: {text_content}")
                else:
                    # æ–‡ç”Ÿè§†é¢‘å’Œå›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼šä½¿ç”¨å®Œæ•´å‚æ•°
                    text_content = f"{prompt} --rt {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                    if seed != -1:
                        text_content += f" --seed {seed}"
                    # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                    text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                    _log_info(f"ğŸ”§ æ ‡å‡†æ¨¡å¼æ–‡æœ¬å†…å®¹: {text_content}")

                content = [
                    {
                        "type": "text",
                        "text": text_content
                    }
                ]

                # æ ¹æ®è§†é¢‘æ¨¡å¼æ·»åŠ å›¾åƒ
                if video_mode == "image_to_video" and input_image is not None:
                    _log_info(f"ğŸ” å›¾ç”Ÿè§†é¢‘æ¨¡å¼: è¾“å…¥å›¾åƒ {input_image.shape}")

                    # ç«å±±å¼•æ“APIéœ€è¦å®Œæ•´çš„Data URLæ ¼å¼ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
                    image_data_url = image_to_base64(input_image, return_data_url=True)
                    if image_data_url:
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": image_data_url
                            }
                        })
                        _log_info(f"ğŸ”§ æ·»åŠ è¾“å…¥å›¾åƒåˆ°content (Data URLé•¿åº¦: {len(image_data_url)})")
                    else:
                        _log_error(f"âŒ å›¾åƒData URLç¼–ç å¤±è´¥")

                elif video_mode == "first_last_frame" and first_frame is not None and last_frame is not None:
                    _log_info(f"ğŸ” é¦–å°¾å¸§æ¨¡å¼: é¦–å¸§ {first_frame.shape}, å°¾å¸§ {last_frame.shape}")
                    # ç«å±±å¼•æ“APIéœ€è¦å®Œæ•´çš„Data URLæ ¼å¼
                    first_data_url = image_to_base64(first_frame, return_data_url=True)
                    last_data_url = image_to_base64(last_frame, return_data_url=True)
                    if first_data_url and last_data_url:
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": first_data_url
                            },
                            "role": "first_frame"  # å®˜æ–¹æ ¼å¼ï¼šé¦–å¸§è§’è‰²æ ‡è¯†
                        })
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": last_data_url
                            },
                            "role": "last_frame"   # å®˜æ–¹æ ¼å¼ï¼šå°¾å¸§è§’è‰²æ ‡è¯†
                        })
                        _log_info(f"ğŸ”§ æ·»åŠ é¦–å°¾å¸§åˆ°content (é¦–å¸§Data URLé•¿åº¦: {len(first_data_url)}, å°¾å¸§Data URLé•¿åº¦: {len(last_data_url)})")

                # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨æ–‡æœ¬ä¸­æŒ‡å®šï¼Œä¸éœ€è¦é¡¶å±‚å‚æ•°
                payload = {
                    "model": model,
                    "content": content
                }

            else:
                # Comfly/T8æ ¼å¼ - æ ¹æ®é”™è¯¯ä¿¡æ¯ï¼ŒComflyä¹Ÿä½¿ç”¨contentæ•°ç»„æ ¼å¼
                _log_info(f"ğŸ”§ æ„å»ºComfly/T8æ ¼å¼payload")

                if api_format == "comfly":
                    # æ ¹æ®APIæ–‡æ¡£ï¼Œä½¿ç”¨ç®€å•çš„æ ¼å¼
                    _log_info(f"ğŸ”§ ä½¿ç”¨Comflyæ ¼å¼æ„å»ºpayload")

                    # Comflyé•œåƒç«™ä½¿ç”¨ä¼ ç»Ÿçš„åˆ†è¾¨ç‡æ ‡ç­¾ï¼Œä¸æ”¯æŒåƒç´ æ ¼å¼
                    payload = {
                        "prompt": prompt,
                        "model": model,
                        "duration": int(duration.replace('s', '')),
                        "resolution": resolution,  # ä½¿ç”¨åŸå§‹åˆ†è¾¨ç‡æ ‡ç­¾å¦‚"720p"
                        "ratio": aspect_ratio,
                        "watermark": watermark
                    }

                    _log_info(f"ğŸ”§ Comflyä½¿ç”¨ä¼ ç»Ÿåˆ†è¾¨ç‡æ ¼å¼: {resolution} + {aspect_ratio}")
                    _log_info(f"ğŸ” Comflyæ ¼å¼durationç±»å‹: {type(payload['duration'])}, å€¼: {payload['duration']}")

                    # T8é•œåƒç«™éœ€è¦ç‰¹æ®Šå‚æ•°
                    if "t8star.cn" in api_url:
                        payload["01K3ZARVMSZ97JPXNWXBCJGG6K"] = ""  # T8å¿…éœ€å‚æ•°
                        _log_info(f"ğŸ”§ ä¸ºT8é•œåƒç«™æ·»åŠ ç‰¹æ®Šå‚æ•°")
                else:
                    # T8æ ¼å¼ä¿æŒåŸæœ‰ç»“æ„ï¼ˆè¿™ä¸ªåˆ†æ”¯ä¸åº”è¯¥è¢«T8é•œåƒç«™ä½¿ç”¨ï¼‰
                    _log_info(f"ğŸ”§ ä½¿ç”¨æ—§T8æ ¼å¼æ„å»ºpayloadï¼ˆä¸æ¨èï¼‰")
                    payload = {
                        "model": model,
                        "prompt": prompt,
                        "duration": duration,
                        "resolution": resolution,  # ä½¿ç”¨åŸå§‹åˆ†è¾¨ç‡æ ‡ç­¾
                        "ratio": aspect_ratio,
                        "watermark": watermark
                    }

                    _log_info(f"ğŸ”§ æ—§T8ä½¿ç”¨ä¼ ç»Ÿåˆ†è¾¨ç‡æ ¼å¼: {resolution} + {aspect_ratio}")
                    _log_info(f"ğŸ” æ—§T8æ ¼å¼durationç±»å‹: {type(payload['duration'])}, å€¼: {payload['duration']}")

                # æ·»åŠ ç§å­
                if seed != -1:
                    if api_format == "comfly":
                        # Comflyæ ¼å¼ï¼šç§å­æ·»åŠ åˆ°payloadä¸­
                        payload["seed"] = seed
                    else:
                        # å…¶ä»–æ ¼å¼ï¼šç§å­æ·»åŠ åˆ°payloadä¸­
                        payload["seed"] = seed

                # æ ¹æ®è§†é¢‘æ¨¡å¼å¤„ç†å›¾åƒè¾“å…¥
                if video_mode == "image_to_video" and input_image is not None:
                    _log_info(f"ğŸ” å›¾ç”Ÿè§†é¢‘æ¨¡å¼: è¾“å…¥å›¾åƒ {input_image.shape}")

                    # æ ¹æ®APIæ ¼å¼é€‰æ‹©åˆé€‚çš„å›¾åƒç¼–ç æ–¹å¼
                    if api_format == "comfly":
                        # Comflyæ ¼å¼ï¼šæ ¹æ®APIæ–‡æ¡£ï¼Œå›¾ç”Ÿè§†é¢‘ä½¿ç”¨imagesæ•°ç»„ï¼ˆå•å¼ å›¾ç‰‡ï¼‰
                        image_data = image_to_base64(input_image, return_data_url=True)
                        payload["images"] = [image_data]
                        _log_info(f"ğŸ”§ Comflyæ ¼å¼: æ·»åŠ å›¾ç”Ÿè§†é¢‘å›¾åƒåˆ°imagesæ•°ç»„ (é•¿åº¦: {len(image_data) if image_data else 0})")
                    else:
                        # T8ç­‰å…¶ä»–æ ¼å¼ï¼šä½¿ç”¨imageå­—æ®µ
                        image_data = image_to_base64(input_image, return_data_url=True)
                        payload["image"] = [image_data]
                        _log_info(f"ğŸ”§ å…¶ä»–æ ¼å¼: æ·»åŠ Data URLå›¾åƒåˆ°è½½è· (é•¿åº¦: {len(image_data) if image_data else 0})")

                    if not image_data:
                        _log_error(f"âŒ å›¾åƒç¼–ç å¤±è´¥")

                elif video_mode == "first_last_frame" and first_frame is not None and last_frame is not None:
                    _log_info(f"ğŸ” é¦–å°¾å¸§æ¨¡å¼: é¦–å¸§ {first_frame.shape}, å°¾å¸§ {last_frame.shape}")

                    # æ ¹æ®APIæ ¼å¼é€‰æ‹©åˆé€‚çš„å›¾åƒç¼–ç æ–¹å¼
                    if api_format == "comfly":
                        # Comflyæ ¼å¼ï¼šä½¿ç”¨imagesæ•°ç»„æ ¼å¼ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯é¦–å¸§ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯å°¾å¸§
                        first_data = image_to_base64(first_frame, return_data_url=True)
                        last_data = image_to_base64(last_frame, return_data_url=True)

                        if first_data and last_data:
                            # æ ¹æ®Comfly APIæ–‡æ¡£ï¼Œé¦–å°¾å¸§ä½¿ç”¨imagesæ•°ç»„
                            payload["images"] = [first_data, last_data]
                            _log_info(f"ğŸ”§ Comflyæ ¼å¼: ä½¿ç”¨imagesæ•°ç»„æ ¼å¼æ·»åŠ é¦–å°¾å¸§")
                        else:
                            _log_error(f"âŒ Comflyé¦–å°¾å¸§ç¼–ç å¤±è´¥")
                    else:
                        # T8ç­‰å…¶ä»–æ ¼å¼ï¼šä½¿ç”¨å®Œæ•´çš„Data URLæ ¼å¼
                        first_data = image_to_base64(first_frame, return_data_url=True)
                        last_data = image_to_base64(last_frame, return_data_url=True)
                        payload["first_frame"] = first_data
                        payload["last_frame"] = last_data
                        _log_info(f"ğŸ”§ å…¶ä»–æ ¼å¼: æ·»åŠ Data URLé¦–å°¾å¸§åˆ°è½½è·")

                    if first_data and last_data:
                        _log_info(f"ğŸ” é¦–å¸§æ•°æ®é•¿åº¦: {len(first_data)}, å°¾å¸§æ•°æ®é•¿åº¦: {len(last_data)}")
                    else:
                        _log_error(f"âŒ é¦–å°¾å¸§ç¼–ç å¤±è´¥")

                elif video_mode == "text_to_video":
                    _log_info(f"ğŸ” æ–‡ç”Ÿè§†é¢‘æ¨¡å¼")

            _log_info(f"ğŸ” è§†é¢‘ç”Ÿæˆè¯¦æƒ…:")
            _log_info(f"   - APIæ ¼å¼: {api_format}")
            _log_info(f"   - APIåœ°å€: {api_url}")
            _log_info(f"   - æ¨¡å‹: {model}")
            _log_info(f"   - è§†é¢‘æ¨¡å¼: {video_mode}")
            _log_info(f"   - æ—¶é•¿: {duration}")
            _log_info(f"   - åˆ†è¾¨ç‡: {resolution}")
            _log_info(f"   - å¸§ç‡: {fps}")

            # è°ƒç”¨è§†é¢‘ç”ŸæˆAPI
            _log_info(f"ğŸ” æœ€ç»ˆpayloadå†…å®¹: {list(payload.keys())}")
            if "api_platform" in payload:
                _log_info(f"ğŸ” api_platformå‚æ•°: {payload['api_platform']}")
            else:
                _log_info(f"âš ï¸ payloadä¸­ç¼ºå°‘api_platformå‚æ•°")

            response = None
            for attempt in range(self.max_retries):
                try:
                    response = call_video_api(api_url, api_key, payload, api_format, self.timeout)

                    if response and response.status_code in [200, 201, 202]:
                        break
                    else:
                        error_msg = response.text if response else "æ— å“åº”"
                        _log_warning(f"è§†é¢‘APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")

                except Exception as e:
                    _log_warning(f"è§†é¢‘APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {str(e)}")

                if attempt < self.max_retries - 1:
                    time.sleep(2)  # é‡è¯•å‰ç­‰å¾…2ç§’

            if not response or response.status_code not in [200, 201, 202]:
                error_msg = f"API Error: {response.text if response else 'No response'} - Connection failed"
                _log_error(error_msg)
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", f"âŒ {error_msg}", "", blank_video_path)

            # è§£æå“åº”
            try:
                result = response.json()
                _log_info(f"ğŸ” è§†é¢‘APIå“åº”æ ¼å¼: {type(result)}")
                _log_info(f"ğŸ” è§†é¢‘APIå“åº”å†…å®¹: {str(result)[:200]}...")

                # æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚æ­¥ä»»åŠ¡å“åº”
                task_id = None
                if "task_id" in result:
                    task_id = result["task_id"]
                elif "id" in result:
                    task_id = result["id"]
                elif "data" in result and isinstance(result["data"], dict) and "task_id" in result["data"]:
                    task_id = result["data"]["task_id"]

                if task_id:
                    _log_info(f"ğŸ” æ£€æµ‹åˆ°å¼‚æ­¥ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}")
                    _log_info(f"â³ å¼€å§‹è½®è¯¢ä»»åŠ¡çŠ¶æ€...")

                    # è½®è¯¢ä»»åŠ¡çŠ¶æ€ - ä¼˜åŒ–è½®è¯¢ç­–ç•¥
                    max_polls = 90  # æœ€å¤šè½®è¯¢90æ¬¡ï¼ˆ15åˆ†é’Ÿï¼‰
                    poll_interval = 10  # æ¯10ç§’æŸ¥è¯¢ä¸€æ¬¡

                    for poll_count in range(max_polls):
                        _log_info(f"ğŸ” è½®è¯¢ä»»åŠ¡çŠ¶æ€ ({poll_count + 1}/{max_polls})")

                        status_response = call_video_task_status(api_url, api_key, task_id, api_format)

                        if status_response and status_response.status_code == 200:
                            status_result = status_response.json()
                            _log_info(f"ğŸ” ä»»åŠ¡çŠ¶æ€å“åº”: {str(status_result)[:200]}...")

                            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                            status = status_result.get("status", "unknown")
                            _log_info(f"ğŸ” å½“å‰ä»»åŠ¡çŠ¶æ€: '{status}' (ç±»å‹: {type(status)})")

                            if status.lower() in ["completed", "success", "finished", "succeeded"] or status in ["SUCCESS", "COMPLETED", "FINISHED", "SUCCEEDED"]:
                                # ä»»åŠ¡å®Œæˆï¼Œæå–è§†é¢‘URL
                                _log_info(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼å®Œæ•´å“åº”: {status_result}")
                                video_url = ""

                                # å°è¯•å¤šç§å¯èƒ½çš„URLå­—æ®µä½ç½®
                                if "data" in status_result:
                                    data = status_result["data"]
                                    _log_info(f"ğŸ” dataå­—æ®µå†…å®¹: {data}")
                                    if isinstance(data, list) and len(data) > 0:
                                        video_data = data[0]
                                    else:
                                        video_data = data

                                    if "url" in video_data:
                                        video_url = video_data["url"]
                                    elif "video_url" in video_data:
                                        video_url = video_data["video_url"]
                                    elif "output_url" in video_data:
                                        video_url = video_data["output_url"]
                                    elif "output" in video_data:
                                        video_url = video_data["output"]

                                # æ£€æŸ¥contentå­—æ®µï¼ˆT8é•œåƒç«™æ ¼å¼ï¼‰
                                if not video_url and "content" in status_result:
                                    content = status_result["content"]
                                    _log_info(f"ğŸ” contentå­—æ®µå†…å®¹: {content}")
                                    if "video_url" in content:
                                        video_url = content["video_url"]
                                    elif "url" in content:
                                        video_url = content["url"]

                                # ç›´æ¥åœ¨æ ¹çº§åˆ«æŸ¥æ‰¾URL
                                if not video_url:
                                    if "url" in status_result:
                                        video_url = status_result["url"]
                                    elif "video_url" in status_result:
                                        video_url = status_result["video_url"]
                                    elif "output_url" in status_result:
                                        video_url = status_result["output_url"]
                                    elif "result_url" in status_result:
                                        video_url = status_result["result_url"]

                                _log_info(f"ğŸ” æå–åˆ°çš„è§†é¢‘URL: {video_url}")

                                if video_url:
                                    _log_info(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_url}")

                                    # ä¸‹è½½è§†é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸ºå¼ é‡
                                    video_path = download_video_from_url(video_url)
                                    if video_path:
                                        _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢è§†é¢‘ä¸ºComfyUIå¯¹è±¡...")
                                        video_obj = video_to_comfyui_video(video_path)
                                        if video_obj is not None:
                                            video_info = f"æ¨¡å‹: {model}, æ¨¡å¼: {video_mode}, æ—¶é•¿: {duration}, åˆ†è¾¨ç‡: {resolution}, å®½é«˜æ¯”: {aspect_ratio}, å¸§ç‡: {fps}fps, ä»»åŠ¡ID: {task_id}"
                                            return (video_obj, video_url, "âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ", video_info, video_path)
                                        else:
                                            _log_error("âŒ è§†é¢‘è½¬æ¢å¤±è´¥")
                                            blank_video = create_blank_video_object()
                                            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                            return (blank_video, video_url, "âš ï¸ è§†é¢‘ç”ŸæˆæˆåŠŸä½†è½¬æ¢å¤±è´¥", f"URL: {video_url}", blank_video_path)
                                    else:
                                        _log_error("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                                        blank_video = create_blank_video_object()
                                        blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                        return (blank_video, video_url, "âš ï¸ è§†é¢‘ç”ŸæˆæˆåŠŸä½†ä¸‹è½½å¤±è´¥", f"URL: {video_url}", blank_video_path)
                                else:
                                    _log_error("âŒ ä»»åŠ¡å®Œæˆä½†æœªæ‰¾åˆ°è§†é¢‘URL")
                                    blank_video = create_blank_video_object()
                                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                    return (blank_video, "", "âŒ ä»»åŠ¡å®Œæˆä½†æœªæ‰¾åˆ°è§†é¢‘URL", str(status_result), blank_video_path)

                            elif status in ["failed", "error"]:
                                error_msg = status_result.get("error", "ä»»åŠ¡å¤±è´¥")
                                _log_error(f"âŒ è§†é¢‘ç”Ÿæˆä»»åŠ¡å¤±è´¥: {error_msg}")
                                blank_video = create_blank_video_object()
                                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                return (blank_video, "", f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}", str(status_result), blank_video_path)

                            elif status.lower() in ["running", "processing", "pending", "queued", "not_start"] or status in ["RUNNING", "PROCESSING", "PENDING", "QUEUED", "NOT_START"]:
                                _log_info(f"â³ ä»»åŠ¡è¿›è¡Œä¸­ï¼ŒçŠ¶æ€: {status}")
                                time.sleep(poll_interval)
                                continue

                            else:
                                _log_warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                                time.sleep(poll_interval)
                                continue

                        else:
                            _log_warning(f"âš ï¸ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                            time.sleep(poll_interval)

                    # è½®è¯¢è¶…æ—¶
                    _log_error("âŒ ä»»åŠ¡è½®è¯¢è¶…æ—¶")
                    blank_video = create_blank_video_object()
                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                    return (blank_video, "", "âŒ è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åæŸ¥çœ‹", f"ä»»åŠ¡ID: {task_id}", blank_video_path)

                else:
                    # åŒæ­¥å“åº”ï¼Œç›´æ¥æå–è§†é¢‘URL
                    video_url = ""
                    if "data" in result and len(result["data"]) > 0:
                        video_data = result["data"][0]
                        if "url" in video_data:
                            video_url = video_data["url"]
                        elif "video_url" in video_data:
                            video_url = video_data["video_url"]

                    if video_url:
                        _log_info(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_url}")

                        # ä¸‹è½½è§†é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸ºå¼ é‡
                        video_path = download_video_from_url(video_url)
                        if video_path:
                            _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢è§†é¢‘ä¸ºå¼ é‡...")
                            video_obj = video_to_comfyui_video(video_path)
                            if video_obj is not None:
                                video_info = f"æ¨¡å‹: {model}, æ¨¡å¼: {video_mode}, æ—¶é•¿: {duration}, åˆ†è¾¨ç‡: {resolution}, å®½é«˜æ¯”: {aspect_ratio}, å¸§ç‡: {fps}fps"
                                return (video_obj, video_url, "âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ", video_info, video_path)
                            else:
                                _log_error("âŒ è§†é¢‘è½¬æ¢å¤±è´¥")
                                blank_video = create_blank_video_object()
                                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                return (blank_video, video_url, "âš ï¸ è§†é¢‘ç”ŸæˆæˆåŠŸä½†è½¬æ¢å¤±è´¥", f"URL: {video_url}", blank_video_path)
                        else:
                            _log_error("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                            blank_video = create_blank_video_object()
                            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                            return (blank_video, video_url, "âš ï¸ è§†é¢‘ç”ŸæˆæˆåŠŸä½†ä¸‹è½½å¤±è´¥", f"URL: {video_url}", blank_video_path)
                    else:
                        _log_error("âŒ å“åº”ä¸­æœªæ‰¾åˆ°è§†é¢‘URL")
                        blank_video = create_blank_video_object()
                        blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                        return (blank_video, "", "âŒ å“åº”ä¸­æœªæ‰¾åˆ°è§†é¢‘URL", str(result), blank_video_path)

            except Exception as e:
                _log_error(f"è§£æè§†é¢‘å“åº”å¤±è´¥: {e}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", f"âŒ è§£æå“åº”å¤±è´¥: {str(e)}", "", blank_video_path)

        except Exception as e:
            error_message = f"Video generation failed: {str(e)}"
            _log_error(error_message)
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", f"âŒ {error_message}", "", blank_video_path)

class DoubaoSeedanceContinuousVideoNode:
    """Doubao-Seedanceè¿ç»­è§†é¢‘ç”ŸæˆèŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())

        # ç¡®ä¿mirror_optionsä¸ä¸ºç©º
        if not mirror_options:
            mirror_options = ["volcengine"]

        return {
            "required": {
                "base_prompt": ("STRING", {"multiline": True, "default": "ä¸€ä¸ªç¾ä¸½çš„åœºæ™¯"}),
                "prompts_text": ("STRING", {"multiline": True, "default": "å¥³å­©æŠ±ç€ç‹ç‹¸ï¼Œå¥³å­©çå¼€çœ¼ï¼Œæ¸©æŸ”åœ°çœ‹å‘é•œå¤´\nå¥³å­©å’Œç‹ç‹¸åœ¨è‰åœ°ä¸Šå¥”è·‘ï¼Œé˜³å…‰æ˜åªš\nå¥³å­©å’Œç‹ç‹¸ååœ¨æ ‘ä¸‹ä¼‘æ¯ï¼Œå¥³å­©è½»è½»æŠšæ‘¸ç‹ç‹¸"}),
                "video_count": ("INT", {"default": 3, "min": 1, "max": 10}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "first_video_model": (["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"], {"default": "doubao-seedance-1-0-lite-t2v-250428"}),
                "subsequent_video_model": (["doubao-seedance-1-0-pro-250528", "doubao-seedance-1-0-lite-i2v-250428", "doubao-seedance-1-0-lite-t2v-250428"], {"default": "doubao-seedance-1-0-lite-i2v-250428"}),
                "duration": (["3s", "5s", "10s", "12s"], {"default": "5s"}),
                "resolution": (["480p", "720p", "1080p"], {"default": "720p"}),
                "aspect_ratio": (["16:9", "4:3", "1:1", "3:4", "9:16", "21:9", "adaptive"], {"default": "16:9"}),
                "fps": ([24, 30], {"default": 30}),
                "watermark": ("BOOLEAN", {"default": False}),
                "camera_fixed": ("BOOLEAN", {"default": False}),
                "merge_videos": ("BOOLEAN", {"default": True}),
                "api_key": ("STRING", {"default": ""}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            },
            "optional": {
                "initial_image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "STRING", "STRING", "VIDEO", "VIDEO")
    RETURN_NAMES = ("first_video", "all_video_urls", "response_text", "video_info", "AFVIDEO", "merged_video")
    FUNCTION = "generate_continuous_videos"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 900  # 15åˆ†é’Ÿè¶…æ—¶
        self.max_retries = 3

    def generate_continuous_videos(self, base_prompt, prompts_text, video_count, mirror_site, first_video_model, subsequent_video_model, duration,
                                 resolution, aspect_ratio, fps, watermark=False, camera_fixed=False, merge_videos=True, api_key="", seed=-1, initial_image=None):
        """ç”Ÿæˆè¿ç»­è§†é¢‘åºåˆ—"""

        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")

        # å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™çš„APIæ ¼å¼
        if mirror_site == "t8_mirror" or "t8star.cn" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # å¼ºåˆ¶ä¿®æ­£Comflyé•œåƒç«™çš„APIæ ¼å¼ï¼ˆæ”¯æŒç«å±±å¼•æ“æ ¼å¼ï¼‰
        if mirror_site == "comfly_mirror" or "comfly.chat" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£Comflyé•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")

        if not api_key.strip():
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªæä¾›API Key", "", blank_video_path)

        if not api_url:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªé…ç½®API URL", "", blank_video_path)

        # æ£€æŸ¥APIæ ¼å¼æ”¯æŒ - ç§»é™¤é™åˆ¶ï¼Œæ”¯æŒæ‰€æœ‰é•œåƒç«™
        _log_info(f"ğŸ” è¿ç»­è§†é¢‘APIæ ¼å¼: {api_format}")

        _log_info(f"ğŸ¬ å¼€å§‹ç”Ÿæˆè¿ç»­è§†é¢‘åºåˆ—: {video_count}ä¸ªè§†é¢‘")
        _log_info(f"ğŸ”— ä½¿ç”¨é•œåƒç«™: {mirror_site} ({api_url})")

        try:
            # è§£ææç¤ºè¯åˆ—è¡¨
            if prompts_text.strip():
                prompts = [p.strip() for p in prompts_text.split('\n') if p.strip()]
            else:
                # å¦‚æœæ²¡æœ‰æä¾›å…·ä½“æç¤ºè¯ï¼Œä½¿ç”¨åŸºç¡€æç¤ºè¯
                prompts = [f"{base_prompt} - ç¬¬{i+1}æ®µ" for i in range(video_count)]

            # ç¡®ä¿æç¤ºè¯æ•°é‡åŒ¹é…
            while len(prompts) < video_count:
                prompts.append(f"{base_prompt} - ç¬¬{len(prompts)+1}æ®µ")
            prompts = prompts[:video_count]

            _log_info(f"ğŸ” è¿ç»­è§†é¢‘æç¤ºè¯åˆ—è¡¨: {prompts}")

            # å­˜å‚¨ç”Ÿæˆçš„è§†é¢‘ä¿¡æ¯
            video_urls = []
            video_infos = []
            response_texts = []
            current_image = initial_image

            for i, prompt in enumerate(prompts):
                _log_info(f"ğŸ¬ ç”Ÿæˆç¬¬{i+1}/{video_count}ä¸ªè§†é¢‘: {prompt}")

                # æ ¹æ®æ˜¯ç¬¬ä¸€ä¸ªè§†é¢‘è¿˜æ˜¯åç»­è§†é¢‘é€‰æ‹©æ¨¡å‹
                current_model = first_video_model if i == 0 else subsequent_video_model
                _log_info(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹: {current_model} ({'ç¬¬ä¸€ä¸ªè§†é¢‘' if i == 0 else 'åç»­è§†é¢‘'})")

                # è°ƒç”¨å•ä¸ªè§†é¢‘ç”Ÿæˆ
                video_result = self._generate_single_video_with_last_frame(
                    prompt, api_url, api_key, api_format, current_model, duration, resolution, aspect_ratio,
                    fps, watermark, camera_fixed, seed, current_image
                )

                if video_result is None:
                    _log_error(f"âŒ ç¬¬{i+1}ä¸ªè§†é¢‘ç”Ÿæˆå¤±è´¥")
                    break

                video_obj, video_url, response_text, video_info, last_frame_url = video_result

                if video_url and last_frame_url:
                    video_urls.append(video_url)
                    video_infos.append(video_info)
                    response_texts.append(response_text)

                    _log_info(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘ç”ŸæˆæˆåŠŸ: {video_url}")

                    # ä¸‹è½½å°¾å¸§ä½œä¸ºä¸‹ä¸€ä¸ªè§†é¢‘çš„é¦–å¸§
                    if i < len(prompts) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªè§†é¢‘
                        current_image = self._download_last_frame_as_image(last_frame_url)
                        if current_image is None:
                            _log_error(f"âŒ æ— æ³•ä¸‹è½½ç¬¬{i+1}ä¸ªè§†é¢‘çš„å°¾å¸§ï¼Œåœæ­¢ç”Ÿæˆ")
                            break
                        _log_info(f"ğŸ”„ å·²è·å–ç¬¬{i+1}ä¸ªè§†é¢‘çš„å°¾å¸§ä½œä¸ºç¬¬{i+2}ä¸ªè§†é¢‘çš„é¦–å¸§")
                else:
                    _log_error(f"âŒ ç¬¬{i+1}ä¸ªè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢è¿ç»­ç”Ÿæˆ")
                    break

            # è¿”å›ç»“æœ
            if video_urls:
                # è¿”å›ç¬¬ä¸€ä¸ªè§†é¢‘ä½œä¸ºä¸»è¦ç»“æœï¼Œå…¶ä»–ä¿¡æ¯åˆå¹¶
                combined_urls = "\n".join(video_urls)
                combined_info = f"è¿ç»­ç”Ÿæˆäº†{len(video_urls)}ä¸ªè§†é¢‘:\n" + "\n".join([f"è§†é¢‘{i+1}: {info}" for i, info in enumerate(video_infos)])
                combined_response = "\n".join(response_texts)

                # è¿”å›ç¬¬ä¸€ä¸ªè§†é¢‘å¯¹è±¡
                first_video = self._download_and_convert_video(video_urls[0])
                first_video_path = getattr(first_video, 'file_path', '') if first_video else ''

                # AFVIDEOä½¿ç”¨è·¯å¾„åŒ…è£…å™¨ï¼Œä¸æ ‡å‡†è§†é¢‘èŠ‚ç‚¹ä¿æŒä¸€è‡´
                afvideo = create_video_path_wrapper(first_video_path) if first_video_path else create_blank_video_object()

                # è§†é¢‘åˆå¹¶åŠŸèƒ½
                merged_video = None
                if merge_videos and len(video_urls) > 1:
                    _log_info(f"ğŸ¬ å¼€å§‹åˆå¹¶{len(video_urls)}ä¸ªè¿ç»­è§†é¢‘...")

                    # ä¸‹è½½æ‰€æœ‰è§†é¢‘æ–‡ä»¶
                    all_video_paths = []
                    for i, url in enumerate(video_urls):
                        try:
                            video_path = download_video_from_url(url)
                            if video_path:
                                all_video_paths.append(video_path)
                                _log_info(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘ä¸‹è½½æˆåŠŸ: {video_path}")
                            else:
                                _log_warning(f"âš ï¸ ç¬¬{i+1}ä¸ªè§†é¢‘ä¸‹è½½å¤±è´¥")
                        except Exception as e:
                            _log_warning(f"âš ï¸ ç¬¬{i+1}ä¸ªè§†é¢‘ä¸‹è½½å¼‚å¸¸: {str(e)}")

                    # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘
                    if len(all_video_paths) > 1:
                        merged_path = merge_videos_with_ffmpeg(all_video_paths)
                        if merged_path:
                            merged_video = video_to_comfyui_video(merged_path)
                            if merged_video:
                                merged_video.file_path = merged_path
                                _log_info(f"âœ… è¿ç»­è§†é¢‘åˆå¹¶æˆåŠŸ: {merged_path}")
                            else:
                                _log_error("âŒ åˆå¹¶è§†é¢‘è½¬æ¢ä¸ºComfyUIå¯¹è±¡å¤±è´¥")
                        else:
                            _log_error("âŒ è§†é¢‘åˆå¹¶å¤±è´¥")
                    else:
                        _log_warning("âš ï¸ å¯ç”¨è§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— æ³•åˆå¹¶")

                # å¦‚æœæ²¡æœ‰åˆå¹¶æˆ–åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘ä½œä¸ºmerged_video
                if not merged_video:
                    merged_video = first_video

                return (first_video, combined_urls, combined_response, combined_info, afvideo, merged_video)
            else:
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                afvideo = create_video_path_wrapper(blank_video_path) if blank_video_path else create_blank_video_object()
                return (blank_video, "", "âŒ è¿ç»­è§†é¢‘ç”Ÿæˆå¤±è´¥", "", afvideo, blank_video)

        except Exception as e:
            error_message = f"è¿ç»­è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}"
            _log_error(error_message)
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            afvideo = create_video_path_wrapper(blank_video_path) if blank_video_path else create_blank_video_object()
            return (blank_video, "", f"âŒ {error_message}", "", afvideo, blank_video)

    def _generate_single_video_with_last_frame(self, prompt, api_url, api_key, api_format, model, duration, resolution,
                                              aspect_ratio, fps, watermark, camera_fixed, seed, input_image=None):
        """ç”Ÿæˆå•ä¸ªè§†é¢‘å¹¶è¿”å›å°¾å¸§URL"""
        try:
            _log_info(f"ğŸ”§ æ„å»º{api_format}æ ¼å¼çš„è¿ç»­è§†é¢‘payload")

            if api_format == "volcengine":
                # ç«å±±å¼•æ“æ ¼å¼ï¼šä½¿ç”¨contentæ•°ç»„
                text_content = f"{prompt} --rt {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"

                content = [{"type": "text", "text": text_content}]

                # æ·»åŠ è¾“å…¥å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
                if input_image is not None:
                    image_data_url = image_to_base64(input_image, return_data_url=True)
                    if image_data_url:
                        content.append({
                            "type": "image_url",
                            "image_url": {"url": image_data_url}
                        })

                payload = {
                    "model": model,
                    "content": content,
                    "return_last_frame": True  # å…³é”®å‚æ•°ï¼šè¿”å›å°¾å¸§
                }

            else:
                # Comfly/T8æ ¼å¼ï¼šä½¿ç”¨ç›´æ¥å‚æ•°
                payload = {
                    "prompt": prompt,
                    "model": model,
                    "duration": int(duration.replace('s', '')),
                    "resolution": resolution,
                    "ratio": aspect_ratio,
                    "watermark": watermark,
                    "return_last_frame": True  # å…³é”®å‚æ•°ï¼šè¿”å›å°¾å¸§
                }

                # æ·»åŠ ç§å­
                if seed != -1:
                    payload["seed"] = seed

                # æ·»åŠ è¾“å…¥å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
                if input_image is not None:
                    image_data_url = image_to_base64(input_image, return_data_url=True)
                    if image_data_url:
                        payload["images"] = [image_data_url]

                # T8é•œåƒç«™ç‰¹æ®Šå‚æ•°
                if "t8star.cn" in api_url:
                    payload["01K3ZARVMSZ97JPXNWXBCJGG6K"] = ""

            # è°ƒç”¨API
            response = call_video_api(api_url, api_key, payload, api_format, timeout=self.timeout)

            # å¤„ç†å“åº” - call_video_apiè¿”å›çš„æ˜¯requests.Responseå¯¹è±¡
            if response and response.status_code == 200:
                try:
                    response_data = response.json()
                    _log_info(f"ğŸ” è¿ç»­è§†é¢‘APIå“åº”: {response_data}")
                except Exception as json_e:
                    _log_error(f"âŒ å“åº”JSONè§£æå¤±è´¥: {json_e}")
                    return None
            else:
                _log_error(f"âŒ APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code if response else 'None'}")
                return None

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚æ­¥ä»»åŠ¡å“åº”
            task_id = None
            if "task_id" in response_data:
                task_id = response_data["task_id"]
            elif "id" in response_data:
                task_id = response_data["id"]
            elif "data" in response_data and isinstance(response_data["data"], dict) and "task_id" in response_data["data"]:
                task_id = response_data["data"]["task_id"]

            if task_id:
                _log_info(f"ğŸ” æ£€æµ‹åˆ°å¼‚æ­¥ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}")
                _log_info(f"â³ å¼€å§‹è½®è¯¢ä»»åŠ¡çŠ¶æ€...")

                # è½®è¯¢ä»»åŠ¡çŠ¶æ€
                max_polls = 90  # æœ€å¤šè½®è¯¢90æ¬¡ï¼ˆ15åˆ†é’Ÿï¼‰
                poll_interval = 10  # æ¯10ç§’æŸ¥è¯¢ä¸€æ¬¡

                for poll_count in range(max_polls):
                    _log_info(f"ğŸ” è½®è¯¢ä»»åŠ¡çŠ¶æ€ ({poll_count + 1}/{max_polls})")

                    status_response = call_video_task_status(api_url, api_key, task_id, api_format)

                    if status_response and status_response.status_code == 200:
                        status_result = status_response.json()
                        _log_info(f"ğŸ” ä»»åŠ¡çŠ¶æ€å“åº”: {str(status_result)[:200]}...")

                        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                        status = status_result.get("status", "unknown")
                        _log_info(f"ğŸ” å½“å‰ä»»åŠ¡çŠ¶æ€: '{status}' (ç±»å‹: {type(status)})")

                        if status.lower() in ["completed", "success", "finished", "succeeded"] or status in ["COMPLETED", "SUCCESS", "FINISHED", "SUCCEEDED"]:
                            _log_info(f"âœ… è¿ç»­è§†é¢‘ä»»åŠ¡å®Œæˆ: {status}")
                            # ä½¿ç”¨status_resultä½œä¸ºæœ€ç»ˆå“åº”æ•°æ®
                            response_data = status_result
                            break

                        elif status.lower() in ["failed", "error"] or status in ["FAILED", "ERROR"]:
                            _log_error(f"âŒ è¿ç»­è§†é¢‘ä»»åŠ¡å¤±è´¥: {status}")
                            return None

                        elif status.lower() in ["running", "processing", "pending", "queued", "not_start"] or status in ["RUNNING", "PROCESSING", "PENDING", "QUEUED", "NOT_START"]:
                            _log_info(f"â³ ä»»åŠ¡è¿›è¡Œä¸­ï¼ŒçŠ¶æ€: {status}")
                            time.sleep(poll_interval)
                            continue

                        else:
                            _log_warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                            time.sleep(poll_interval)
                            continue

                    else:
                        _log_warning(f"âš ï¸ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                        time.sleep(poll_interval)

                # è½®è¯¢è¶…æ—¶
                if poll_count >= max_polls - 1:
                    _log_error("âŒ è¿ç»­è§†é¢‘ä»»åŠ¡è½®è¯¢è¶…æ—¶")
                    return None

            # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
            if response_data and (response_data.get('status', '').lower() in ['completed', 'success', 'finished', 'succeeded'] or response_data.get('status') in ['COMPLETED', 'SUCCESS', 'FINISHED', 'SUCCEEDED']):
                video_url = None
                last_frame_url = None

                # æ ¹æ®APIæ ¼å¼æå–è§†é¢‘URLå’Œå°¾å¸§URL
                if api_format == "volcengine":
                    # ç«å±±å¼•æ“æ ¼å¼
                    if 'content' in response_data:
                        content_data = response_data['content']
                        video_url = content_data.get('video_url')
                        last_frame_url = content_data.get('last_frame_url')
                elif api_format == "comfly":
                    # Comflyæ ¼å¼ - æ”¯æŒå¤šç§å“åº”æ ¼å¼
                    # æ ¼å¼1: data.output (Comflyè¿ç»­è§†é¢‘æ ¼å¼)
                    if 'data' in response_data and isinstance(response_data['data'], dict):
                        if 'output' in response_data['data']:
                            video_url = response_data['data']['output']
                            last_frame_url = response_data['data'].get('last_frame_url', '')
                        elif 'content' in response_data['data'] and isinstance(response_data['data']['content'], dict):
                            video_url = response_data['data']['content'].get('video_url')
                            last_frame_url = response_data['data']['content'].get('last_frame_url')

                    # æ ¼å¼2: content.video_url (æ ‡å‡†æ ¼å¼)
                    if not video_url and 'content' in response_data:
                        content_data = response_data['content']
                        video_url = content_data.get('video_url')
                        last_frame_url = content_data.get('last_frame_url')

                    # æ ¼å¼3: ç›´æ¥åœ¨responseä¸­
                    if not video_url:
                        video_url = response_data.get('video_url')
                        last_frame_url = response_data.get('last_frame_url')

                if video_url and last_frame_url:
                    # ä¸‹è½½å¹¶è½¬æ¢è§†é¢‘
                    video_obj = self._download_and_convert_video(video_url)

                    video_info = f"è§†é¢‘å°ºå¯¸: {resolution}, æ—¶é•¿: {duration}, å®½é«˜æ¯”: {aspect_ratio}"
                    response_text = f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ"

                    return (video_obj, video_url, response_text, video_info, last_frame_url)
                else:
                    _log_error(f"âŒ æ— æ³•ä»å“åº”ä¸­æå–è§†é¢‘URLæˆ–å°¾å¸§URL")
                    _log_info(f"ğŸ” å“åº”ç»“æ„: {response_data}")

            _log_error(f"âŒ å•ä¸ªè§†é¢‘ç”Ÿæˆå¤±è´¥æˆ–ä¸æ”¯æŒreturn_last_frameåŠŸèƒ½")
            return None

        except Exception as e:
            _log_error(f"âŒ å•ä¸ªè§†é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return None

    def _download_last_frame_as_image(self, last_frame_url):
        """ä¸‹è½½å°¾å¸§URLå¹¶è½¬æ¢ä¸ºå›¾åƒtensor"""
        try:
            import requests
            import numpy as np
            from PIL import Image
            import io

            _log_info(f"ğŸ”½ ä¸‹è½½å°¾å¸§å›¾åƒ: {last_frame_url}")

            # ä¸‹è½½å›¾åƒ
            response = requests.get(last_frame_url, timeout=30)
            response.raise_for_status()

            # è½¬æ¢ä¸ºPILå›¾åƒ
            image = Image.open(io.BytesIO(response.content))
            image = image.convert('RGB')

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_array = np.array(image).astype(np.float32) / 255.0

            # è½¬æ¢ä¸ºComfyUIæ ¼å¼çš„tensor (1, H, W, 3)
            if len(image_array.shape) == 3:
                image_tensor = image_array[np.newaxis, ...]  # æ·»åŠ batchç»´åº¦
            else:
                image_tensor = image_array

            _log_info(f"âœ… å°¾å¸§å›¾åƒä¸‹è½½æˆåŠŸï¼Œå°ºå¯¸: {image_tensor.shape}")
            return image_tensor

        except Exception as e:
            _log_error(f"âŒ ä¸‹è½½å°¾å¸§å›¾åƒå¤±è´¥: {str(e)}")
            return None

    def _download_and_convert_video(self, video_url):
        """ä¸‹è½½è§†é¢‘å¹¶è½¬æ¢ä¸ºComfyUIå¯¹è±¡"""
        try:
            # å¤ç”¨ç°æœ‰çš„è§†é¢‘ä¸‹è½½å’Œè½¬æ¢é€»è¾‘
            video_path = download_video_from_url(video_url)
            if video_path:
                video_obj = video_to_comfyui_video(video_path)
                if video_obj:
                    # ä¸ºvideoå¯¹è±¡æ·»åŠ file_pathå±æ€§
                    video_obj.file_path = video_path
                    return video_obj
            return None
        except Exception as e:
            _log_error(f"âŒ è§†é¢‘ä¸‹è½½è½¬æ¢å¤±è´¥: {str(e)}")
            return None

class DoubaoSeedanceMultiRefVideoNode:
    """Doubao-Seedanceå¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆèŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())

        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "ä¸€ä¸ªç¾ä¸½çš„åœºæ™¯ï¼ŒåŒ…å«[å›¾1]å’Œ[å›¾2]çš„å…ƒç´ "}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedance-1-0-lite-i2v-250428"], {"default": "doubao-seedance-1-0-lite-i2v-250428"}),
                "duration": (["3s", "5s", "10s", "12s"], {"default": "5s"}),
                "resolution": (["480p", "720p"], {"default": "720p"}),
                "aspect_ratio": (["16:9", "4:3", "1:1", "3:4", "9:16", "21:9", "adaptive"], {"default": "16:9"}),
                "fps": ([24, 30], {"default": 30}),
                "watermark": ("BOOLEAN", {"default": False}),
                "camera_fixed": ("BOOLEAN", {"default": False}),
                "api_key": ("STRING", {"default": ""}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            },
            "optional": {
                "reference_image_1": ("IMAGE",),
                "reference_image_2": ("IMAGE",),
                "reference_image_3": ("IMAGE",),
                "reference_image_4": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "STRING", "STRING", "VIDEO")
    RETURN_NAMES = ("video", "video_url", "response_text", "video_info", "AFVIDEO")
    FUNCTION = "generate_multi_ref_video"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 900  # 15åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
        self.max_retries = 3

    def generate_multi_ref_video(self, prompt, mirror_site, model, duration, resolution, aspect_ratio, fps, watermark=False, camera_fixed=False, api_key="", seed=-1,
                                reference_image_1=None, reference_image_2=None, reference_image_3=None, reference_image_4=None):
        """ç”Ÿæˆå¤šå›¾å‚è€ƒè§†é¢‘"""

        # æ”¶é›†å‚è€ƒå›¾ç‰‡
        reference_images = []
        if reference_image_1 is not None:
            reference_images.append(reference_image_1)
        if reference_image_2 is not None:
            reference_images.append(reference_image_2)
        if reference_image_3 is not None:
            reference_images.append(reference_image_3)
        if reference_image_4 is not None:
            reference_images.append(reference_image_4)

        if not reference_images:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        if len(reference_images) > 4:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœ€å¤šæ”¯æŒ4å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆ: å‚è€ƒå›¾ç‰‡æ•°é‡={len(reference_images)}")

        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")

        # å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™çš„APIæ ¼å¼ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
        if mirror_site == "t8_mirror" or "t8star.cn" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")

        if not api_key.strip():
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªæä¾›API Key", "", blank_video_path)

        try:
            # å¤šå›¾å‚è€ƒæ”¯æŒç«å±±å¼•æ“æ ¼å¼å’ŒComflyå®˜æ–¹æ ¼å¼
            if api_format not in ["volcengine", "comfly"]:
                _log_warning(f"âš ï¸ å¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å’ŒComflyæ ¼å¼ï¼Œå½“å‰æ ¼å¼: {api_format}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šå¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å®˜æ–¹ã€T8é•œåƒç«™å’ŒComflyé•œåƒç«™", "", blank_video_path)

            # æ„å»ºç»Ÿä¸€çš„contentæ•°ç»„æ ¼å¼ï¼ˆç«å±±å¼•æ“å’ŒComflyå®˜æ–¹æ ¼å¼ç›¸åŒï¼‰
            _log_info(f"ğŸ”§ æ„å»ºå¤šå›¾å‚è€ƒ{api_format}æ ¼å¼payload")

            # æ„å»ºæ–‡æœ¬å†…å®¹
            if api_format == "volcengine":
                # ç«å±±å¼•æ“æ ¼å¼ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
                text_content = f"{prompt} --rt {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")
            else:  # api_format == "comfly"
                # Comflyå®˜æ–¹æ ¼å¼ï¼šä¹Ÿä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¸ç«å±±å¼•æ“ç›¸åŒï¼‰
                text_content = f"{prompt} --ratio {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ Comflyå®˜æ–¹å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")

            content = [
                {
                    "type": "text",
                    "text": text_content
                }
            ]

            # æ·»åŠ å‚è€ƒå›¾ç‰‡åˆ°contentæ•°ç»„
            for i, ref_image in enumerate(reference_images, 1):
                _log_info(f"ğŸ” å¤„ç†å‚è€ƒå›¾ç‰‡ {i}: {ref_image.shape}")

                # ç»Ÿä¸€ä½¿ç”¨å®Œæ•´çš„Data URLæ ¼å¼
                image_data_url = image_to_base64(ref_image, return_data_url=True)
                if image_data_url:
                    image_content = {
                        "type": "image_url",
                        "image_url": {
                            "url": image_data_url
                        }
                    }

                    # å¤šå›¾å‚è€ƒç»Ÿä¸€ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ï¼Œéƒ½éœ€è¦roleå­—æ®µ
                    image_content["role"] = "reference_image"

                    content.append(image_content)
                    _log_info(f"ğŸ”§ æ·»åŠ å‚è€ƒå›¾ç‰‡{i}åˆ°content (Data URLé•¿åº¦: {len(image_data_url)})")
                else:
                    _log_error(f"âŒ å‚è€ƒå›¾ç‰‡{i} Data URLç¼–ç å¤±è´¥")

            # æ„å»ºpayload
            payload = {
                "model": model,
                "content": content
            }

            _log_info(f"ğŸ” å¤šå›¾å‚è€ƒpayloadæ„å»ºå®Œæˆ: æ ¼å¼={api_format}, æ¨¡å‹={model}, contentæ•°é‡={len(content)}")

            # è°ƒç”¨å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPIï¼ˆä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹ï¼‰
            response = call_multi_ref_video_api(api_url, api_key, payload, api_format, self.timeout)

            if not response or response.status_code != 200:
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šè§†é¢‘ç”Ÿæˆä»»åŠ¡åˆ›å»ºå¤±è´¥", "", blank_video_path)

            # ä»å“åº”ä¸­æå–ä»»åŠ¡ID
            try:
                result = response.json()
                task_id = None

                # ç«å±±å¼•æ“æ ¼å¼çš„ä»»åŠ¡IDæå–
                if "id" in result:
                    task_id = result["id"]
                elif "task_id" in result:
                    task_id = result["task_id"]
                elif "data" in result and isinstance(result["data"], dict):
                    if "id" in result["data"]:
                        task_id = result["data"]["id"]
                    elif "task_id" in result["data"]:
                        task_id = result["data"]["task_id"]

                if not task_id:
                    _log_error(f"âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»åŠ¡ID: {result}")
                    blank_video = create_blank_video_object()
                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                    return (blank_video, "", "âŒ é”™è¯¯ï¼šæ— æ³•è·å–ä»»åŠ¡ID", "", blank_video_path)

                _log_info(f"ğŸ¬ å¤šå›¾å‚è€ƒè§†é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")

            except Exception as e:
                _log_error(f"âŒ è§£æä»»åŠ¡åˆ›å»ºå“åº”å¤±è´¥: {e}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", f"âŒ é”™è¯¯ï¼šè§£æå“åº”å¤±è´¥: {str(e)}", "", blank_video_path)

            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            max_polls = 90  # 15åˆ†é’Ÿï¼Œæ¯10ç§’è½®è¯¢ä¸€æ¬¡
            poll_interval = 10

            for poll_count in range(1, max_polls + 1):
                _log_info(f"ğŸ” è½®è¯¢ä»»åŠ¡çŠ¶æ€ ({poll_count}/{max_polls})")

                status_response = call_video_task_status(api_url, api_key, task_id, api_format)
                status_result = None
                if status_response and status_response.status_code == 200:
                    status_result = status_response.json()
                    _log_info(f"ğŸ” ä»»åŠ¡çŠ¶æ€å“åº”: {str(status_result)[:200]}...")

                if status_result:
                    status = status_result.get('status', 'unknown')
                    _log_info(f"ğŸ” å½“å‰ä»»åŠ¡çŠ¶æ€: '{status}' (ç±»å‹: {type(status)})")

                    if status.lower() in ["completed", "success", "finished", "succeeded"] or status in ["SUCCESS", "COMPLETED", "FINISHED", "SUCCEEDED"]:
                        _log_info(f"âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ")

                        # è·å–è§†é¢‘URL - æ”¯æŒå¤šç§å“åº”æ ¼å¼
                        video_url = None

                        # æ ¼å¼1: data.content.video_url (Comflyå¤šå›¾å‚è€ƒæ ¼å¼)
                        if 'data' in status_result and isinstance(status_result['data'], dict):
                            if 'content' in status_result['data'] and isinstance(status_result['data']['content'], dict):
                                if 'video_url' in status_result['data']['content']:
                                    video_url = status_result['data']['content']['video_url']

                        # æ ¼å¼2: content.video_url (ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ ¼å¼)
                        if not video_url and 'content' in status_result and isinstance(status_result['content'], dict):
                            if 'video_url' in status_result['content']:
                                video_url = status_result['content']['video_url']

                        # æ ¼å¼3: video_resultæ•°ç»„æ ¼å¼
                        if not video_url and 'video_result' in status_result and status_result['video_result']:
                            video_result = status_result['video_result'][0] if isinstance(status_result['video_result'], list) else status_result['video_result']
                            video_url = video_result.get('url')

                        # æ ¼å¼4: ç›´æ¥video_urlå­—æ®µ
                        if not video_url and 'video_url' in status_result:
                            video_url = status_result['video_url']

                        # æ ¼å¼4: result.video_urlæ ¼å¼
                        if not video_url and 'result' in status_result and status_result['result']:
                            result = status_result['result']
                            if isinstance(result, dict) and 'video_url' in result:
                                video_url = result['video_url']
                                _log_info(f"ğŸ” ä»result.video_urlæå–è§†é¢‘URL")

                        if video_url:
                            _log_info(f"ğŸ¬ è·å–åˆ°è§†é¢‘URL: {video_url}")

                            # ä¸‹è½½å¹¶è½¬æ¢è§†é¢‘
                            video_path = download_video_from_url(video_url)
                            if video_path:
                                _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢è§†é¢‘ä¸ºComfyUIå¯¹è±¡...")
                                video_obj = video_to_comfyui_video(video_path)
                                if video_obj is not None:
                                    video_info = f"æ¨¡å‹: {model}, å‚è€ƒå›¾ç‰‡: {len(reference_images)}å¼ , æ—¶é•¿: {duration}, åˆ†è¾¨ç‡: {resolution}, å®½é«˜æ¯”: {aspect_ratio}, å¸§ç‡: {fps}fps, ä»»åŠ¡ID: {task_id}"
                                    return (video_obj, video_url, "âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ", video_info, video_path)
                                else:
                                    _log_error("âŒ è§†é¢‘è½¬æ¢å¤±è´¥")
                                    blank_video = create_blank_video_object()
                                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                    return (blank_video, video_url, "âŒ è§†é¢‘è½¬æ¢å¤±è´¥", "", blank_video_path)
                            else:
                                _log_error("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                                blank_video = create_blank_video_object()
                                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                return (blank_video, video_url, "âŒ è§†é¢‘ä¸‹è½½å¤±è´¥", "", blank_video_path)
                        else:
                            _log_error("âŒ æœªè·å–åˆ°è§†é¢‘URL")
                            blank_video = create_blank_video_object()
                            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                            return (blank_video, "", "âŒ æœªè·å–åˆ°è§†é¢‘URL", "", blank_video_path)

                    elif status.lower() in ["failed", "error"] or status in ["FAILED", "ERROR"]:
                        fail_reason = status_result.get('fail_reason', 'æœªçŸ¥é”™è¯¯')
                        _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}")
                        blank_video = create_blank_video_object()
                        blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                        return (blank_video, "", f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}", "", blank_video_path)

                    elif status.lower() in ["running", "processing", "in_progress", "not_start", "queued"] or status in ["RUNNING", "PROCESSING", "IN_PROGRESS", "NOT_START", "QUEUED"]:
                        _log_info(f"â³ ä»»åŠ¡è¿›è¡Œä¸­ï¼ŒçŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                    else:
                        _log_warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                else:
                    _log_warning(f"âš ï¸ æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€ï¼Œå“åº”: {status_response}")
                    if poll_count < max_polls:
                        time.sleep(poll_interval)
                    continue

            # è¶…æ—¶å¤„ç†
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆè¶…æ—¶")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ è§†é¢‘ç”Ÿæˆè¶…æ—¶", "", blank_video_path)

        except Exception as e:
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", f"âŒ é”™è¯¯ï¼š{str(e)}", "", blank_video_path)

class VideoStitchingNode:
    """è§†é¢‘æ‹¼æ¥èŠ‚ç‚¹ - æœ€å¤šå¯ä»¥å°†8ä¸ªè§†é¢‘æ‹¼æ¥åœ¨ä¸€èµ·"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video1": ("VIDEO",),
            },
            "optional": {
                "video2": ("VIDEO",),
                "video3": ("VIDEO",),
                "video4": ("VIDEO",),
                "video5": ("VIDEO",),
                "video6": ("VIDEO",),
                "video7": ("VIDEO",),
                "video8": ("VIDEO",),
                "output_filename": ("STRING", {"default": ""}),
                "stitch_method": (["concat", "concat_crossfade", "concat_advanced", "concat_morph", "concat_optical_flow", "hstack", "vstack", "grid2x2", "grid2x3", "grid2x4"], {"default": "concat"}),
                "output_quality": (["high", "medium", "low"], {"default": "high"}),
                "scale_videos": ("BOOLEAN", {"default": True}),
                "smooth_transitions": ("BOOLEAN", {"default": True}),
                "transition_duration": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.1}),
                "force_keyframes": ("BOOLEAN", {"default": True}),
                "transition_type": (["fade", "wipeleft", "wiperight", "wipeup", "wipedown", "slideleft", "slideright", "slideup", "slidedown", "smoothleft", "smoothright", "smoothup", "smoothdown", "circleopen", "circleclose", "vertopen", "vertclose", "horzopen", "horzclose", "dissolve", "pixelize", "radial", "smoothradial"], {"default": "fade"}),
                "motion_compensation": ("BOOLEAN", {"default": False}),
                "edge_enhancement": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "VIDEO")
    RETURN_NAMES = ("stitched_video", "video_path", "AFVIDEO")
    FUNCTION = "stitch_videos"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘å¤„ç†éœ€è¦æ›´é•¿æ—¶é—´

    def stitch_videos(self, video1, video2=None, video3=None, video4=None, video5=None, video6=None, video7=None, video8=None,
                     output_filename="", stitch_method="concat", output_quality="high", scale_videos=True,
                     smooth_transitions=True, transition_duration=0.5, force_keyframes=True, transition_type="fade",
                     motion_compensation=False, edge_enhancement=False):
        """
        æ‹¼æ¥å¤šä¸ªè§†é¢‘

        Args:
            video1-video8: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            stitch_method: æ‹¼æ¥æ–¹æ³•
            output_quality: è¾“å‡ºè´¨é‡
            scale_videos: æ˜¯å¦ç¼©æ”¾è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸

        Returns:
            tuple: (æ‹¼æ¥åçš„VIDEOå¯¹è±¡, è§†é¢‘æ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹è§†é¢‘æ‹¼æ¥...")

            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„è§†é¢‘
            videos = [video1]
            for video in [video2, video3, video4, video5, video6, video7, video8]:
                if video is not None:
                    videos.append(video)

            if len(videos) < 2:
                error_msg = "è‡³å°‘éœ€è¦2ä¸ªè§†é¢‘æ‰èƒ½è¿›è¡Œæ‹¼æ¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            _log_info(f"ğŸ“Š å°†æ‹¼æ¥{len(videos)}ä¸ªè§†é¢‘ï¼Œä½¿ç”¨{stitch_method}æ–¹æ³•")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„
            video_paths = []
            for i, video in enumerate(videos):
                _log_info(f"ğŸ” å¤„ç†ç¬¬{i+1}ä¸ªè§†é¢‘...")
                video_path = self._extract_video_path(video)
                if not video_path:
                    error_msg = f"æ— æ³•è·å–ç¬¬{i+1}ä¸ªè§†é¢‘çš„æœ‰æ•ˆè·¯å¾„: {video_path}"
                    _log_error(error_msg)
                    _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                    return self._create_error_result(error_msg)

                if not os.path.exists(video_path):
                    error_msg = f"ç¬¬{i+1}ä¸ªè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                    _log_error(error_msg)
                    return self._create_error_result(error_msg)

                video_paths.append(video_path)
                _log_info(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                output_filename = f"stitched_video_{stitch_method}_{int(time.time())}.mp4"

            if not output_filename.lower().endswith('.mp4'):
                output_filename += '.mp4'

            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•è€Œä¸æ˜¯ç³»ç»Ÿä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
                _log_info(f"ğŸ“ ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
            except ImportError:
                # å¦‚æœåœ¨ComfyUIç¯å¢ƒå¤–ï¼Œå°è¯•æ¨æ–­ComfyUIè·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None

                # å‘ä¸ŠæŸ¥æ‰¾ComfyUIæ ¹ç›®å½•
                path_parts = current_dir.split(os.sep)
                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")) and \
                       os.path.exists(os.path.join(potential_root, "nodes.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                    _log_info(f"ğŸ“ æ¨æ–­ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
                    _log_info(f"ğŸ“ å›é€€åˆ°ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir}")
            except Exception as e:
                import tempfile
                output_dir = tempfile.gettempdir()
                _log_info(f"ğŸ“ å¼‚å¸¸ï¼Œä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir} (é”™è¯¯: {e})")

            output_path = os.path.join(output_dir, output_filename)

            # æ ¹æ®æ‹¼æ¥æ–¹æ³•æ‰§è¡Œä¸åŒçš„å¤„ç†
            success = False
            if stitch_method == "concat":
                success = self._concat_videos(video_paths, output_path, output_quality, smooth_transitions, transition_duration, force_keyframes)
            elif stitch_method == "concat_crossfade":
                if len(video_paths) <= 2:
                    success = self._concat_with_crossfade_transitions(video_paths, output_path, output_quality, transition_duration)
                else:
                    success = self._concat_with_xfade_multiple(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "concat_advanced":
                success = self._concat_with_advanced_transitions(video_paths, output_path, output_quality, transition_duration, transition_type, motion_compensation, edge_enhancement)
            elif stitch_method == "concat_morph":
                success = self._concat_with_morphing_transitions(video_paths, output_path, output_quality, transition_duration, motion_compensation)
            elif stitch_method == "concat_optical_flow":
                success = self._concat_with_optical_flow_transitions(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "hstack":
                success = self._hstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "vstack":
                success = self._vstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "grid2x2":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x2", scale_videos)
            elif stitch_method == "grid2x3":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x3", scale_videos)
            elif stitch_method == "grid2x4":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x4", scale_videos)

            if not success:
                error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥ï¼Œæ–¹æ³•: {stitch_method}"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            # è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡
            stitched_video = video_to_comfyui_video(output_path)
            if stitched_video:
                stitched_video.file_path = output_path
                _log_info(f"âœ… è§†é¢‘æ‹¼æ¥æˆåŠŸ: {output_path}")

                # AFVIDEOä½¿ç”¨è·¯å¾„åŒ…è£…å™¨ï¼Œä¸æ ‡å‡†è§†é¢‘èŠ‚ç‚¹ä¿æŒä¸€è‡´
                afvideo = create_video_path_wrapper(output_path) if output_path else create_blank_video_object()

                return (stitched_video, output_path, afvideo)
            else:
                error_msg = "æ‹¼æ¥è§†é¢‘è½¬æ¢ä¸ºComfyUIå¯¹è±¡å¤±è´¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

        except Exception as e:
            error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            return self._create_error_result(error_msg)

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _get_quality_params(self, quality):
        """è·å–è´¨é‡å‚æ•°"""
        quality_settings = {
            "high": ["-crf", "18", "-preset", "medium"],
            "medium": ["-crf", "23", "-preset", "fast"],
            "low": ["-crf", "28", "-preset", "faster"]
        }
        return quality_settings.get(quality, quality_settings["high"])

    def _concat_videos(self, video_paths, output_path, quality, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """è¿ç»­æ‹¼æ¥è§†é¢‘ï¼ˆæ—¶é—´è½´ä¸Šè¿æ¥ï¼‰- æ”¹è¿›ç‰ˆæœ¬å‡å°‘é—ªçƒ"""
        try:
            import subprocess
            import tempfile

            _log_info("ğŸ”— ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            # é¦–å…ˆæ£€æŸ¥è§†é¢‘å±æ€§ä¸€è‡´æ€§
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§")
                return False

            # åˆ›å»ºconcatæ–‡ä»¶åˆ—è¡¨ - ä½¿ç”¨åˆé€‚çš„ä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                temp_dir = folder_paths.get_temp_directory()
            except:
                import tempfile
                temp_dir = tempfile.gettempdir()
            concat_file = os.path.join(temp_dir, f"concat_list_{int(time.time())}.txt")

            with open(concat_file, 'w', encoding='utf-8') as f:
                for video_path in video_paths:
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                    abs_path = os.path.abspath(video_path).replace('\\', '/')
                    f.write(f"file '{abs_path}'\n")

            # æ ¹æ®è§†é¢‘å±æ€§ä¸€è‡´æ€§é€‰æ‹©å¤„ç†æ–¹å¼
            if video_info['consistent']:
                # å±æ€§ä¸€è‡´ï¼Œå°è¯•ç›´æ¥å¤åˆ¶æµï¼ˆæœ€å¿«ï¼Œæ— è´¨é‡æŸå¤±ï¼‰
                success = self._concat_with_copy(concat_file, output_path)
                if success:
                    self._cleanup_temp_file(concat_file)
                    return True
                _log_info("ğŸ”„ ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œå°è¯•é‡æ–°ç¼–ç ...")

            # å±æ€§ä¸ä¸€è‡´æˆ–ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›çš„é‡æ–°ç¼–ç æ–¹æ³•
            success = self._concat_with_smooth_transitions(concat_file, output_path, quality, video_info, smooth_transitions, transition_duration, force_keyframes)

            self._cleanup_temp_file(concat_file)
            return success

        except Exception as e:
            _log_error(f"concatæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _analyze_video_properties(self, video_paths):
        """åˆ†æè§†é¢‘å±æ€§ï¼Œæ£€æŸ¥ä¸€è‡´æ€§"""
        try:
            import subprocess
            import json

            _log_info("ğŸ” åˆ†æè§†é¢‘å±æ€§...")

            video_props = []
            for video_path in video_paths:
                # ä½¿ç”¨ffprobeè·å–è§†é¢‘ä¿¡æ¯
                cmd = [
                    'ffprobe',
                    '-v', 'quiet',
                    '-print_format', 'json',
                    '-show_streams',
                    '-select_streams', 'v:0',
                    video_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                if result.returncode != 0:
                    _log_error(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_path}")
                    return None

                try:
                    info = json.loads(result.stdout)
                    if 'streams' in info and len(info['streams']) > 0:
                        stream = info['streams'][0]
                        props = {
                            'width': stream.get('width', 0),
                            'height': stream.get('height', 0),
                            'fps': eval(stream.get('r_frame_rate', '0/1')),
                            'codec': stream.get('codec_name', ''),
                            'pix_fmt': stream.get('pix_fmt', '')
                        }
                        video_props.append(props)
                        _log_info(f"ğŸ“Š {os.path.basename(video_path)}: {props['width']}x{props['height']} @{props['fps']:.2f}fps {props['codec']}")
                    else:
                        _log_error(f"æ— æ³•è§£æè§†é¢‘æµä¿¡æ¯: {video_path}")
                        return None
                except json.JSONDecodeError:
                    _log_error(f"æ— æ³•è§£æffprobeè¾“å‡º: {video_path}")
                    return None

            # æ£€æŸ¥å±æ€§ä¸€è‡´æ€§
            if not video_props:
                return None

            first_props = video_props[0]
            consistent = all(
                props['width'] == first_props['width'] and
                props['height'] == first_props['height'] and
                abs(props['fps'] - first_props['fps']) < 0.1 and
                props['codec'] == first_props['codec'] and
                props['pix_fmt'] == first_props['pix_fmt']
                for props in video_props
            )

            _log_info(f"âœ… è§†é¢‘å±æ€§ä¸€è‡´æ€§: {'æ˜¯' if consistent else 'å¦'}")

            return {
                'consistent': consistent,
                'properties': video_props,
                'target_width': first_props['width'],
                'target_height': first_props['height'],
                'target_fps': first_props['fps'],
                'target_codec': first_props['codec'],
                'target_pix_fmt': first_props['pix_fmt']
            }

        except Exception as e:
            _log_error(f"åˆ†æè§†é¢‘å±æ€§å¤±è´¥: {str(e)}")
            return None

    def _concat_with_copy(self, concat_file, output_path):
        """ä½¿ç”¨æµå¤åˆ¶æ–¹å¼æ‹¼æ¥ï¼ˆæœ€å¿«ï¼Œé€‚ç”¨äºå±æ€§ä¸€è‡´çš„è§†é¢‘ï¼‰"""
        try:
            import subprocess

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµ
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œæµå¤åˆ¶å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… æµå¤åˆ¶æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_info(f"âš ï¸ æµå¤åˆ¶å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"æµå¤åˆ¶æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_smooth_transitions(self, concat_file, output_path, quality, video_info, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """ä½¿ç”¨å¹³æ»‘è¿‡æ¸¡çš„é‡æ–°ç¼–ç æ–¹å¼æ‹¼æ¥"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            # æ„å»ºæ”¹è¿›çš„FFmpegå‘½ä»¤ï¼Œå‡å°‘é—ªçƒ
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',  # å¼ºåˆ¶ä½¿ç”¨H.264ç¼–ç å™¨
                '-pix_fmt', 'yuv420p',  # ç»Ÿä¸€åƒç´ æ ¼å¼
                '-r', str(int(video_info['target_fps'])),  # ç»Ÿä¸€å¸§ç‡
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",  # ç»Ÿä¸€åˆ†è¾¨ç‡
                '-vsync', 'cfr',  # æ’å®šå¸§ç‡
                '-bf', '2',  # Bå¸§æ•°é‡
                '-sc_threshold', '0',  # ç¦ç”¨åœºæ™¯åˆ‡æ¢æ£€æµ‹
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-fflags', '+genpts',  # ç”ŸæˆPTS
            ]

            # æ ¹æ®å‚æ•°æ·»åŠ å…³é”®å¸§æ§åˆ¶
            if force_keyframes:
                keyframe_interval = max(1, int(video_info['target_fps'] * 2))  # æ¯2ç§’ä¸€ä¸ªå…³é”®å¸§
                cmd.extend([
                    '-force_key_frames', f'expr:gte(t,n_forced*2)',
                    '-g', str(keyframe_interval),
                ])

            # æ·»åŠ å¹³æ»‘è¿‡æ¸¡æ»¤é•œï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if smooth_transitions and transition_duration > 0:
                # ä½¿ç”¨minterpolateæ»¤é•œè¿›è¡Œå¸§æ’å€¼ï¼Œå‡å°‘è·³è·ƒæ„Ÿ
                cmd.extend([
                    '-vf', f'minterpolate=fps={video_info["target_fps"]}:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1'
                ])

            cmd.extend(quality_params + ['-y', output_path])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¹³æ»‘è¿‡æ¸¡ç¼–ç : {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å¦‚æœé«˜çº§æ»¤é•œå¤±è´¥ï¼Œå°è¯•åŸºç¡€æ–¹æ³•
                if smooth_transitions:
                    _log_info("ğŸ”„ å°è¯•åŸºç¡€å¹³æ»‘æ–¹æ³•...")
                    return self._concat_with_basic_smooth(concat_file, output_path, quality, video_info)
                return False

        except Exception as e:
            _log_error(f"å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_basic_smooth(self, concat_file, output_path, quality, video_info):
        """åŸºç¡€å¹³æ»‘æ‹¼æ¥æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",
                '-vsync', 'cfr',
                '-bf', '2',
                '-g', str(int(video_info['target_fps'] * 2)),
                '-sc_threshold', '0',
                '-avoid_negative_ts', 'make_zero',
                '-fflags', '+genpts',
            ] + quality_params + [
                '-y',
                output_path
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"åŸºç¡€å¹³æ»‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _cleanup_temp_file(self, temp_file):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        except Exception as e:
            _log_error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

    def _concat_with_crossfade_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, False, 0, True)

            _log_info(f"ğŸ¬ ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # å¯¹äºäº¤å‰æ·¡åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼š
            # 1. å…ˆç”¨concatæ­£å¸¸æ‹¼æ¥
            # 2. ç„¶ååœ¨æ‹¼æ¥ç‚¹æ·»åŠ æ·¡åŒ–æ•ˆæœ

            # é¦–å…ˆè·å–è§†é¢‘ä¿¡æ¯ä»¥è®¡ç®—æ€»æ—¶é•¿
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # è®¡ç®—æ¯ä¸ªè§†é¢‘çš„æ—¶é•¿å’Œç´¯ç§¯æ—¶é•¿
            video_durations = []
            cumulative_time = 0

            for video_path in video_paths:
                try:
                    cmd_duration = [
                        'ffprobe',
                        '-v', 'quiet',
                        '-show_entries', 'format=duration',
                        '-of', 'csv=p=0',
                        video_path
                    ]
                    result = subprocess.run(cmd_duration, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        video_durations.append(duration)
                        cumulative_time += duration
                    else:
                        video_durations.append(2.0)  # é»˜è®¤2ç§’
                        cumulative_time += 2.0
                except:
                    video_durations.append(2.0)
                    cumulative_time += 2.0

            _log_info(f"ğŸ“Š è§†é¢‘æ—¶é•¿: {[f'{d:.1f}s' for d in video_durations]}, æ€»æ—¶é•¿: {cumulative_time:.1f}s")

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºç®€åŒ–çš„äº¤å‰æ·¡åŒ–æ»¤é•œ
            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•äº¤å‰æ·¡åŒ–
                filter_complex = self._build_simple_crossfade_filter(video_durations, transition_duration)
            else:
                # å¤šä¸ªè§†é¢‘ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•
                _log_info("ğŸ”„ å¤šè§†é¢‘äº¤å‰æ·¡åŒ–ï¼Œä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œäº¤å‰æ·¡åŒ–å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… äº¤å‰æ·¡åŒ–æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å›é€€åˆ°æ™®é€šæ‹¼æ¥
                _log_info("ğŸ”„ å›é€€åˆ°æ™®é€šæ‹¼æ¥æ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

        except Exception as e:
            _log_error(f"äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°æ™®é€šæ‹¼æ¥
            return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

    def _build_simple_crossfade_filter(self, video_durations, transition_duration):
        """æ„å»ºç®€å•çš„ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–æ»¤é•œ"""
        if len(video_durations) != 2:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        duration1, duration2 = video_durations

        # ç¡®ä¿è¿‡æ¸¡æ—¶é—´ä¸è¶…è¿‡è¾ƒçŸ­è§†é¢‘çš„ä¸€åŠ
        max_transition = min(duration1, duration2) / 2
        actual_transition = min(transition_duration, max_transition)

        if actual_transition <= 0:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        # ä½¿ç”¨xfadeæ»¤é•œè¿›è¡Œäº¤å‰æ·¡åŒ–ï¼ˆæ›´ä¸“ä¸šçš„æ–¹æ³•ï¼‰
        # xfadeæ»¤é•œä¼šè‡ªåŠ¨å¤„ç†æ—¶é—´å¯¹é½
        offset_time = duration1 - actual_transition

        filter_complex = f"[0:v][1:v]xfade=transition=fade:duration={actual_transition}:offset={offset_time}[output]"

        return filter_complex

    def _concat_with_xfade_multiple(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥å¤šä¸ªè§†é¢‘ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        try:
            import subprocess
            import tempfile

            _log_info(f"ğŸ¬ ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨xfade
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

            # å¤šä¸ªè§†é¢‘éœ€è¦é€’å½’å¤„ç†
            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"intermediate_{i}.mp4")

                    # ä½¿ç”¨ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–
                    success = self._concat_with_crossfade_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘xfadeæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_advanced_transitions(self, video_paths, output_path, quality, transition_duration=0.5, transition_type="fade", motion_compensation=False, edge_enhancement=False):
        """ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ¨ ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘ï¼Œè¿‡æ¸¡ç±»å‹: {transition_type}")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ
            if len(video_paths) == 2:
                filter_complex = self._build_advanced_transition_filter(video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨é€’å½’å¤„ç†
                return self._concat_advanced_multiple(video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œé«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout * 2  # é«˜çº§å¤„ç†éœ€è¦æ›´å¤šæ—¶é—´
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                # å›é€€åˆ°äº¤å‰æ·¡åŒ–
                _log_info("ğŸ”„ å›é€€åˆ°äº¤å‰æ·¡åŒ–æ–¹æ³•...")
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

        except Exception as e:
            _log_error(f"é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°äº¤å‰æ·¡åŒ–
            return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

    def _build_advanced_transition_filter(self, video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # é¢„å¤„ç†æ»¤é•œ
            preprocess_filters = []

            # è¾¹ç¼˜å¢å¼º
            if edge_enhancement:
                preprocess_filters.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                input_labels = ["[v0enhanced]", "[v1enhanced]"]
            else:
                input_labels = ["[0:v]", "[1:v]"]

            # è¿åŠ¨è¡¥å¿ï¼ˆä½¿ç”¨minterpolateè¿›è¡Œå¸§æ’å€¼ï¼‰
            if motion_compensation:
                preprocess_filters.extend([
                    f"{input_labels[0]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    f"{input_labels[1]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                input_labels = ["[v0smooth]", "[v1smooth]"]

            # æ„å»ºxfadeè¿‡æ¸¡
            xfade_filter = f"{input_labels[0]}{input_labels[1]}xfade=transition={transition_type}:duration={actual_transition}:offset={offset_time}[output]"

            # ç»„åˆæ‰€æœ‰æ»¤é•œ
            if preprocess_filters:
                filter_complex = ";".join(preprocess_filters) + ";" + xfade_filter
            else:
                filter_complex = xfade_filter

            return filter_complex

        except Exception as e:
            _log_error(f"æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            return f"[0:v][1:v]xfade=transition=fade:duration={transition_duration}:offset={max(0, durations[0] - transition_duration)}[output]"

    def _concat_advanced_multiple(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—é—®é¢˜"""
        try:
            # å¯¹äºå¤šè§†é¢‘ï¼Œä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾è€Œä¸æ˜¯é€’å½’æ‹¼æ¥
            # è¿™æ ·å¯ä»¥é¿å…é‡å¤å‡å»è¿‡æ¸¡æ—¶é—´çš„é—®é¢˜

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨åŸæ–¹æ³•
                return self._concat_with_advanced_transitions(
                    video_paths, output_path, quality, transition_duration,
                    transition_type, motion_compensation, edge_enhancement
                )

            # å¤šäº2ä¸ªè§†é¢‘æ—¶ï¼Œæ„å»ºä¸€æ¬¡æ€§æ»¤é•œé“¾
            return self._concat_advanced_multiple_chain(
                video_paths, output_path, quality, transition_duration,
                transition_type, motion_compensation, edge_enhancement
            )

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_advanced_multiple_chain(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾æ‹¼æ¥å¤šä¸ªè§†é¢‘ - æ­£ç¡®çš„æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾
            filter_complex = self._build_multiple_xfade_chain(video_paths, durations, actual_transition, transition_type)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘é«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_xfade_chain(self, video_paths, durations, transition_duration, transition_type):
        """æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration
                return f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[output]"

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            filter_parts.append(f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[v01]")
            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration
                filter_parts.append(f"[{input_label}][{i}:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _simple_concat_multiple(self, video_paths, output_path):
        """ç®€å•çš„å¤šè§†é¢‘æ‹¼æ¥ï¼ˆæ— è¿‡æ¸¡ï¼‰"""
        try:
            import subprocess
            import tempfile

            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                concat_file = f.name

            try:
                cmd = [
                    'ffmpeg',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', concat_file,
                    '-c', 'copy',
                    '-y',
                    output_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

                if result.returncode == 0 and os.path.exists(output_path):
                    return True
                else:
                    return False

            finally:
                try:
                    os.unlink(concat_file)
                except:
                    pass

        except Exception as e:
            _log_error(f"ç®€å•å¤šè§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_morphing_transitions(self, video_paths, output_path, quality, transition_duration=0.5, motion_compensation=False):
        """ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆå®éªŒæ€§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ§¬ ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "fade", motion_compensation, False)

            # å¯¹äºå½¢æ€å­¦è¿‡æ¸¡ï¼Œæˆ‘ä»¬ä½¿ç”¨blendæ»¤é•œå’Œmorphologicalæ“ä½œ
            if len(video_paths) == 2:
                filter_complex = self._build_morphing_filter(video_paths, transition_duration, motion_compensation)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾ï¼Œé¿å…æ—¶é•¿è®¡ç®—é”™è¯¯
                return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # å¤§å¹…ç¼©çŸ­è¶…æ—¶æ—¶é—´ - å½¢æ€å­¦è¿‡æ¸¡ä¹Ÿåº”è¯¥å¿«é€Ÿå¤„ç†
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except Exception as e:
            _log_error(f"å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

    def _build_morphing_filter(self, video_paths, transition_duration, motion_compensation):
        """æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ - æ›´ç¨³å®šçš„å®ç°
            filter_parts = []

            # è¿åŠ¨è¡¥å¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                # ä½¿ç”¨é«˜è´¨é‡dissolveè¿‡æ¸¡
                filter_parts.append(
                    f"[v0smooth][v1smooth]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )
            else:
                # ä¸ä½¿ç”¨è¿åŠ¨è¡¥å¿æ—¶ï¼Œä½¿ç”¨è¾¹ç¼˜å¢å¼ºçš„dissolve
                filter_parts.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                filter_parts.append(
                    f"[v0enhanced][v1enhanced]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°ç®€å•çš„dissolveè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=dissolve:duration={transition_duration}:offset={offset_time}[output]"

    def _concat_with_optical_flow_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆæœ€é«˜çº§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸŒŠ ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

            # ç°åœ¨FFmpegå‚æ•°å·²ä¿®å¤ï¼Œå¯ä»¥æ”¯æŒå„ç§åˆ†è¾¨ç‡çš„å…‰æµè¿‡æ¸¡
            # ä½†å¯¹äºè¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ï¼Œä»ç„¶å»ºè®®ä½¿ç”¨å¿«é€Ÿæ–¹æ³•ä»¥ä¿è¯ç”¨æˆ·ä½“éªŒ
            if 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (å¦‚1920x1080)ï¼Œæé†’ç”¨æˆ·ä½†ä¸å¼ºåˆ¶è·³è¿‡
                    _log_info(f"âš ï¸ æ£€æµ‹åˆ°è¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ ({video_info['target_width']}x{video_info['target_height']})ï¼Œå…‰æµè¿‡æ¸¡å¯èƒ½è¾ƒæ…¢")
                    _log_info("ğŸ’¡ å¦‚éœ€å¿«é€Ÿå¤„ç†ï¼Œå»ºè®®ä½¿ç”¨concat_advancedæ–¹æ³•")
                    # ä¸å†å¼ºåˆ¶è·³è¿‡ï¼Œè®©ç”¨æˆ·é€‰æ‹©

            # å°è¯•çœŸæ­£çš„å…‰æµè¿‡æ¸¡å¤„ç†
            if len(video_paths) == 2:
                filter_complex = self._build_optical_flow_filter(video_paths, transition_duration)
            else:
                # å¤šè§†é¢‘å…‰æµè¿‡æ¸¡ï¼šä½¿ç”¨é“¾å¼å…‰æµå¤„ç†
                _log_info("ğŸŒŠ æ‰§è¡Œå¤šè§†é¢‘å…‰æµè¿‡æ¸¡å¤„ç†...")
                filter_complex = self._build_optical_flow_multiple_filter(video_paths, transition_duration)

                # å¦‚æœå¤šè§†é¢‘å…‰æµæ»¤é•œæ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡
                if filter_complex is None:
                    _log_info("ğŸ”„ å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                    return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "radial", False, False)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå…‰æµè¿‡æ¸¡å‘½ä»¤...")

            # ä¸ºçœŸæ­£çš„å…‰æµè¿‡æ¸¡è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                    timeout_seconds = 600  # 10åˆ†é’Ÿï¼Œè½»é‡çº§å…‰æµ
                elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                    timeout_seconds = 480  # 8åˆ†é’Ÿï¼Œæ ‡å‡†å…‰æµ
                else:
                    timeout_seconds = 300  # 5åˆ†é’Ÿï¼Œé«˜è´¨é‡å…‰æµ
            else:
                timeout_seconds = 300  # é»˜è®¤5åˆ†é’Ÿ

            _log_info(f"â±ï¸ å…‰æµè¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (çœŸæ­£å…‰æµå¤„ç†)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å…‰æµè¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å…‰æµè¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except Exception as e:
            _log_error(f"å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

    def _build_optical_flow_filter(self, video_paths, transition_duration):
        """æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œï¼ˆç®€åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç°åœ¨æä¾›çœŸæ­£çš„å…‰æµè¿‡æ¸¡é€‰é¡¹
            # ç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒçº§åˆ«çš„å…‰æµå¤„ç†

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
            pixels = 1248 * 704  # é»˜è®¤å€¼
            if len(video_paths) >= 2:
                try:
                    # å°è¯•è·å–å®é™…åˆ†è¾¨ç‡
                    cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and 'x' in result.stdout:
                        width, height = map(int, result.stdout.strip().split('x'))
                        pixels = width * height
                except:
                    pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ ä½¿ç”¨è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                # è½»é‡çº§å…‰æµï¼šä»…ä½¿ç”¨åŸºç¡€è¿åŠ¨è¡¥å¿
                filter_parts = [
                    "[0:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v0flow]",
                    "[1:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ ä½¿ç”¨æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆå¹³è¡¡è´¨é‡ä¸é€Ÿåº¦ï¼‰")
                # æ ‡å‡†å…‰æµï¼šä¸­ç­‰å¤æ‚åº¦
                filter_parts = [
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v0flow]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            else:
                _log_info("ğŸŒŠ ä½¿ç”¨é«˜è´¨é‡å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                # é«˜è´¨é‡å…‰æµï¼šå®Œæ•´ç®—æ³•
                filter_parts = [
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v0flow]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]

            return ";".join(filter_parts)

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜è´¨é‡çš„smoothleftè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"

    def _build_optical_flow_multiple_filter(self, video_paths, transition_duration):
        """æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œé“¾"""
        try:
            # è·å–æ‰€æœ‰è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        durations.append(duration)
                    else:
                        _log_error(f"ffprobeå¤±è´¥: {video_path}, è¿”å›ç : {result.returncode}")
                        _log_error(f"stderr: {result.stderr}")
                        durations.append(4.0)
                except Exception as e:
                    _log_error(f"ffprobeå¼‚å¸¸: {video_path}, é”™è¯¯: {str(e)}")
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v]concat=n=1:v=1[output]"

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯ç”¨äºé€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            pixels = 1248 * 704  # é»˜è®¤å€¼
            try:
                cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                if result.returncode == 0 and 'x' in result.stdout:
                    width, height = map(int, result.stdout.strip().split('x'))
                    pixels = width * height
            except:
                pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ å¤šè§†é¢‘è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ å¤šè§†é¢‘å¿«é€Ÿå…‰æµè¿‡æ¸¡ï¼ˆä¼˜åŒ–å¤„ç†é€Ÿåº¦ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"  # é™ä½fpsæé«˜é€Ÿåº¦
            else:
                _log_info("ğŸŒŠ å¤šè§†é¢‘æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1"

            filter_parts = []

            # é¦–å…ˆå¯¹æ‰€æœ‰è¾“å…¥è§†é¢‘åº”ç”¨å…‰æµå¤„ç†
            for i in range(len(video_paths)):
                filter_parts.append(f"[{i}:v]minterpolate={minterpolate_params}[v{i}flow]")

            # ä½¿ç”¨æ­£ç¡®çš„å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ–¹æ³•ï¼šé“¾å¼å¤„ç†ï¼Œä½†éœ€è¦æ­£ç¡®è®¡ç®—æ¯ä¸ªè¿‡æ¸¡çš„æ—¶é•¿
            #
            # å…³é”®ç†è§£ï¼šxfadeçš„offsetæ˜¯ç›¸å¯¹äºç¬¬ä¸€ä¸ªè¾“å…¥çš„æ—¶é•¿ï¼Œè€Œä¸æ˜¯ç»å¯¹æ—¶é—´
            # æ¯ä¸ªxfadeè¾“å‡ºçš„é•¿åº¦ = offset + transition_duration

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡ï¼švideo1 + video2
            offset_time = durations[0] - transition_duration  # 11.5ç§’
            filter_parts.append(f"[v0flow][v1flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[v01]")
            # v01çš„é•¿åº¦ = durations[0] + durations[1] - transition_duration = 23.5ç§’

            # åç»­è¿‡æ¸¡éœ€è¦é‡æ–°æ€è€ƒï¼šæˆ‘ä»¬éœ€è¦å°†v01å’Œåç»­è§†é¢‘æ‹¼æ¥
            # ä½†v01å·²ç»æ˜¯23.5ç§’çš„å®Œæ•´è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å…¶æœ«å°¾æ·»åŠ æ–°è§†é¢‘

            current_video_length = durations[0] + durations[1] - transition_duration  # v01çš„é•¿åº¦

            for i in range(2, len(video_paths)):
                if i == 2:
                    input_label = "v01"
                    output_label = "v02" if i < len(video_paths) - 1 else "output"
                else:
                    input_label = f"v0{i-1}"
                    output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # å¯¹äºåç»­è¿‡æ¸¡ï¼Œoffsetåº”è¯¥æ˜¯å½“å‰è§†é¢‘é•¿åº¦å‡å»è¿‡æ¸¡æ—¶é—´
                offset_time = current_video_length - transition_duration
                filter_parts.append(f"[{input_label}][v{i}flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[{output_label}]")

                # æ›´æ–°å½“å‰è§†é¢‘é•¿åº¦ï¼šåŠ ä¸Šæ–°è§†é¢‘é•¿åº¦ï¼Œå‡å»è¿‡æ¸¡æ—¶é—´
                current_video_length += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•
            _log_info("ğŸ”„ å…‰æµè¿‡æ¸¡å¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return None  # è¿”å›Noneè¡¨ç¤ºéœ€è¦å›é€€

    def _concat_morphing_multiple(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿ç•™æ—§æ–¹æ³•ä½œä¸ºå¤‡ç”¨"""
        _log_info("ğŸ”„ ä½¿ç”¨æ—§çš„é€’å½’å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰")
        return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

    def _concat_morphing_multiple_chain(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾çš„å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾
            filter_complex = self._build_multiple_morphing_chain(video_paths, durations, actual_transition, motion_compensation)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡è°ƒæ•´è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout_seconds)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            return False
        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_morphing_chain(self, video_paths, durations, transition_duration, motion_compensation):
        """æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration

                # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ
                if motion_compensation:
                    # å¸¦è¿åŠ¨è¡¥å¿çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                        "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                        f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]
                else:
                    # ç®€å•çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]edgedetect=low=0.1:high=0.4[v0edge]",
                        "[1:v]edgedetect=low=0.1:high=0.4[v1edge]",
                        f"[v0edge][v1edge]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]

                return ";".join(filter_parts)

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ - ä½¿ç”¨ç®€åŒ–çš„è¿‡æ¸¡æ•ˆæœ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                    f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]"
                ])
            else:
                filter_parts.append(f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]")

            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration

                if motion_compensation and i == 2:  # åªå¯¹ç¬¬äºŒä¸ªè¿‡æ¸¡ä½¿ç”¨è¿åŠ¨è¡¥å¿ï¼Œé¿å…è¿‡äºå¤æ‚
                    filter_parts.extend([
                        f"[{i}:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v{i}smooth]",
                        f"[{input_label}][v{i}smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]"
                    ])
                else:
                    filter_parts.append(f"[{input_label}][{i}:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _concat_optical_flow_multiple(self, video_paths, output_path, quality, transition_duration):
        """å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥"""
        try:
            import tempfile

            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"flow_intermediate_{i}.mp4")

                    success = self._concat_with_optical_flow_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"å…‰æµè¿‡æ¸¡ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _hstack_videos(self, video_paths, output_path, quality, scale_videos):
        """æ°´å¹³æ‹¼æ¥è§†é¢‘ï¼ˆå¹¶æ’æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†”ï¸ ä½¿ç”¨hstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("hstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†æ°´å¹³æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                hstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]hstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + hstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "hstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"hstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _vstack_videos(self, video_paths, output_path, quality, scale_videos):
        """å‚ç›´æ‹¼æ¥è§†é¢‘ï¼ˆä¸Šä¸‹æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†•ï¸ ä½¿ç”¨vstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("vstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†å‚ç›´æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                vstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]vstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + vstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "vstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"vstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _grid_videos(self, video_paths, output_path, quality, grid_type, scale_videos):
        """ç½‘æ ¼æ‹¼æ¥è§†é¢‘ï¼ˆ2x2ã€2x3æˆ–2x4å¸ƒå±€ï¼‰"""
        try:
            import subprocess

            _log_info(f"ğŸ”² ä½¿ç”¨{grid_type}ç½‘æ ¼æ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if grid_type == "2x2":
                max_videos = 4
            elif grid_type == "2x3":
                max_videos = 6
            elif grid_type == "2x4":
                max_videos = 8
            else:
                max_videos = 4

            if len(video_paths) > max_videos:
                _log_error(f"{grid_type}ç½‘æ ¼æœ€å¤šæ”¯æŒ{max_videos}ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # ä¸ºä¸è¶³çš„ä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
            while len(video_paths) < max_videos:
                video_paths.append(None)

            # æ„å»ºç½‘æ ¼æ»¤é•œ
            if scale_videos:
                # ç¼©æ”¾æ‰€æœ‰è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸
                scale_filters = []
                for i in range(len([v for v in video_paths if v is not None])):
                    scale_filters.append(f"[{i}:v]scale=320:240[v{i}]")

                # ä¸ºç©ºä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:320x240:d=1[v{i}]")

                if grid_type == "2x2":
                    # 2x2ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    # 2x3ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[middle];[v4][v5]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    # 2x4ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[row1];[v2][v3]hstack[row2];[v4][v5]hstack[row3];[v6][v7]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                all_filters = scale_filters + black_filters + [grid_filter]
                filter_complex = ";".join(all_filters)
            else:
                # ä¸ç¼©æ”¾ï¼Œç›´æ¥ç½‘æ ¼æ‹¼æ¥ï¼ˆå¯èƒ½ä¼šæœ‰å°ºå¯¸ä¸åŒ¹é…é—®é¢˜ï¼‰
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:640x480:d=1[v{i}]")

                if grid_type == "2x2":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[middle];[4:v][5:v]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    grid_filter = f"[0:v][1:v]hstack[row1];[2:v][3:v]hstack[row2];[4:v][5:v]hstack[row3];[6:v][7:v]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                filter_complex = ";".join(black_filters + [grid_filter])

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"gridæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _create_error_result(self, error_msg):
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        try:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            afvideo = create_video_path_wrapper(blank_video_path) if blank_video_path else create_blank_video_object()
            return (blank_video, f"âŒ {error_msg}", afvideo)
        except:
            return (None, f"âŒ {error_msg}", None)


class GetLastFrameNode:
    """æå–ä»»æ„è§†é¢‘å°¾å¸§çš„ç‹¬ç«‹èŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
            },
            "optional": {
                "output_filename": ("STRING", {"default": ""}),
                "image_quality": (["high", "medium", "low"], {"default": "high"}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("last_frame_image", "frame_path")
    FUNCTION = "extract_last_frame"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 60  # 1åˆ†é’Ÿè¶…æ—¶

    def extract_last_frame(self, video, output_filename="", image_quality="high"):
        """
        æå–è§†é¢‘çš„æœ€åä¸€å¸§

        Args:
            video: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            image_quality: å›¾åƒè´¨é‡è®¾ç½®

        Returns:
            tuple: (å›¾åƒå¼ é‡, å›¾åƒæ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹æå–è§†é¢‘å°¾å¸§...")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ”¹è¿›çš„æå–æ–¹æ³•
            video_path = self._extract_video_path(video)

            if not video_path:
                error_msg = f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}"
                _log_error(error_msg)
                _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                # è¿”å›ç©ºç™½å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            if not os.path.exists(video_path):
                error_msg = f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"ğŸ“¹ è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                output_filename = f"{video_name}_last_frame.jpg"

            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
            if not output_filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                output_filename += '.jpg'

            # ä½¿ç”¨ä¸´æ—¶ç›®å½•
            import tempfile
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{int(time.time())}_{output_filename}")

            # è®¾ç½®å›¾åƒè´¨é‡å‚æ•°
            quality_settings = {
                "high": ["-q:v", "2"],      # é«˜è´¨é‡
                "medium": ["-q:v", "5"],    # ä¸­ç­‰è´¨é‡
                "low": ["-q:v", "8"]        # ä½è´¨é‡
            }
            quality_params = quality_settings.get(image_quality, quality_settings["high"])

            # æå–å°¾å¸§
            frame_path = self._extract_frame_with_ffmpeg(video_path, output_path, quality_params)

            if not frame_path:
                error_msg = "å°¾å¸§æå–å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            # å°†å›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼
            image_tensor = self._load_image_as_tensor(frame_path)

            if image_tensor is None:
                error_msg = "å›¾åƒåŠ è½½å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {frame_path}")
            return (image_tensor, frame_path)

        except Exception as e:
            error_msg = f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            blank_image = self._create_blank_image()
            return (blank_image, f"âŒ {error_msg}")

    def _extract_frame_with_ffmpeg(self, video_path, output_path, quality_params):
        """ä½¿ç”¨FFmpegæå–å°¾å¸§"""
        try:
            import subprocess

            # æ–¹æ³•1ï¼šä½¿ç”¨select=eofè¿‡æ»¤å™¨
            cmd1 = [
                'ffmpeg',
                '-i', video_path,
                '-vf', 'select=eof',
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd1)}")

            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                return output_path

            # æ–¹æ³•2ï¼šå¤‡ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
            _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•...")

            # è·å–è§†é¢‘æ—¶é•¿
            duration_cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                video_path
            ]

            duration_result = subprocess.run(
                duration_cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if duration_result.returncode == 0:
                try:
                    duration = float(duration_result.stdout.strip())
                    seek_time = max(0, duration - 0.1)

                    cmd2 = [
                        'ffmpeg',
                        '-ss', str(seek_time),
                        '-i', video_path,
                        '-frames:v', '1',
                    ] + quality_params + [
                        '-y',
                        output_path
                    ]

                    result = subprocess.run(
                        cmd2,
                        capture_output=True,
                        text=True,
                        timeout=self.timeout
                    )

                    if result.returncode == 0 and os.path.exists(output_path):
                        return output_path
                except:
                    pass

            return None

        except Exception as e:
            _log_error(f"FFmpegæå–å¤±è´¥: {str(e)}")
            return None

    def _load_image_as_tensor(self, image_path):
        """å°†å›¾åƒæ–‡ä»¶åŠ è½½ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        try:
            from PIL import Image
            import numpy as np
            import torch

            # ä½¿ç”¨PILåŠ è½½å›¾åƒ
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img).astype(np.float32) / 255.0

                # æ·»åŠ batchç»´åº¦ [H, W, C] -> [1, H, W, C]
                img_array = np.expand_dims(img_array, axis=0)

                # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
                img_tensor = torch.from_numpy(img_array)

                _log_info(f"âœ… å›¾åƒå¼ é‡æ ¼å¼: {img_tensor.shape}, dtype: {img_tensor.dtype}")
                return img_tensor

        except Exception as e:
            _log_error(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
            return None

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _create_blank_image(self):
        """åˆ›å»ºç©ºç™½å›¾åƒå¼ é‡"""
        try:
            import numpy as np
            import torch
            # åˆ›å»º512x512çš„é»‘è‰²å›¾åƒ
            blank_array = np.zeros((1, 512, 512, 3), dtype=np.float32)
            # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
            blank_tensor = torch.from_numpy(blank_array)
            return blank_tensor
        except:
            return None






class DoubaoSeed16Node:
    """è±†åŒ…å¤§æ¨¡å‹æ–‡æœ¬ç”ŸæˆèŠ‚ç‚¹ - æ”¯æŒdoubao-seed-1.6å’Œdoubao-seed-1.6-flashæ¨¡å‹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = []
        
        # åªæ˜¾ç¤ºæ”¯æŒæ–‡æœ¬ç”Ÿæˆçš„é•œåƒç«™
        for site_name, site_config in mirror_sites.items():
            text_models = site_config.get('text_models', [])
            if text_models:  # å¦‚æœæœ‰æ–‡æœ¬æ¨¡å‹ï¼Œåˆ™æ”¯æŒæ–‡æœ¬ç”Ÿæˆ
                mirror_options.append(site_name)
        
        if not mirror_options:
            mirror_options = ["comfly", "volcengine"]
        
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seed-1-6-250615", "doubao-seed-1-6-flash-250615", "doubao-seed-1-6-flash-250828"], {"default": "doubao-seed-1-6-250615"}),
                "api_key": ("STRING", {"default": ""}),
                "max_tokens": ("INT", {"default": 1000, "min": 1, "max": 4000, "step": 1}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0, "step": 0.1}),
                "top_p": ("FLOAT", {"default": 0.9, "min": 0.0, "max": 1.0, "step": 0.01}),
            },
            "optional": {
                "system_prompt": ("STRING", {"multiline": True, "default": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿æ–‡æœ¬ç”Ÿæˆå’Œå†…å®¹åˆ›ä½œã€‚"}),
                "stream": ("BOOLEAN", {"default": False}),
                "presence_penalty": ("FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 0.1}),
                "frequency_penalty": ("FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 0.1}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("generated_text", "response_info", "usage_info")
    FUNCTION = "generate_text"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶ï¼ˆæ•…äº‹ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´ï¼‰

    def generate_text(self, prompt, mirror_site="comfly", model="doubao-seed-1-6-250615", api_key="", max_tokens=1000, 
                     temperature=0.7, top_p=0.9, system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿æ–‡æœ¬ç”Ÿæˆå’Œå†…å®¹åˆ›ä½œã€‚", 
                     stream=False, presence_penalty=0.0, frequency_penalty=0.0):
        """
        è°ƒç”¨è±†åŒ…å¤§æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ

        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
            mirror_site: é•œåƒç«™é€‰æ‹© (comfly, t8_mirror, volcengine)
            model: æ¨¡å‹åç§° (doubao-seed-1-6-250615, doubao-seed-1-6-flash-250615, doubao-seed-1-6-flash-250828)
            api_key: APIå¯†é’¥
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            top_p: æ ¸é‡‡æ ·å‚æ•°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            stream: æ˜¯å¦æµå¼è¾“å‡º
            presence_penalty: å­˜åœ¨æƒ©ç½š
            frequency_penalty: é¢‘ç‡æƒ©ç½š

        Returns:
            tuple: (ç”Ÿæˆçš„æ–‡æœ¬, å“åº”ä¿¡æ¯, ä½¿ç”¨æƒ…å†µä¿¡æ¯)
        """
        try:
            _log_info(f"ğŸ¤– å¼€å§‹è°ƒç”¨è±†åŒ…å¤§æ¨¡å‹ {model} è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ...")
            _log_info(f"ğŸ“ æç¤ºè¯: {prompt[:100]}...")
            _log_info(f"ğŸŒ ä½¿ç”¨é•œåƒç«™: {mirror_site}")

            # è·å–é•œåƒç«™é…ç½®
            site_config = get_mirror_site_config(mirror_site)
            api_url = site_config.get("url", "").strip()
            api_format = site_config.get("api_format", "comfly")

            # ä½¿ç”¨é…ç½®é‡Œçš„APIæ ¼å¼ï¼›ä¸å†å¼ºåˆ¶æ”¹å†™ï¼Œé¿å…ç«¯ç‚¹å’Œæ ¼å¼ä¸ä¸€è‡´
            _log_info(f"ğŸ”§ APIæ ¼å¼: {api_format}")

            # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
            if site_config.get("api_key") and not api_key.strip():
                api_key = site_config.get("api_key")
                _log_info(f"ğŸ”‘ ä½¿ç”¨é•œåƒç«™APIå¯†é’¥: {api_key[:10]}...")

            # è·å–APIå¯†é’¥
            if not api_key:
                api_key = self._get_api_key()
                if not api_key:
                    error_msg = "æœªæä¾›APIå¯†é’¥ï¼Œè¯·åœ¨èŠ‚ç‚¹ä¸­è®¾ç½®æˆ–é…ç½®ç¯å¢ƒå˜é‡DOUBAO_API_KEY"
                    _log_error(error_msg)
                    return ("", f"âŒ {error_msg}", "")

            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": max_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "stream": stream,
                "presence_penalty": presence_penalty,
                "frequency_penalty": frequency_penalty
            }

            # è°ƒç”¨API
            response = self._call_doubao_api(api_url, api_key, request_data, stream, api_format)
            
            if response is None:
                error_msg = "APIè°ƒç”¨å¤±è´¥"
                _log_error(error_msg)
                return ("", f"âŒ {error_msg}", "")

            # è§£æå“åº”
            generated_text, response_info, usage_info = self._parse_response(response, stream)
            
            _log_info(f"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(generated_text)} å­—ç¬¦")
            return (generated_text, response_info, usage_info)

        except Exception as e:
            error_msg = f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {str(e)}"
            _log_error(error_msg)
            return ("", f"âŒ {error_msg}", "")

    def _get_api_key(self):
        """è·å–APIå¯†é’¥"""
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–
        import os
        api_key = os.getenv('DOUBAO_API_KEY')
        if api_key:
            return api_key
        
        # ä»é…ç½®æ–‡ä»¶è·å–
        try:
            import json
            config_path = os.path.join(os.path.dirname(__file__), 'SeedReam4_config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config.get('doubao_api_key', '')
        except:
            pass
        
        return ""

    def _call_doubao_api(self, api_url, api_key, request_data, stream=False, api_format="volcengine"):
        """è°ƒç”¨è±†åŒ…å¤§æ¨¡å‹API"""
        try:
            import requests
            import json

            # æŒ‰æ ¼å¼æ„å»ºç«¯ç‚¹
            if api_format == "volcengine":
                # ç«å±±å¼•æ“å®˜æ–¹: åŸºç¡€æ˜¯ /api/v3
                # chat èµ° /chat/completions
                if api_url.endswith('/'):
                    api_url = api_url + 'chat/completions'
                elif api_url.endswith('/api/v3'):
                    api_url = api_url + '/chat/completions'
                elif api_url.endswith('/api/v3/'):
                    api_url = api_url + 'chat/completions'
                elif not api_url.endswith('/chat/completions'):
                    api_url = api_url.rstrip('/') + '/chat/completions'
            else:
                # å…¶å®ƒé•œåƒæŒ‰å…¶è‡ªèº«ï¼ˆå¦‚ comfly çš„ /v1/chat/completionsï¼‰
                if not api_url.endswith('/chat/completions'):
                    api_url = api_url.rstrip('/') + '/chat/completions'
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "User-Agent": "ComfyUI-Doubao-Seed/2.0.0"
            }

            _log_info(f"ğŸŒ è°ƒç”¨API: {api_url}")
            _log_info(f"ğŸ“Š è¯·æ±‚å‚æ•°: model={request_data['model']}, max_tokens={request_data['max_tokens']}")
            _log_info(f"ğŸ”§ APIæ ¼å¼: {api_format}")

            # å‘é€è¯·æ±‚
            response = requests.post(
                api_url,
                headers=headers,
                json=request_data,
                timeout=self.timeout
            )

            if response.status_code == 200:
                _log_info("âœ… APIè°ƒç”¨æˆåŠŸ")
                try:
                    return response.json()
                except json.JSONDecodeError as e:
                    _log_error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    _log_error(f"å“åº”å†…å®¹: {response.text[:500]}...")
                    return None
            else:
                _log_error(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                _log_error(f"å“åº”å†…å®¹: {response.text}")
                return None

        except requests.exceptions.Timeout:
            _log_error("âŒ APIè°ƒç”¨è¶…æ—¶")
            return None
        except requests.exceptions.RequestException as e:
            _log_error(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            _log_error(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None

    def _parse_response(self, response, stream=False):
        """è§£æAPIå“åº”"""
        try:
            if stream:
                # æµå¼å“åº”å¤„ç†
                generated_text = ""
                for line in response.get('data', []):
                    if 'choices' in line and len(line['choices']) > 0:
                        delta = line['choices'][0].get('delta', {})
                        if 'content' in delta:
                            generated_text += delta['content']
                
                response_info = f"æµå¼ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_text)} å­—ç¬¦"
                usage_info = "æµå¼æ¨¡å¼ï¼Œæ— ä½¿ç”¨ç»Ÿè®¡"
            else:
                # æ™®é€šå“åº”å¤„ç†
                choices = response.get('choices', [])
                if not choices:
                    return ("", "âŒ å“åº”ä¸­æ— ç”Ÿæˆå†…å®¹", "")
                
                generated_text = choices[0].get('message', {}).get('content', "")
                
                # æ„å»ºå“åº”ä¿¡æ¯
                response_info = f"æ¨¡å‹: {response.get('model', 'unknown')}\n"
                response_info += f"ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_text)} å­—ç¬¦"
                
                # æ„å»ºä½¿ç”¨æƒ…å†µä¿¡æ¯
                usage = response.get('usage', {})
                usage_info = f"Tokenä½¿ç”¨æƒ…å†µ:\n"
                usage_info += f"- æç¤ºè¯tokens: {usage.get('prompt_tokens', 0)}\n"
                usage_info += f"- ç”Ÿæˆtokens: {usage.get('completion_tokens', 0)}\n"
                usage_info += f"- æ€»tokens: {usage.get('total_tokens', 0)}"

            return (generated_text, response_info, usage_info)

        except Exception as e:
            _log_error(f"âŒ å“åº”è§£æå¤±è´¥: {str(e)}")
            return ("", f"âŒ å“åº”è§£æå¤±è´¥: {str(e)}", "")


class DoubaoComicBookNode:
    """è±†åŒ…è¿ç¯ç”»åˆ›ä½œèŠ‚ç‚¹ - é›†æˆæ–‡æœ¬ç”Ÿæˆå’Œå›¾åƒç”Ÿæˆï¼Œåˆ›ä½œå®Œæ•´è¿ç¯ç”»"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = []
        
        # åªæ˜¾ç¤ºæ”¯æŒæ–‡æœ¬ç”Ÿæˆçš„é•œåƒç«™
        for site_name, site_config in mirror_sites.items():
            text_models = site_config.get('text_models', [])
            if text_models:  # å¦‚æœæœ‰æ–‡æœ¬æ¨¡å‹ï¼Œåˆ™æ”¯æŒæ–‡æœ¬ç”Ÿæˆ
                mirror_options.append(site_name)
        
        if not mirror_options:
            mirror_options = ["comfly", "volcengine"]
        
        return {
            "required": {
                "story_prompt": ("STRING", {"multiline": True, "default": "ä¸€ä¸ªå…³äºå°å…”å­å†’é™©çš„æ¸©é¦¨æ•…äº‹"}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "text_model": (["doubao-seed-1-6-250615", "doubao-seed-1-6-flash-250615", "doubao-seed-1-6-flash-250828"], {"default": "doubao-seed-1-6-250615"}),
                "image_model": (["doubao-seedream-4-0-250828"], {"default": "doubao-seedream-4-0-250828"}),
                "story_length": (["short", "medium", "long"], {"default": "medium"}),
                "image_style": (["realistic", "cartoon", "anime", "watercolor", "sketch"], {"default": "cartoon"}),
                "resolution": (["1K", "2K", "4K"], {"default": "2K"}),
                "aspect_ratio": (["1:1", "4:3", "3:4", "16:9", "9:16"], {"default": "4:3"}),
                "watermark": ("BOOLEAN", {"default": False}),  # æ°´å°æ§åˆ¶ï¼Œé»˜è®¤ä¸æ˜¾ç¤º
                "api_key": ("STRING", {"default": ""}),
                "max_tokens": ("INT", {"default": 2000, "min": 500, "max": 4000, "step": 100}),
                "temperature": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1}),
            },
            "optional": {
                "reference_images": ("IMAGE",),  # æœ€å¤š10å¼ å‚è€ƒå›¾ç‰‡
                "reference_image_2": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡2
                "reference_image_3": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡3
                "reference_image_4": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡4
                "reference_image_5": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡5
                "reference_image_6": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡6
                "reference_image_7": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡7
                "reference_image_8": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡8
                "reference_image_9": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡9
                "reference_image_10": ("IMAGE",),  # å‚è€ƒå›¾ç‰‡10
                "character_description": ("STRING", {"multiline": True, "default": ""}),
                "background_style": ("STRING", {"multiline": True, "default": ""}),
                "story_theme": ("STRING", {"multiline": True, "default": ""}),
                "sequential_generation": (["disabled", "auto"], {"default": "auto"}),
            }
        }

    # è¾“å‡ºæ”¯æŒï¼š
    # - IMAGE_BATCH: æŒ‰åœºæ™¯è¿”å›å›¾åƒæ‰¹æ¬¡ï¼Œä¾¿äºåœ¨ComfyUIä¸­åˆ†é¡µæµè§ˆ
    # - STRING: è¿”å›å®Œæ•´æ•…äº‹æ–‡æœ¬ã€ç»“æ„åŒ–JSONå’Œç”Ÿæˆä¿¡æ¯
    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("comic_images", "story_text", "story_structure", "generation_info")
    FUNCTION = "create_comic_book"
    CATEGORY = "Ken-Chen/Doubao"

    def __init__(self):
        self.timeout = 600  # 10åˆ†é’Ÿè¶…æ—¶ï¼Œè¿ç¯ç”»åˆ›ä½œéœ€è¦æ›´é•¿æ—¶é—´
        self.config = get_seedream4_config()
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    def create_comic_book(self, story_prompt, mirror_site="comfly", text_model="doubao-seed-1-6-250615", 
                         image_model="doubao-seedream-4-0-250828", story_length="medium", image_style="cartoon",
                         resolution="2K", aspect_ratio="4:3", api_key="", max_tokens=2000, temperature=0.8,
                         reference_images=None, reference_image_2=None, reference_image_3=None, reference_image_4=None,
                         reference_image_5=None, reference_image_6=None, reference_image_7=None, reference_image_8=None,
                         reference_image_9=None, reference_image_10=None, character_description="", background_style="",
                         story_theme="", watermark=False, sequential_generation="auto"):
        """
        åˆ›å»ºè¿ç¯ç”»æ•…äº‹ä¹¦

        Args:
            story_prompt: æ•…äº‹æç¤ºè¯
            mirror_site: é•œåƒç«™é€‰æ‹©
            text_model: æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
            image_model: å›¾åƒç”Ÿæˆæ¨¡å‹
            story_length: æ•…äº‹é•¿åº¦ (short/medium/long)
            image_style: å›¾åƒé£æ ¼
            resolution: å›¾åƒåˆ†è¾¨ç‡
            aspect_ratio: å®½é«˜æ¯”
            api_key: APIå¯†é’¥
            max_tokens: æœ€å¤§tokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            reference_images: å‚è€ƒå›¾ç‰‡ï¼ˆæœ€å¤š10å¼ ï¼‰
            character_description: è§’è‰²æè¿°
            background_style: èƒŒæ™¯é£æ ¼
            story_theme: æ•…äº‹ä¸»é¢˜
            watermark: æ˜¯å¦æ·»åŠ æ°´å°
            sequential_generation: é¡ºåºç”Ÿæˆæ¨¡å¼

        Returns:
            tuple: (è¿ç¯ç”»å›¾åƒ, æ•…äº‹æ–‡æœ¬, æ•…äº‹ç»“æ„, ç”Ÿæˆä¿¡æ¯)
        """
        try:
            _log_info("ğŸ“š å¼€å§‹åˆ›ä½œè¿ç¯ç”»æ•…äº‹ä¹¦...")
            _log_info(f"ğŸ“ æ•…äº‹æç¤º: {story_prompt[:100]}...")
            _log_info(f"ğŸ¨ å›¾åƒé£æ ¼: {image_style}, åˆ†è¾¨ç‡: {resolution}")

            # æ”¶é›†æ‰€æœ‰å‚è€ƒå›¾ç‰‡
            all_reference_images = self._collect_reference_images(
                reference_images, reference_image_2, reference_image_3, reference_image_4,
                reference_image_5, reference_image_6, reference_image_7, reference_image_8,
                reference_image_9, reference_image_10
            )
            _log_info(f"ğŸ–¼ï¸ æ”¶é›†åˆ° {len(all_reference_images)} å¼ å‚è€ƒå›¾ç‰‡")

            # 1. ç”Ÿæˆæ•…äº‹ç»“æ„
            story_structure = self._generate_story_structure(
                story_prompt, mirror_site, text_model, story_length, 
                character_description, background_style, story_theme, 
                api_key, temperature, max_tokens
            )

            if not story_structure:
                error_msg = "æ•…äº‹ç»“æ„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ•…äº‹ç»“æ„"
                _log_warning(error_msg)
                # åˆ›å»ºé»˜è®¤æ•…äº‹ç»“æ„ä½œä¸ºé™çº§æ–¹æ¡ˆ
                story_structure = self._create_default_story_structure(story_prompt, story_length)

            # 2. è§£ææ•…äº‹ç»“æ„ï¼Œç”Ÿæˆåœºæ™¯æè¿°
            scenes = self._parse_story_structure(story_structure)
            _log_info(f"ğŸ“– è§£æå‡º {len(scenes)} ä¸ªåœºæ™¯")

            # è‹¥åœºæ™¯æ•°è¿‡å°‘ï¼Œåˆ™æ ¹æ®æ•…äº‹é•¿åº¦è¿›è¡Œæ‰©å±•ï¼Œç¡®ä¿èƒ½åˆ†é¡µæµè§ˆ
            desired_counts = {"short": 3, "medium": 6, "long": 9}
            desired = desired_counts.get(story_length, 6)
            if len(scenes) < desired and len(scenes) > 0:
                base_len = len(scenes)
                _log_warning(f"åœºæ™¯æ•°ä¸è¶³ {desired}ï¼Œå°†ä» {base_len} æ‰©å±•...")
                i = 0
                while len(scenes) < desired:
                    src = scenes[i % base_len]
                    clone = {
                        "scene_number": len(scenes) + 1,
                        "title": f"{src.get('title','åœºæ™¯')} Â· å˜ä½“ {len(scenes)+1-base_len}",
                        "description": f"{src.get('description','')} (variation {len(scenes)+1-base_len})",
                        "dialogue": src.get('dialogue', ''),
                        "narration": src.get('narration', '')
                    }
                    scenes.append(clone)
                    i += 1
                _log_info(f"âœ… åœºæ™¯å·²æ‰©å±•è‡³ {len(scenes)} ä¸ª")

            # 3. ç”Ÿæˆæ¯ä¸ªåœºæ™¯çš„å›¾åƒ
            comic_images = []
            generation_info = f"è¿ç¯ç”»åˆ›ä½œå®Œæˆ\næ•…äº‹é•¿åº¦: {story_length}\nå›¾åƒé£æ ¼: {image_style}\nåˆ†è¾¨ç‡: {resolution}\nåœºæ™¯æ•°é‡: {len(scenes)}\n"

            for i, scene in enumerate(scenes):
                _log_info(f"ğŸ¬ ç”Ÿæˆç¬¬ {i+1}/{len(scenes)} ä¸ªåœºæ™¯: {scene['title']}")
                
                # ç”Ÿæˆåœºæ™¯å›¾åƒ
                scene_image = self._generate_scene_image(
                    scene, mirror_site, image_model, image_style, 
                    resolution, aspect_ratio, all_reference_images, 
                    watermark, api_key, i
                )
                
                if scene_image is not None:
                    comic_images.append(scene_image)
                    generation_info += f"åœºæ™¯ {i+1}: âœ… ç”ŸæˆæˆåŠŸ\n"
                else:
                    generation_info += f"åœºæ™¯ {i+1}: âŒ ç”Ÿæˆå¤±è´¥\n"

            if not comic_images:
                error_msg = "æ‰€æœ‰åœºæ™¯å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤å›¾åƒ"
                _log_warning(error_msg)
                # åˆ›å»ºé»˜è®¤å›¾åƒä½œä¸ºé™çº§æ–¹æ¡ˆ
                final_comic = self._create_default_comic_image(aspect_ratio)
                generation_info += "âš ï¸ ä½¿ç”¨é»˜è®¤å›¾åƒä½œä¸ºé™çº§æ–¹æ¡ˆ\n"
            else:
                # 4. ç»„åˆæ‰€æœ‰å›¾åƒä¸ºè¿ç¯ç”»æ‰¹æ¬¡ï¼ˆä¸æ‹¼æ¥ï¼ŒæŒ‰æ‰¹æ¬¡è¾“å‡ºä»¥ä¾¿åˆ†é¡µæµè§ˆï¼‰
                final_comic = self._stack_images_as_batch(comic_images)
            
            _log_info(f"âœ… è¿ç¯ç”»åˆ›ä½œå®Œæˆï¼Œå…±ç”Ÿæˆ {len(comic_images)} ä¸ªåœºæ™¯")
            return (final_comic, story_structure, self._format_story_structure(scenes), generation_info)

        except Exception as e:
            error_msg = f"è¿ç¯ç”»åˆ›ä½œå¤±è´¥: {str(e)}"
            _log_error(error_msg)
            return (None, "", "", f"âŒ {error_msg}")

    def _collect_reference_images(self, *reference_images):
        """æ”¶é›†æ‰€æœ‰éç©ºçš„å‚è€ƒå›¾ç‰‡"""
        try:
            all_images = []
            for img in reference_images:
                if img is not None:
                    all_images.append(img)
            return all_images
        except Exception as e:
            _log_error(f"æ”¶é›†å‚è€ƒå›¾ç‰‡å¤±è´¥: {str(e)}")
            return []

    def _create_default_story_structure(self, story_prompt, story_length):
        """åˆ›å»ºé»˜è®¤æ•…äº‹ç»“æ„ä½œä¸ºé™çº§æ–¹æ¡ˆ"""
        try:
            # æ ¹æ®æ•…äº‹é•¿åº¦ç¡®å®šåœºæ™¯æ•°é‡
            scene_counts = {"short": 3, "medium": 5, "long": 8}
            scene_count = scene_counts.get(story_length, 5)

            # æå–æ•…äº‹ä¸»é¢˜å…³é”®è¯ï¼ˆç®€å•å¤„ç†ï¼‰
            theme = story_prompt[:30] if len(story_prompt) > 30 else story_prompt

            # åˆ›å»ºç®€å•çš„æ•…äº‹ç»“æ„
            story_structure = {
                "title": f"{theme}çš„æ•…äº‹",
                "summary": f"è¿™æ˜¯ä¸€ä¸ªæ¸©é¦¨çš„æ•…äº‹ã€‚",
                "scenes": []
            }

            # åˆ›å»ºæ›´åˆç†çš„é»˜è®¤åœºæ™¯æè¿°
            default_scenes = [
                {
                    "title": "å¼€å§‹",
                    "description": "æ•…äº‹çš„å¼€å§‹ï¼Œä»‹ç»ä¸»è¦è§’è‰²å’Œåœºæ™¯",
                    "dialogue": "è®©æˆ‘ä»¬å¼€å§‹è¿™ä¸ªæ•…äº‹å§ï¼",
                    "narration": "åœ¨ä¸€ä¸ªç¾å¥½çš„æ—¥å­é‡Œï¼Œæ•…äº‹å¼€å§‹äº†..."
                },
                {
                    "title": "å‘å±•",
                    "description": "æ•…äº‹æƒ…èŠ‚çš„å‘å±•ï¼Œè§’è‰²å¼€å§‹è¡ŒåŠ¨",
                    "dialogue": "æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼",
                    "narration": "è§’è‰²ä»¬è¸ä¸Šäº†æ–°çš„æ—…ç¨‹..."
                },
                {
                    "title": "é«˜æ½®",
                    "description": "æ•…äº‹çš„é«˜æ½®éƒ¨åˆ†ï¼Œé‡åˆ°æŒ‘æˆ˜",
                    "dialogue": "æˆ‘ä»¬ä¸€å®šèƒ½å…‹æœå›°éš¾ï¼",
                    "narration": "åœ¨å…³é”®æ—¶åˆ»ï¼Œè§’è‰²ä»¬å±•ç°äº†å‹‡æ°”..."
                },
                {
                    "title": "è½¬æŠ˜",
                    "description": "æ•…äº‹çš„è½¬æŠ˜ç‚¹ï¼Œé—®é¢˜å¾—åˆ°è§£å†³",
                    "dialogue": "å¤ªå¥½äº†ï¼Œæˆ‘ä»¬æˆåŠŸäº†ï¼",
                    "narration": "ç»è¿‡åŠªåŠ›ï¼Œé—®é¢˜ç»ˆäºè§£å†³äº†..."
                },
                {
                    "title": "ç»“å±€",
                    "description": "æ•…äº‹çš„ç»“å±€ï¼Œåœ†æ»¡æ”¶åœº",
                    "dialogue": "è¿™çœŸæ˜¯ä¸€æ¬¡ç¾å¥½çš„ç»å†ï¼",
                    "narration": "æ•…äº‹åœ¨æ¸©é¦¨çš„æ°›å›´ä¸­ç»“æŸäº†..."
                }
            ]

            # æ ¹æ®åœºæ™¯æ•°é‡é€‰æ‹©åˆé€‚çš„é»˜è®¤åœºæ™¯
            for i in range(scene_count):
                if i < len(default_scenes):
                    scene = default_scenes[i].copy()
                else:
                    # å¦‚æœéœ€è¦æ›´å¤šåœºæ™¯ï¼Œä½¿ç”¨é€šç”¨æ¨¡æ¿
                    scene = {
                        "title": f"åœºæ™¯ {i + 1}",
                        "description": f"æ•…äº‹ç»§ç»­å‘å±•ï¼Œå±•ç°æ›´å¤šç²¾å½©å†…å®¹",
                        "dialogue": f"è§’è‰²ä»¬ç»§ç»­ä»–ä»¬çš„æ•…äº‹...",
                        "narration": f"åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼Œæ•…äº‹ç»§ç»­å±•å¼€..."
                    }

                scene["scene_number"] = i + 1
                story_structure["scenes"].append(scene)

            _log_warning(f"âš ï¸ ä½¿ç”¨é»˜è®¤æ•…äº‹ç»“æ„ï¼ˆæ–‡æœ¬ç”Ÿæˆå¯èƒ½å¤±è´¥ï¼‰ï¼ŒåŒ…å« {scene_count} ä¸ªåœºæ™¯")
            _log_warning(f"âš ï¸ å»ºè®®æ£€æŸ¥APIé…ç½®å’Œç½‘ç»œè¿æ¥ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•…äº‹å†…å®¹")
            return story_structure

        except Exception as e:
            _log_error(f"åˆ›å»ºé»˜è®¤æ•…äº‹ç»“æ„å¤±è´¥: {str(e)}")
            return None

    def _create_default_comic_image(self, aspect_ratio):
        """åˆ›å»ºé»˜è®¤è¿ç¯ç”»å›¾åƒä½œä¸ºé™çº§æ–¹æ¡ˆ"""
        try:
            import torch
            import numpy as np
            
            # æ ¹æ®å®½é«˜æ¯”ç¡®å®šå›¾åƒå°ºå¯¸
            aspect_ratios = {
                "1:1": (512, 512),
                "4:3": (512, 384),
                "3:4": (384, 512),
                "16:9": (512, 288),
                "9:16": (288, 512)
            }
            
            width, height = aspect_ratios.get(aspect_ratio, (512, 384))
            
            # åˆ›å»ºé»˜è®¤å›¾åƒï¼ˆç™½è‰²èƒŒæ™¯ï¼Œé»‘è‰²æ–‡å­—æç¤ºï¼‰
            default_image = torch.ones((1, height, width, 3), dtype=torch.float32)
            
            _log_info(f"ğŸ–¼ï¸ åˆ›å»ºé»˜è®¤è¿ç¯ç”»å›¾åƒï¼Œå°ºå¯¸: {width}x{height}")
            return default_image
            
        except Exception as e:
            _log_error(f"åˆ›å»ºé»˜è®¤å›¾åƒå¤±è´¥: {str(e)}")
            # è¿”å›æœ€å°çš„æœ‰æ•ˆå›¾åƒ
            return torch.ones((1, 256, 256, 3), dtype=torch.float32)

    def _generate_story_structure(self, story_prompt, mirror_site, text_model, story_length, 
                                 character_description, background_style, story_theme, api_key, temperature, max_tokens):
        """ç”Ÿæˆæ•…äº‹ç»“æ„"""
        for attempt in range(self.max_retries):
            try:
                _log_info(f"ğŸ“ å°è¯•ç”Ÿæˆæ•…äº‹ç»“æ„ (ç¬¬ {attempt + 1}/{self.max_retries} æ¬¡)")
                
                # æ„å»ºç³»ç»Ÿæç¤ºè¯
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å„¿ç«¥æ•…äº‹åˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿åˆ›ä½œè¿ç¯ç”»æ•…äº‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚åˆ›ä½œä¸€ä¸ªç»“æ„åŒ–çš„æ•…äº‹ã€‚

æ•…äº‹è¦æ±‚ï¼š
- æ•…äº‹é•¿åº¦ï¼š{story_length}ï¼ˆshort: 3-5ä¸ªåœºæ™¯ï¼Œmedium: 6-10ä¸ªåœºæ™¯ï¼Œlong: 11-15ä¸ªåœºæ™¯ï¼‰
- è§’è‰²æè¿°ï¼š{character_description if character_description else "æ ¹æ®æ•…äº‹å†…å®¹è‡ªç”±åˆ›ä½œ"}
- èƒŒæ™¯é£æ ¼ï¼š{background_style if background_style else "æ ¹æ®æ•…äº‹å†…å®¹è‡ªç”±åˆ›ä½œ"}
- æ•…äº‹ä¸»é¢˜ï¼š{story_theme if story_theme else "æ¸©é¦¨ã€ç§¯æå‘ä¸Š"}

âš ï¸ é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡å­—è¯´æ˜æˆ–markdownæ ‡è®°ï¼š

{{
    "title": "æ•…äº‹æ ‡é¢˜",
    "summary": "æ•…äº‹ç®€ä»‹",
    "scenes": [
        {{
            "scene_number": 1,
            "title": "åœºæ™¯æ ‡é¢˜",
            "description": "åœºæ™¯æè¿°ï¼ˆç”¨äºå›¾åƒç”Ÿæˆï¼‰",
            "dialogue": "å¯¹è¯å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰",
            "narration": "æ—ç™½å†…å®¹"
        }}
    ]
}}

JSONæ ¼å¼è¦æ±‚ï¼š
1. æ‰€æœ‰å­—ç¬¦ä¸²å€¼å¿…é¡»ç”¨åŒå¼•å·åŒ…è£¹
2. å­—ç¬¦ä¸²ä¸­çš„å¼•å·å¿…é¡»è½¬ä¹‰ä¸º \\"
3. ä¸è¦åœ¨å­—ç¬¦ä¸²ä¸­ä½¿ç”¨æ¢è¡Œç¬¦
4. ç¡®ä¿æ‰€æœ‰æ‹¬å·æ­£ç¡®é—­åˆ
5. æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ åä¸è¦æœ‰é€—å·
6. åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—

è¯·ç¡®ä¿æ¯ä¸ªåœºæ™¯çš„æè¿°éƒ½é€‚åˆå›¾åƒç”Ÿæˆï¼ŒåŒ…å«å…·ä½“çš„è§†è§‰å…ƒç´ ã€‚"""

                # è°ƒç”¨æ–‡æœ¬ç”ŸæˆAPI
                text_node = DoubaoSeed16Node()
                generated_text, _, _ = text_node.generate_text(
                    prompt=story_prompt,
                    mirror_site=mirror_site,
                    model=text_model,
                    api_key=api_key,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    system_prompt=system_prompt
                )

                if generated_text and len(generated_text.strip()) > 0:
                    _log_info("âœ… æ•…äº‹ç»“æ„ç”ŸæˆæˆåŠŸ")
                    return generated_text
                else:
                    _log_warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è¿”å›ç©ºç»“æœ")

            except Exception as e:
                _log_error(f"ç¬¬ {attempt + 1} æ¬¡æ•…äº‹ç»“æ„ç”Ÿæˆå¤±è´¥: {str(e)}")
                if attempt == self.max_retries - 1:
                    _log_error("æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†")
                    return None
                else:
                    _log_info(f"ç­‰å¾… {2 ** attempt} ç§’åé‡è¯•...")
                    import time
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

        return None

    def _parse_story_structure(self, story_structure):
        """è§£ææ•…äº‹ç»“æ„"""
        try:
            import json
            import re

            _log_info(f"ğŸ” å¼€å§‹è§£ææ•…äº‹ç»“æ„ï¼Œç±»å‹: {type(story_structure)}")

            # å…è®¸ç›´æ¥ä¼  dict
            if isinstance(story_structure, dict):
                data = story_structure
                _log_info("âœ… æ•…äº‹ç»“æ„å·²ç»æ˜¯å­—å…¸æ ¼å¼")
            else:
                # æ‰“å°å‰100ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                preview = str(story_structure)[:100] if story_structure else "ç©º"
                _log_info(f"ğŸ” æ•…äº‹ç»“æ„å­—ç¬¦ä¸²é¢„è§ˆ: {preview}")

                # é¢„å¤„ç†ï¼šç§»é™¤markdownä»£ç å—æ ‡è®°
                story_str = str(story_structure).strip()
                if story_str.startswith("```"):
                    lines = story_str.split('\n')
                    if len(lines) > 1:
                        story_str = '\n'.join(lines[1:])
                        if story_str.endswith("```"):
                            story_str = story_str[:-3].strip()
                    _log_info("âœ… ç§»é™¤äº†markdownä»£ç å—æ ‡è®°")

                # å°è¯•æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{.*\}', story_str, re.DOTALL)
                if json_match:
                    try:
                        data = json.loads(json_match.group())
                        _log_info("âœ… JSONè§£ææˆåŠŸ")
                    except json.JSONDecodeError as je:
                        _log_warning(f"âš ï¸ JSONè§£æå¤±è´¥: {je}")
                        data = None
                else:
                    _log_warning("âš ï¸ æœªæ‰¾åˆ°JSONå¯¹è±¡")
                    data = None

            if data is None:
                # å¦‚æœæ— æ³•è§£æJSONï¼Œå°è¯•æŒ‰è¡Œè§£æ
                _log_info("ğŸ”„ å°è¯•æŒ‰è¡Œè§£ææ•…äº‹ç»“æ„")
                lines = story_structure.split('\n') if isinstance(story_structure, str) else []
                scenes = []
                current_scene = {}

                for line in lines:
                    line = line.strip()
                    if 'åœºæ™¯' in line or 'Scene' in line.lower():
                        if current_scene:
                            scenes.append(current_scene)
                        current_scene = {
                            'title': line,
                            'description': '',
                            'dialogue': '',
                            'narration': ''
                        }
                    elif current_scene and line:
                        if not current_scene['description']:
                            current_scene['description'] = line
                        elif not current_scene['dialogue']:
                            current_scene['dialogue'] = line

                if current_scene:
                    scenes.append(current_scene)

                _log_info(f"âœ… æŒ‰è¡Œè§£æå‡º {len(scenes)} ä¸ªåœºæ™¯")
                return scenes
            else:
                scenes = data.get('scenes', [])
                _log_info(f"âœ… ä»JSONè§£æå‡º {len(scenes)} ä¸ªåœºæ™¯")
                return scenes

        except Exception as e:
            _log_error(f"æ•…äº‹ç»“æ„è§£æå¤±è´¥: {str(e)}")
            import traceback
            _log_error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def _generate_scene_image(self, scene, mirror_site, image_model, image_style, 
                             resolution, aspect_ratio, reference_images, watermark, api_key, scene_index=0):
        """ç”Ÿæˆåœºæ™¯å›¾åƒ"""
        for attempt in range(self.max_retries):
            try:
                _log_info(f"ğŸ¨ å°è¯•ç”Ÿæˆåœºæ™¯å›¾åƒ (ç¬¬ {attempt + 1}/{self.max_retries} æ¬¡)")
                
                # æ„å»ºå›¾åƒç”Ÿæˆæç¤ºè¯
                image_prompt = f"{scene['description']}, {image_style} style, high quality, detailed"
                
                # é€‰æ‹©å‚è€ƒå›¾ç‰‡ï¼ˆå¾ªç¯ä½¿ç”¨å¤šå¼ å‚è€ƒå›¾ç‰‡ï¼‰
                selected_reference = None
                if reference_images and len(reference_images) > 0:
                    selected_reference = reference_images[scene_index % len(reference_images)]
                    _log_info(f"ğŸ¨ ä½¿ç”¨å‚è€ƒå›¾ç‰‡ {scene_index % len(reference_images) + 1}/{len(reference_images)}")
                
                # è°ƒç”¨å›¾åƒç”ŸæˆAPI
                image_node = SeedReam4APISingleNode()
                generated_image, _, _ = image_node.generate_image(
                    prompt=image_prompt,
                    mirror_site=mirror_site,
                    model=image_model,
                    resolution=resolution,
                    aspect_ratio=aspect_ratio,
                    api_key=api_key,
                    watermark=watermark,
                    image=selected_reference
                )
                
                if generated_image is not None:
                    _log_info("âœ… åœºæ™¯å›¾åƒç”ŸæˆæˆåŠŸ")
                    return generated_image
                else:
                    _log_warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è¿”å›ç©ºå›¾åƒ")

            except Exception as e:
                _log_error(f"ç¬¬ {attempt + 1} æ¬¡åœºæ™¯å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
                if attempt == self.max_retries - 1:
                    _log_error("æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†")
                    return None
                else:
                    _log_info(f"ç­‰å¾… {2 ** attempt} ç§’åé‡è¯•...")
                    import time
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

        return None

    def _combine_comic_images(self, comic_images, aspect_ratio):
        """ç»„åˆè¿ç¯ç”»å›¾åƒ"""
        try:
            if not comic_images:
                return None
            
            # ç®€å•çš„å›¾åƒç»„åˆé€»è¾‘
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°æ›´å¤æ‚çš„å¸ƒå±€
            return comic_images[0]  # æš‚æ—¶è¿”å›ç¬¬ä¸€å¼ å›¾åƒ

        except Exception as e:
            _log_error(f"å›¾åƒç»„åˆå¤±è´¥: {str(e)}")
            return None

    def _stack_images_as_batch(self, images):
        """å°†å¤šå¼ å›¾åƒå †å ä¸ºComfyUIå¯è¯†åˆ«çš„å›¾åƒæ‰¹æ¬¡ (B,H,W,C)ï¼Œè‡ªåŠ¨è°ƒæ•´å°ºå¯¸"""
        try:
            import torch
            import torch.nn.functional as F

            # è¿‡æ»¤æœ‰æ•ˆå›¾åƒ
            valid = [img for img in images if img is not None]
            if not valid:
                _log_error("æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒå¯ä»¥å †å ")
                return None

            # æ”¶é›†æ‰€æœ‰å¼ é‡
            tensors = []
            for i, img in enumerate(valid):
                if isinstance(img, torch.Tensor) and img.ndim == 4 and img.shape[0] == 1:
                    tensors.append(img)
                    _log_info(f"ğŸ“Š å›¾åƒ {i+1} å°ºå¯¸: {img.shape}")
                else:
                    _log_warning(f"âš ï¸ å›¾åƒ {i+1} æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡")

            if not tensors:
                _log_error("æ²¡æœ‰æœ‰æ•ˆçš„å¼ é‡å¯ä»¥å †å ")
                return None

            # æ£€æŸ¥æ‰€æœ‰å›¾åƒå°ºå¯¸æ˜¯å¦ä¸€è‡´
            shapes = [t.shape for t in tensors]
            if len(set(shapes)) > 1:
                _log_warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸åŒå°ºå¯¸çš„å›¾åƒ: {shapes}")

                # æ‰¾åˆ°æœ€å¸¸è§çš„å°ºå¯¸ä½œä¸ºç›®æ ‡å°ºå¯¸
                from collections import Counter
                shape_counts = Counter(shapes)
                target_shape = shape_counts.most_common(1)[0][0]
                target_h, target_w = target_shape[1], target_shape[2]

                _log_info(f"ğŸ”§ å°†æ‰€æœ‰å›¾åƒè°ƒæ•´ä¸ºç›®æ ‡å°ºå¯¸: {target_h}x{target_w}")

                # è°ƒæ•´æ‰€æœ‰å›¾åƒåˆ°ç›®æ ‡å°ºå¯¸
                resized_tensors = []
                for i, tensor in enumerate(tensors):
                    if tensor.shape != target_shape:
                        # è°ƒæ•´å°ºå¯¸ (1, H, W, C) -> (1, C, H, W) -> resize -> (1, H, W, C)
                        _log_info(f"ğŸ”§ è°ƒæ•´å›¾åƒ {i+1} ä» {tensor.shape} åˆ° {target_shape}")

                        # è½¬æ¢ä¸º (1, C, H, W) æ ¼å¼
                        tensor_chw = tensor.permute(0, 3, 1, 2)

                        # ä½¿ç”¨åŒçº¿æ€§æ’å€¼è°ƒæ•´å°ºå¯¸
                        resized = F.interpolate(
                            tensor_chw,
                            size=(target_h, target_w),
                            mode='bilinear',
                            align_corners=False
                        )

                        # è½¬æ¢å› (1, H, W, C) æ ¼å¼
                        resized = resized.permute(0, 2, 3, 1)
                        resized_tensors.append(resized)
                    else:
                        resized_tensors.append(tensor)

                tensors = resized_tensors

            # å †å æ‰€æœ‰å›¾åƒ
            batch = torch.cat(tensors, dim=0).contiguous()
            _log_info(f"ğŸ“š å·²å †å ä¸ºå›¾åƒæ‰¹æ¬¡ï¼Œæ•°é‡: {batch.shape[0]}, å½¢çŠ¶: {batch.shape}")
            return batch

        except Exception as e:
            _log_error(f"å †å å›¾åƒæ‰¹æ¬¡å¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())

            # å¦‚æœå †å å¤±è´¥ï¼Œè‡³å°‘è¿”å›ç¬¬ä¸€å¼ å›¾åƒ
            try:
                if images and len(images) > 0 and images[0] is not None:
                    _log_warning("âš ï¸ å †å å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€å¼ å›¾åƒ")
                    return images[0]
            except:
                pass

            return None

    def _format_story_structure(self, scenes):
        """æ ¼å¼åŒ–æ•…äº‹ç»“æ„è¾“å‡º"""
        try:
            formatted = "ğŸ“š è¿ç¯ç”»æ•…äº‹ç»“æ„\n\n"
            for i, scene in enumerate(scenes):
                formatted += f"åœºæ™¯ {i+1}: {scene.get('title', 'æœªå‘½å')}\n"
                formatted += f"æè¿°: {scene.get('description', 'æ— æè¿°')}\n"
                if scene.get('dialogue'):
                    formatted += f"å¯¹è¯: {scene['dialogue']}\n"
                if scene.get('narration'):
                    formatted += f"æ—ç™½: {scene['narration']}\n"
                formatted += "\n"
            
            return formatted

        except Exception as e:
            _log_error(f"æ•…äº‹ç»“æ„æ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            return "æ ¼å¼åŒ–å¤±è´¥"


# åˆ†é¡µæµè§ˆèŠ‚ç‚¹ï¼šä»å›¾åƒæ‰¹æ¬¡ä¸­æŒ‰é¡µé€‰æ‹©ä¸€å¼ ï¼Œç”¨äºè¿ç¯ç”»ç¿»é¡µ
class ComicPageSelectorNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "page_index": ("INT", {"default": 1, "min": 1, "max": 9999, "step": 1}),
                "loop": ("BOOLEAN", {"default": True}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("page_image", "page_info")
    FUNCTION = "select_page"
    CATEGORY = "Ken-Chen/Doubao"

    def select_page(self, images, page_index=1, loop=True):
        try:
            import torch
            if images is None or not isinstance(images, torch.Tensor) or images.ndim != 4:
                return (None, "æ— æ•ˆçš„å›¾åƒæ‰¹æ¬¡")
            total = int(images.shape[0])
            if total == 0:
                return (None, "ç©ºçš„å›¾åƒæ‰¹æ¬¡")
            # å°†1-basedé¡µç è½¬æ¢ä¸ºç´¢å¼•
            idx = page_index - 1
            if loop:
                idx = idx % total
            else:
                idx = max(0, min(idx, total - 1))
            # å¼ºåˆ¶æˆè¿ç»­å†…å­˜ï¼Œé¿å…ä¸Šæ¸¸æŸäº›æ“ä½œå¯¼è‡´çš„è§†å›¾åˆ‡ç‰‡é—®é¢˜
            selected = images[idx:idx+1, ...].contiguous()
            info = f"ç¬¬ {idx + 1}/{total} é¡µ"
            _log_info(f"ğŸ“– åˆ†é¡µæµè§ˆ: {info}")
            return (selected, info)
        except Exception as e:
            _log_error(f"åˆ†é¡µé€‰æ‹©å¤±è´¥: {str(e)}")
            return (None, f"é”™è¯¯: {str(e)}")


# ç”Ÿæˆå¯äº¤äº’HTMLæµè§ˆæ–‡ä»¶çš„èŠ‚ç‚¹
class ComicHTMLViewerNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "story_structure": ("STRING", {"multiline": True, "default": ""}),
                "title": ("STRING", {"default": "æˆ‘çš„è¿ç¯ç”»"}),
            },
            "optional": {
                "output_filename": ("STRING", {"default": "comic_story.html"}),
                "transition_effect": (["page-turn", "fade", "slide", "flip", "none"], {"default": "page-turn"}),
                "transition_duration": ("FLOAT", {"default": 1.5, "min": 0.1, "max": 3.0, "step": 0.1}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("viewer_path", "summary")
    FUNCTION = "create_viewer"
    CATEGORY = "Ken-Chen/Doubao"

    def _tensor_batch_to_base64_list(self, images, quality=85, max_size=None):
        """
        å°†å›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64åˆ—è¡¨ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ”¯æŒå‹ç¼©å’Œç¼©æ”¾ï¼‰

        Args:
            images: å›¾åƒå¼ é‡
            quality: JPEGè´¨é‡ (1-100)ï¼Œé»˜è®¤85
            max_size: æœ€å¤§å°ºå¯¸ï¼ˆå®½æˆ–é«˜ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸ç¼©æ”¾

        Returns:
            base64ç¼–ç çš„å›¾ç‰‡åˆ—è¡¨
        """
        try:
            import torch
            import numpy as np
            from PIL import Image
            import io, base64
            if images is None or not isinstance(images, torch.Tensor) or images.ndim != 4:
                return []
            result = []
            b, h, w, c = images.shape
            data = images.clamp(0.0, 1.0).mul(255.0).byte().cpu().numpy()

            _log_info(f"ğŸ–¼ï¸ å¼€å§‹ç¼–ç  {b} å¼ å›¾ç‰‡ï¼ˆè´¨é‡={quality}, æœ€å¤§å°ºå¯¸={max_size}ï¼‰")

            for i in range(b):
                arr = data[i]
                img = Image.fromarray(arr, mode="RGB")

                # ğŸš€ ä¼˜åŒ–1ï¼šç¼©æ”¾å›¾ç‰‡ä»¥å‡å°æ–‡ä»¶å¤§å°
                if max_size is not None:
                    original_size = img.size
                    if img.width > max_size or img.height > max_size:
                        if img.width > img.height:
                            new_width = max_size
                            new_height = int(img.height * (max_size / img.width))
                        else:
                            new_height = max_size
                            new_width = int(img.width * (max_size / img.height))
                        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                        _log_info(f"  å›¾ç‰‡ {i+1}: ç¼©æ”¾ {original_size} -> {img.size}")

                # ğŸš€ ä¼˜åŒ–2ï¼šä½¿ç”¨JPEGæ ¼å¼å‹ç¼©ï¼ˆæ¯”PNGå°å¾ˆå¤šï¼‰
                buf = io.BytesIO()
                img.save(buf, format="JPEG", quality=quality, optimize=True)
                encoded = base64.b64encode(buf.getvalue()).decode("utf-8")
                result.append(f"data:image/jpeg;base64,{encoded}")

                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                size_kb = len(encoded) / 1024
                _log_info(f"  å›¾ç‰‡ {i+1}: {size_kb:.1f} KB")

            total_size_mb = sum(len(s) for s in result) / 1024 / 1024
            _log_info(f"âœ… å›¾ç‰‡ç¼–ç å®Œæˆï¼Œæ€»å¤§å°: {total_size_mb:.2f} MB")

            return result
        except Exception as e:
            _log_error(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}")
            return []

    def _parse_scenes_from_structure(self, story_structure):
        try:
            import json
            import re

            # è°ƒè¯•ä¿¡æ¯
            _log_info(f"ğŸ” å¼€å§‹è§£ææ•…äº‹ç»“æ„ï¼Œç±»å‹: {type(story_structure)}")

            if not story_structure:
                _log_warning("âš ï¸ æ•…äº‹ç»“æ„ä¸ºç©º")
                return []

            if isinstance(story_structure, dict):
                data = story_structure
                _log_info("âœ… æ•…äº‹ç»“æ„å·²ç»æ˜¯å­—å…¸æ ¼å¼")
            else:
                # æ‰“å°å‰100ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                preview = str(story_structure)[:100] if story_structure else "ç©º"
                _log_info(f"ğŸ” æ•…äº‹ç»“æ„å­—ç¬¦ä¸²é¢„è§ˆ: {preview}")

                # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå»é™¤markdownä»£ç å—ï¼‰
                story_str = str(story_structure).strip()

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¼å¼åŒ–æ–‡æœ¬ï¼ˆä»¥"ğŸ“š è¿ç¯ç”»æ•…äº‹ç»“æ„"å¼€å¤´ï¼‰
                if story_str.startswith("ğŸ“š è¿ç¯ç”»æ•…äº‹ç»“æ„") or "åœºæ™¯ 1:" in story_str or "åœºæ™¯ 2:" in story_str:
                    _log_warning("âš ï¸ æ£€æµ‹åˆ°æ ¼å¼åŒ–æ–‡æœ¬è€Œä¸æ˜¯JSON")
                    _log_warning("ğŸ’¡ æç¤ºï¼šè¯·è¿æ¥ DoubaoComicBookNode çš„ç¬¬2ä¸ªè¾“å‡º(story_text)è€Œä¸æ˜¯ç¬¬3ä¸ªè¾“å‡º(story_structure)")
                    _log_info("ğŸ”„ å°è¯•ä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­æå–åœºæ™¯ä¿¡æ¯...")
                    return self._parse_formatted_text(story_str)

                # ç§»é™¤markdownä»£ç å—æ ‡è®°
                if story_str.startswith("```"):
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œåçš„å†…å®¹
                    lines = story_str.split('\n')
                    if len(lines) > 1:
                        # ç§»é™¤ç¬¬ä¸€è¡Œçš„```jsonæˆ–```
                        story_str = '\n'.join(lines[1:])
                        # ç§»é™¤æœ€åçš„```
                        if story_str.endswith("```"):
                            story_str = story_str[:-3].strip()

                # å°è¯•æå–JSONå¯¹è±¡
                json_match = re.search(r'\{.*\}', story_str, re.DOTALL)
                if json_match:
                    story_str = json_match.group()
                    _log_info("âœ… æˆåŠŸæå–JSONå¯¹è±¡")

                try:
                    data = json.loads(story_str)
                    _log_info("âœ… JSONè§£ææˆåŠŸ")
                except json.JSONDecodeError as je:
                    _log_warning(f"âš ï¸ JSONè§£æå¤±è´¥: {je}")
                    _log_info(f"ğŸ” é”™è¯¯ä½ç½®: ç¬¬{je.lineno}è¡Œ, ç¬¬{je.colno}åˆ—")
                    _log_info(f"ğŸ” é”™è¯¯é™„è¿‘å†…å®¹: {story_str[max(0, je.pos-50):min(len(story_str), je.pos+50)]}")
                    _log_info("ğŸ”§ å°è¯•ä¿®å¤JSONæ ¼å¼...")

                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONé”™è¯¯
                    fixed_str = story_str

                    # 1. ç§»é™¤æ§åˆ¶å­—ç¬¦å’Œéæ³•å­—ç¬¦
                    fixed_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', fixed_str)

                    # 2. ä¿®å¤æœªè½¬ä¹‰çš„å¼•å·ï¼ˆåœ¨JSONå€¼ä¸­ï¼‰
                    # å…ˆæ‰¾åˆ°æ‰€æœ‰çš„é”®å€¼å¯¹ï¼Œç„¶åä¿®å¤å€¼ä¸­çš„å¼•å·
                    def fix_quotes_in_value(match):
                        key = match.group(1)
                        value = match.group(2)
                        # è½¬ä¹‰å€¼ä¸­çš„å¼•å·ï¼ˆä½†ä¸è½¬ä¹‰å·²ç»è½¬ä¹‰çš„ï¼‰
                        value = re.sub(r'(?<!\\)"', r'\\"', value)
                        return f'"{key}": "{value}"'

                    # åŒ¹é… "key": "value" æ ¼å¼ï¼Œvalueä¸­å¯èƒ½æœ‰æœªè½¬ä¹‰çš„å¼•å·
                    fixed_str = re.sub(r'"([^"]+)":\s*"([^"]*(?:[^"\\]|\\.)*)(?=")', fix_quotes_in_value, fixed_str)

                    # 3. ç§»é™¤æœ€åä¸€ä¸ªå¯¹è±¡/æ•°ç»„çš„å¤šä½™é€—å·
                    fixed_str = re.sub(r',(\s*[}\]])', r'\1', fixed_str)

                    # 4. ä¿®å¤æœªé—­åˆçš„å­—ç¬¦ä¸²
                    lines = fixed_str.split('\n')
                    fixed_lines = []
                    in_string = False
                    for line in lines:
                        stripped = line.strip()
                        if not stripped or stripped.startswith('//'):
                            continue

                        # è®¡ç®—å¼•å·æ•°é‡ï¼ˆå¿½ç•¥è½¬ä¹‰çš„å¼•å·ï¼‰
                        quote_count = len(re.findall(r'(?<!\\)"', line))

                        # å¦‚æœå¼•å·æ•°é‡æ˜¯å¥‡æ•°ï¼Œè¯´æ˜æœ‰æœªé—­åˆçš„å¼•å·
                        if quote_count % 2 == 1:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯é”®å€¼å¯¹çš„å¼€å§‹
                            if ':' in line and not line.rstrip().endswith('"'):
                                line = line.rstrip() + '"'

                        fixed_lines.append(line)
                    fixed_str = '\n'.join(fixed_lines)

                    # 5. æ£€æŸ¥å¹¶è¡¥å…¨æœªé—­åˆçš„æ•°ç»„å’Œå¯¹è±¡
                    open_braces = fixed_str.count('{')
                    close_braces = fixed_str.count('}')
                    open_brackets = fixed_str.count('[')
                    close_brackets = fixed_str.count(']')

                    # è¡¥å…¨ç¼ºå¤±çš„é—­åˆæ‹¬å·
                    if open_brackets > close_brackets:
                        _log_info(f"ğŸ”§ è¡¥å…¨ {open_brackets - close_brackets} ä¸ªæ•°ç»„é—­åˆæ‹¬å·")
                        fixed_str += '\n' + '    ]' * (open_brackets - close_brackets)

                    if open_braces > close_braces:
                        _log_info(f"ğŸ”§ è¡¥å…¨ {open_braces - close_braces} ä¸ªå¯¹è±¡é—­åˆæ‹¬å·")
                        fixed_str += '\n' + '}' * (open_braces - close_braces)

                    # 6. å°è¯•å†æ¬¡è§£æ
                    try:
                        data = json.loads(fixed_str)
                        _log_info("âœ… JSONä¿®å¤æˆåŠŸ")
                    except json.JSONDecodeError as je2:
                        _log_error(f"âŒ JSONä¿®å¤å¤±è´¥: {je2}")

                        # 7. å°è¯•ä½¿ç”¨æ›´æ¿€è¿›çš„ä¿®å¤ç­–ç•¥
                        _log_info("ğŸ”§ å°è¯•æ¿€è¿›ä¿®å¤ç­–ç•¥...")
                        try:
                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åœºæ™¯æ•°ç»„
                            scenes_match = re.search(r'"scenes"\s*:\s*\[(.*)\]', fixed_str, re.DOTALL)
                            if scenes_match:
                                scenes_str = scenes_match.group(1)
                                # åˆ†å‰²åœºæ™¯å¯¹è±¡
                                scene_objects = re.findall(r'\{[^{}]*\}', scenes_str)

                                scenes = []
                                for scene_obj in scene_objects:
                                    try:
                                        scene = json.loads(scene_obj)
                                        scenes.append(scene)
                                    except:
                                        # å°è¯•æ‰‹åŠ¨è§£æ
                                        scene = {}
                                        for field in ['title', 'description', 'dialogue', 'narration']:
                                            field_match = re.search(f'"{field}"\\s*:\\s*"([^"]*)"', scene_obj)
                                            if field_match:
                                                scene[field] = field_match.group(1)
                                        if scene:
                                            scenes.append(scene)

                                if scenes:
                                    data = {"scenes": scenes}
                                    _log_info(f"âœ… æ¿€è¿›ä¿®å¤æˆåŠŸï¼Œæå–åˆ° {len(scenes)} ä¸ªåœºæ™¯")
                                else:
                                    raise ValueError("æ— æ³•æå–åœºæ™¯")
                            else:
                                raise ValueError("æœªæ‰¾åˆ°scenesæ•°ç»„")

                        except Exception as je3:
                            _log_error(f"âŒ æ¿€è¿›ä¿®å¤ä¹Ÿå¤±è´¥: {je3}")
                            _log_error(f"ğŸ” åŸå§‹å†…å®¹å‰500å­—ç¬¦: {story_str[:500]}")
                            _log_error(f"ğŸ” åŸå§‹å†…å®¹å500å­—ç¬¦: {story_str[-500:]}")
                            _log_warning("ğŸ”„ å°è¯•æŒ‰è¡Œè§£ææ•…äº‹ç»“æ„")
                            return self._parse_formatted_text(story_structure)

            scenes = data.get("scenes", [])
            _log_info(f"âœ… è§£æå‡º {len(scenes)} ä¸ªåœºæ™¯")

            parsed = []
            for i, s in enumerate(scenes, 1):
                # ç»„åˆæ‰€æœ‰å¯ç”¨çš„æ–‡æœ¬å†…å®¹
                text_parts = []

                # è·å–æè¿°ï¼ˆæ€»æ˜¯éœ€è¦ï¼Œå› ä¸ºè¿™æ˜¯å›¾åƒç”Ÿæˆçš„æç¤ºè¯ï¼‰
                description = s.get("description", "").strip()

                # æ·»åŠ æ—ç™½ï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
                narration = s.get("narration", "").strip()
                # è¿‡æ»¤æ‰å ä½ç¬¦æ–‡æœ¬ï¼ˆå¦‚"æ—ç™½æè¿° 1"ã€"æ—ç™½å†…å®¹"ç­‰ï¼‰
                is_narration_placeholder = re.match(r'^æ—ç™½(æè¿°|å†…å®¹|æ–‡å­—)?\s*\d*$', narration) if narration else True

                # æ·»åŠ å¯¹è¯ï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
                dialogue = s.get("dialogue", "").strip()
                # è¿‡æ»¤æ‰å ä½ç¬¦æ–‡æœ¬ï¼ˆå¦‚"è§’è‰²å¯¹è¯ 1"ã€"å¯¹è¯å†…å®¹"ç­‰ï¼‰
                is_dialogue_placeholder = re.match(r'^(è§’è‰²)?å¯¹è¯(å†…å®¹)?\s*\d*$', dialogue) if dialogue else True

                # æ£€æŸ¥æè¿°æ˜¯å¦æ˜¯å ä½ç¬¦
                is_description_placeholder = False
                if description:
                    if re.match(r'^(åœºæ™¯)?æè¿°\s*\d*$', description) or \
                       description.startswith("æ•…äº‹çš„ç¬¬") or \
                       description.startswith("åœºæ™¯çš„"):
                        is_description_placeholder = True

                # ç»„åˆæ–‡æœ¬ï¼šä¼˜å…ˆä½¿ç”¨æ—ç™½å’Œå¯¹è¯ï¼Œå¦‚æœéƒ½æ˜¯å ä½ç¬¦åˆ™ä½¿ç”¨æè¿°
                if narration and not is_narration_placeholder:
                    text_parts.append(f"æ—ç™½ï¼š{narration}")

                if dialogue and not is_dialogue_placeholder:
                    text_parts.append(f"å¯¹è¯ï¼š{dialogue}")

                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ—ç™½å’Œå¯¹è¯ï¼Œä½¿ç”¨æè¿°
                if not text_parts and description and not is_description_placeholder:
                    text_parts.append(description)

                # å¦‚æœæ‰€æœ‰å†…å®¹éƒ½æ˜¯å ä½ç¬¦æˆ–ä¸ºç©ºï¼Œè‡³å°‘æ˜¾ç¤ºæè¿°ï¼ˆå³ä½¿æ˜¯å ä½ç¬¦ï¼‰
                if not text_parts:
                    if description:
                        text_parts.append(description)
                    else:
                        text_parts.append(f"åœºæ™¯ {i}")

                # ç»„åˆæ–‡æœ¬
                combined_text = "\n\n".join(text_parts)

                parsed.append({
                    "title": s.get("title", f"åœºæ™¯ {i}"),
                    "text": combined_text
                })

                _log_info(f"  åœºæ™¯ {i}: {s.get('title', '')} - æ–‡æœ¬é•¿åº¦: {len(combined_text)}")

            return parsed
        except Exception as e:
            _log_error(f"åœºæ™¯è§£æå¤±è´¥: {str(e)}")
            import traceback
            _log_error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def _parse_formatted_text(self, text):
        """ä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­è§£æåœºæ™¯ä¿¡æ¯"""
        try:
            import re
            _log_info("ğŸ”„ å¼€å§‹è§£ææ ¼å¼åŒ–æ–‡æœ¬")
            lines = text.split('\n')
            scenes = []
            current_scene = None
            current_description = None  # ä¿å­˜æè¿°å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # åŒ¹é…åœºæ™¯æ ‡é¢˜ï¼šåœºæ™¯ 1: xxx æˆ– åœºæ™¯1: xxxï¼ˆæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
                scene_match = re.match(r'åœºæ™¯\s*(\d+)[ï¼š:]\s*(.+)', line)
                if scene_match:
                    # ä¿å­˜ä¸Šä¸€ä¸ªåœºæ™¯
                    if current_scene:
                        # å¦‚æœåœºæ™¯æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨æè¿°ä½œä¸ºé™çº§
                        if not current_scene["text"] and current_description:
                            current_scene["text"] = current_description
                        scenes.append(current_scene)
                    # å¼€å§‹æ–°åœºæ™¯
                    current_scene = {
                        "title": scene_match.group(2).strip(),
                        "text": ""
                    }
                    current_description = None
                    continue

                # æ”¶é›†åœºæ™¯å†…å®¹
                if current_scene:
                    # åŒ¹é…æ ‡ç­¾è¡Œï¼ˆæè¿°:ã€å¯¹è¯:ã€æ—ç™½:ï¼Œæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
                    label_match = re.match(r'^(æè¿°|å¯¹è¯|æ—ç™½)[ï¼š:]\s*(.+)', line)
                    if label_match:
                        label = label_match.group(1)
                        content = label_match.group(2).strip()

                        # è¿‡æ»¤å ä½ç¬¦å†…å®¹
                        is_placeholder = False
                        if label == "æ—ç™½" and re.match(r'^æ—ç™½(æè¿°|å†…å®¹|æ–‡å­—)?\s*\d*$', content):
                            is_placeholder = True
                        elif label == "å¯¹è¯" and re.match(r'^(è§’è‰²)?å¯¹è¯(å†…å®¹)?\s*\d*$', content):
                            is_placeholder = True
                        elif label == "æè¿°":
                            # ä¿å­˜æè¿°å†…å®¹ï¼ˆå³ä½¿æ˜¯å ä½ç¬¦ï¼Œä¹Ÿä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰
                            current_description = content
                            if re.match(r'^(åœºæ™¯)?æè¿°\s*\d*$', content) or \
                               content.startswith("æ•…äº‹çš„ç¬¬") or \
                               content.startswith("åœºæ™¯çš„"):
                                is_placeholder = True

                        if content and not is_placeholder:
                            if current_scene["text"]:
                                current_scene["text"] += f"\n\n{label}ï¼š{content}"
                            else:
                                current_scene["text"] = f"{label}ï¼š{content}"
                    else:
                        # å…¶ä»–å†…å®¹ä¹Ÿæ·»åŠ è¿›å»ï¼ˆå¦‚æœä¸æ˜¯ç©ºè¡Œï¼‰
                        if line and not line.startswith("ğŸ“š"):
                            if current_scene["text"]:
                                current_scene["text"] += "\n" + line
                            else:
                                current_scene["text"] = line

            # ä¿å­˜æœ€åä¸€ä¸ªåœºæ™¯
            if current_scene:
                # å¦‚æœåœºæ™¯æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨æè¿°ä½œä¸ºé™çº§
                if not current_scene["text"] and current_description:
                    current_scene["text"] = current_description
                scenes.append(current_scene)

            _log_info(f"âœ… ä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­è§£æå‡º {len(scenes)} ä¸ªåœºæ™¯")
            return scenes

        except Exception as e:
            _log_error(f"æ ¼å¼åŒ–æ–‡æœ¬è§£æå¤±è´¥: {str(e)}")
            import traceback
            _log_error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def create_viewer(self, images, story_structure, title="æˆ‘çš„è¿ç¯ç”»", output_filename="comic_story.html",
                     transition_effect="page-turn", transition_duration=1.5):
        try:
            import os, time
            # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨å‹ç¼©å’Œç¼©æ”¾æ¥å‡å°HTMLæ–‡ä»¶å¤§å°
            # quality=85: JPEGè´¨é‡ï¼ˆ1-100ï¼‰ï¼Œ85æ˜¯é«˜è´¨é‡å’Œæ–‡ä»¶å¤§å°çš„å¹³è¡¡ç‚¹
            # max_size=1920: æœ€å¤§å®½åº¦æˆ–é«˜åº¦ï¼Œå¯¹äºç½‘é¡µæ˜¾ç¤ºå·²ç»è¶³å¤Ÿ
            _log_info("ğŸ–¼ï¸ å¼€å§‹ç¼–ç å›¾ç‰‡ï¼ˆä½¿ç”¨å‹ç¼©ä¼˜åŒ–ä»¥å‡å°æ–‡ä»¶å¤§å°ï¼‰...")
            img_list = self._tensor_batch_to_base64_list(images, quality=85, max_size=1920)
            pages = self._parse_scenes_from_structure(story_structure)
            total = max(len(img_list), len(pages))
            # å¯¹é½é•¿åº¦
            while len(img_list) < total and len(img_list) > 0:
                img_list.append(img_list[-1])
            while len(pages) < total and total > 0:
                pages.append({"title": f"ç¬¬{len(pages)+1}é¡µ", "text": ""})

            html = self._build_html(title, img_list, pages, transition_effect, transition_duration)

            # ä½¿ç”¨ComfyUIçš„outputç›®å½•
            try:
                import folder_paths
                out_dir = folder_paths.get_output_directory()
                _log_info(f"ğŸ“ ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•: {out_dir}")
            except ImportError:
                # å¦‚æœåœ¨ComfyUIç¯å¢ƒå¤–ï¼Œå°è¯•æ¨æ–­ComfyUIè·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None

                # å‘ä¸ŠæŸ¥æ‰¾ComfyUIæ ¹ç›®å½•
                path_parts = current_dir.split(os.sep)
                for i in range(len(path_parts), 0, -1):
                    potential_root = os.sep.join(path_parts[:i])
                    if os.path.exists(os.path.join(potential_root, "main.py")) and \
                       os.path.exists(os.path.join(potential_root, "nodes.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    out_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(out_dir, exist_ok=True)
                    _log_info(f"ğŸ“ æ¨æ–­ComfyUIè¾“å‡ºç›®å½•: {out_dir}")
                else:
                    # é™çº§åˆ°web/exportsç›®å½•
                    out_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "web", "exports"))
                    _log_info(f"ğŸ“ ä½¿ç”¨web/exportsç›®å½•: {out_dir}")

            os.makedirs(out_dir, exist_ok=True)
            # åŠ æ—¶é—´æˆ³é˜²æ­¢è¦†ç›–
            ts = int(time.time())
            if not output_filename.lower().endswith(".html"):
                output_filename += ".html"
            out_path = os.path.join(out_dir, f"{ts}_" + output_filename)
            with open(out_path, "w", encoding="utf-8") as f:
                f.write(html)
            info = f"âœ… å·²ç”Ÿæˆè¿ç¯ç”»HTMLæµè§ˆæ–‡ä»¶: {out_path}\né¡µæ•°: {total}\nç‰¹æ•ˆ: {transition_effect} ({transition_duration}s)"
            _log_info(info)
            return (out_path, info)
        except Exception as e:
            _log_error(f"åˆ›å»ºHTMLæµè§ˆæ–‡ä»¶å¤±è´¥: {str(e)}")
            return ("", f"é”™è¯¯: {str(e)}")

    def _build_html(self, title, img_list, pages, transition_effect="page-turn", transition_duration=1.5):
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        _log_info(f"[DEBUG] _build_html è°ƒç”¨å‚æ•°: transition_effect={transition_effect}, transition_duration={transition_duration}")

        # å°è¯•ä½¿ç”¨æ–°çš„æ¨¡æ¿ç”Ÿæˆå™¨
        try:
            import sys
            import importlib
            # å¼ºåˆ¶é‡æ–°åŠ è½½æ¨¡å—
            if 'custom_nodes.ComfyUI_doubao_seed.comic_html_template' in sys.modules:
                importlib.reload(sys.modules['custom_nodes.ComfyUI_doubao_seed.comic_html_template'])

            from .comic_html_template import build_comic_html
            _log_info(f"[DEBUG] è°ƒç”¨ build_comic_htmlï¼Œtransition_effect={transition_effect}")
            html = build_comic_html(title, img_list, pages, transition_effect, transition_duration)
            _log_info(f"[DEBUG] build_comic_html æˆåŠŸï¼ŒHTMLé•¿åº¦={len(html)}")
            return html
        except Exception as e:
            _log_error(f"ä½¿ç”¨æ–°æ¨¡æ¿å¤±è´¥ï¼Œé™çº§åˆ°ç®€å•æ¨¡æ¿: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())

        # é™çº§åˆ°ç®€å•æ¨¡æ¿
        import json
        total = len(img_list)
        img_list_json = json.dumps(img_list)
        pages_json = json.dumps(pages)
        # ç®€æ˜“æ ·å¼ä¸ç¿»é¡µé€»è¾‘ï¼Œå°½é‡æ¥è¿‘å®˜æ–¹â€œå·¦å›¾å³æ–‡ã€ä¸Šä¸‹é¡µâ€ä½“éªŒ
        return f"""<!DOCTYPE html>
<html lang=\"zh-CN\">
<head>
<meta charset=\"utf-8\" />
<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />
<title>{title}</title>
<style>
body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, 'Noto Sans', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif; margin: 0; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; }}
.container {{ max-width: 1300px; margin: 0 auto; background: #fff; box-shadow: 0 10px 40px rgba(0,0,0,0.2); border-radius: 16px; padding: 36px; }}
.header {{ display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; padding-bottom: 14px; border-bottom: 2px solid #f0f0f0; }}
.page {{ display: grid; grid-template-columns: 1.5fr 1fr; gap: 28px; align-items: start; min-height: 550px; }}
.img-wrap {{ border-radius: 12px; overflow: hidden; box-shadow: 0 6px 24px rgba(0,0,0,0.12); }}
.img-wrap img {{ width: 100%; height: auto; display: block; }}
.text-wrap {{ background: linear-gradient(135deg, #fdfbfb 0%, #ebedee 100%); border-radius: 12px; padding: 28px; min-height: 450px; box-shadow: 0 4px 16px rgba(0,0,0,0.08); line-height: 2.1; font-size: 16px; color: #333; overflow-y: auto; max-height: 650px; }}
.toolbar {{ display: flex; gap: 12px; align-items: center; }}
.btn {{ border: none; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; padding: 10px 20px; cursor: pointer; font-size: 16px; font-weight: 500; transition: all 0.3s ease; box-shadow: 0 2px 10px rgba(102, 126, 234, 0.3); }}
.btn:hover {{ transform: translateY(-2px); box-shadow: 0 4px 15px rgba(102, 126, 234, 0.5); }}
.counter {{ color: #666; font-size: 16px; font-weight: 500; min-width: 60px; text-align: center; }}
@media (max-width: 768px) {{ .page {{ grid-template-columns: 1fr; gap: 20px; }} .container {{ padding: 20px; }} }}
</style>
</head>
<body>
  <div class=\"container\">
    <div class=\"header\">
      <div>ğŸ“– {title}</div>
      <div class=\"toolbar\">
        <button class=\"btn\" onclick=\"prev()\">â—€</button>
        <span class=\"counter\" id=\"counter\">1/{total}</span>
        <button class=\"btn\" onclick=\"next()\">â–¶</button>
      </div>
    </div>
    <div class=\"page\">
      <div class=\"img-wrap\"><img id=\"img\" src=\"{img_list[0] if total>0 else ''}\" /></div>
      <div class=\"text-wrap\"><div id=\"text\">{pages[0]['text'] if total>0 else ''}</div></div>
    </div>
  </div>
<script>
const IMGS = {img_list_json};
const PAGES = {pages_json};
let i = 0;
function render() {{
  if (IMGS.length === 0) return;
  document.getElementById('img').src = IMGS[i];
  document.getElementById('text').innerText = (PAGES[i] && (PAGES[i].text||'')) || '';
  document.getElementById('counter').innerText = (i+1) + '/' + IMGS.length;
}}
function prev() {{ i = (i - 1 + IMGS.length) % IMGS.length; render(); }}
function next() {{ i = (i + 1) % IMGS.length; render(); }}
document.addEventListener('keydown', (e) => {{ if (e.key==='ArrowLeft') prev(); if (e.key==='ArrowRight') next(); }});
</script>
</body>
</html>"""


# æ‰¹é‡å¯¼å‡ºèŠ‚ç‚¹ï¼šå°†å›¾åƒæ‰¹æ¬¡å¯¼å‡ºä¸ºå›¾ç‰‡åºåˆ—ï¼Œå¹¶å¯é€‰åˆæˆä¸ºPDF
class ComicBatchExporterNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
            },
            "optional": {
                "story_structure": ("STRING", {"multiline": True, "default": ""}),
                "title": ("STRING", {"default": "æˆ‘çš„è¿ç¯ç”»"}),
                "output_subdir": ("STRING", {"default": "comic_export"}),
                "filename_prefix": ("STRING", {"default": "page_"}),
                "image_format": (["png", "jpg"], {"default": "png"}),
                "jpg_quality": ("INT", {"default": 92, "min": 10, "max": 100, "step": 1}),
                "export_pdf": ("BOOLEAN", {"default": True}),
                "pdf_with_text": ("BOOLEAN", {"default": True}),
                "pdf_filename": ("STRING", {"default": "comic_story.pdf"}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("export_dir", "summary")
    FUNCTION = "export"
    CATEGORY = "Ken-Chen/Doubao"

    def _tensor_batch_to_pil_list(self, images):
        try:
            import torch
            from PIL import Image
            if images is None or not isinstance(images, torch.Tensor) or images.ndim != 4:
                return []
            data = images.clamp(0.0, 1.0).mul(255.0).byte().cpu().numpy()
            pil_list = []
            for i in range(data.shape[0]):
                pil_list.append(Image.fromarray(data[i], mode="RGB"))
            return pil_list
        except Exception as e:
            _log_error(f"å›¾åƒè½¬æ¢å¤±è´¥: {str(e)}")
            return []

    def _parse_pages(self, story_structure):
        try:
            import json
            import re

            if not story_structure:
                _log_warning("âš ï¸ æ•…äº‹ç»“æ„ä¸ºç©ºï¼Œè·³è¿‡æ–‡æœ¬å¯¼å‡º")
                return []

            if isinstance(story_structure, dict):
                data = story_structure
            else:
                # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå»é™¤markdownä»£ç å—ï¼‰
                story_str = str(story_structure).strip()

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¼å¼åŒ–æ–‡æœ¬
                if story_str.startswith("ğŸ“š è¿ç¯ç”»æ•…äº‹ç»“æ„") or "åœºæ™¯ 1:" in story_str or "åœºæ™¯ 2:" in story_str:
                    _log_info("ğŸ”„ æ£€æµ‹åˆ°æ ¼å¼åŒ–æ–‡æœ¬ï¼Œå°è¯•è§£æ...")
                    return self._parse_formatted_text_for_export(story_str)

                # ç§»é™¤markdownä»£ç å—æ ‡è®°
                if story_str.startswith("```"):
                    lines = story_str.split('\n')
                    if len(lines) > 1:
                        story_str = '\n'.join(lines[1:])
                        if story_str.endswith("```"):
                            story_str = story_str[:-3].strip()

                # å°è¯•æå–JSONå¯¹è±¡
                json_match = re.search(r'\{.*\}', story_str, re.DOTALL)
                if json_match:
                    story_str = json_match.group()

                try:
                    data = json.loads(story_str)
                except json.JSONDecodeError as je:
                    _log_warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•æ ¼å¼åŒ–æ–‡æœ¬è§£æ: {je}")
                    return self._parse_formatted_text_for_export(story_structure)

            scenes = data.get("scenes", [])
            parsed = []
            for i, s in enumerate(scenes, 1):
                # ç»„åˆæ‰€æœ‰å¯ç”¨çš„æ–‡æœ¬å†…å®¹
                text_parts = []

                # è·å–æè¿°ï¼ˆæ€»æ˜¯éœ€è¦ï¼Œå› ä¸ºè¿™æ˜¯å›¾åƒç”Ÿæˆçš„æç¤ºè¯ï¼‰
                description = s.get("description", "").strip()

                # æ·»åŠ æ—ç™½ï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
                narration = s.get("narration", "").strip()
                # è¿‡æ»¤æ‰å ä½ç¬¦æ–‡æœ¬ï¼ˆå¦‚"æ—ç™½æè¿° 1"ã€"æ—ç™½å†…å®¹"ç­‰ï¼‰
                is_narration_placeholder = re.match(r'^æ—ç™½(æè¿°|å†…å®¹|æ–‡å­—)?\s*\d*$', narration) if narration else True

                # æ·»åŠ å¯¹è¯ï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
                dialogue = s.get("dialogue", "").strip()
                # è¿‡æ»¤æ‰å ä½ç¬¦æ–‡æœ¬ï¼ˆå¦‚"è§’è‰²å¯¹è¯ 1"ã€"å¯¹è¯å†…å®¹"ç­‰ï¼‰
                is_dialogue_placeholder = re.match(r'^(è§’è‰²)?å¯¹è¯(å†…å®¹)?\s*\d*$', dialogue) if dialogue else True

                # æ£€æŸ¥æè¿°æ˜¯å¦æ˜¯å ä½ç¬¦
                is_description_placeholder = False
                if description:
                    if re.match(r'^(åœºæ™¯)?æè¿°\s*\d*$', description) or \
                       description.startswith("æ•…äº‹çš„ç¬¬") or \
                       description.startswith("åœºæ™¯çš„"):
                        is_description_placeholder = True

                # ç»„åˆæ–‡æœ¬ï¼šä¼˜å…ˆä½¿ç”¨æ—ç™½å’Œå¯¹è¯ï¼Œå¦‚æœéƒ½æ˜¯å ä½ç¬¦åˆ™ä½¿ç”¨æè¿°
                if narration and not is_narration_placeholder:
                    text_parts.append(f"æ—ç™½ï¼š{narration}")

                if dialogue and not is_dialogue_placeholder:
                    text_parts.append(f"å¯¹è¯ï¼š{dialogue}")

                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ—ç™½å’Œå¯¹è¯ï¼Œä½¿ç”¨æè¿°
                if not text_parts and description and not is_description_placeholder:
                    text_parts.append(description)

                # å¦‚æœæ‰€æœ‰å†…å®¹éƒ½æ˜¯å ä½ç¬¦æˆ–ä¸ºç©ºï¼Œè‡³å°‘æ˜¾ç¤ºæè¿°ï¼ˆå³ä½¿æ˜¯å ä½ç¬¦ï¼‰
                if not text_parts:
                    if description:
                        text_parts.append(description)
                    else:
                        text_parts.append(f"åœºæ™¯ {i}")

                # ç»„åˆæ–‡æœ¬
                combined_text = "\n\n".join(text_parts)

                parsed.append({
                    "title": s.get("title", f"åœºæ™¯ {i}"),
                    "text": combined_text
                })

            return parsed
        except Exception as e:
            _log_warning(f"è§£ææ•…äº‹ç»“æ„å¤±è´¥ï¼Œè·³è¿‡æ–‡æœ¬å¯¼å‡º: {str(e)}")
            return []

    def _parse_formatted_text_for_export(self, text):
        """ä»æ ¼å¼åŒ–æ–‡æœ¬ä¸­è§£æåœºæ™¯ä¿¡æ¯ï¼ˆç”¨äºå¯¼å‡ºï¼‰"""
        try:
            import re
            lines = text.split('\n')
            scenes = []
            current_scene = None
            current_description = None  # ä¿å­˜æè¿°å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # åŒ¹é…åœºæ™¯æ ‡é¢˜ï¼ˆæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
                scene_match = re.match(r'åœºæ™¯\s*(\d+)[ï¼š:]\s*(.+)', line)
                if scene_match:
                    if current_scene:
                        # å¦‚æœåœºæ™¯æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨æè¿°ä½œä¸ºé™çº§
                        if not current_scene["text"] and current_description:
                            current_scene["text"] = current_description
                        scenes.append(current_scene)
                    current_scene = {
                        "title": scene_match.group(2).strip(),
                        "text": ""
                    }
                    current_description = None
                    continue

                # æ”¶é›†åœºæ™¯å†…å®¹
                if current_scene:
                    # åŒ¹é…æ ‡ç­¾è¡Œï¼ˆæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
                    label_match = re.match(r'^(æè¿°|å¯¹è¯|æ—ç™½)[ï¼š:]\s*(.+)', line)
                    if label_match:
                        label = label_match.group(1)
                        content = label_match.group(2).strip()

                        # è¿‡æ»¤å ä½ç¬¦å†…å®¹
                        is_placeholder = False
                        if label == "æ—ç™½" and re.match(r'^æ—ç™½(æè¿°|å†…å®¹|æ–‡å­—)?\s*\d*$', content):
                            is_placeholder = True
                        elif label == "å¯¹è¯" and re.match(r'^(è§’è‰²)?å¯¹è¯(å†…å®¹)?\s*\d*$', content):
                            is_placeholder = True
                        elif label == "æè¿°":
                            # ä¿å­˜æè¿°å†…å®¹ï¼ˆå³ä½¿æ˜¯å ä½ç¬¦ï¼Œä¹Ÿä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰
                            current_description = content
                            if re.match(r'^(åœºæ™¯)?æè¿°\s*\d*$', content) or \
                               content.startswith("æ•…äº‹çš„ç¬¬") or \
                               content.startswith("åœºæ™¯çš„"):
                                is_placeholder = True

                        if content and not is_placeholder:
                            if current_scene["text"]:
                                current_scene["text"] += f"\n\n{label}ï¼š{content}"
                            else:
                                current_scene["text"] = f"{label}ï¼š{content}"
                    else:
                        # å…¶ä»–å†…å®¹ä¹Ÿæ·»åŠ è¿›å»ï¼ˆå¦‚æœä¸æ˜¯ç©ºè¡Œï¼‰
                        if line and not line.startswith("ğŸ“š"):
                            if current_scene["text"]:
                                current_scene["text"] += "\n" + line
                            else:
                                current_scene["text"] = line

            if current_scene:
                # å¦‚æœåœºæ™¯æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨æè¿°ä½œä¸ºé™çº§
                if not current_scene["text"] and current_description:
                    current_scene["text"] = current_description
                scenes.append(current_scene)

            return scenes

        except Exception as e:
            _log_error(f"æ ¼å¼åŒ–æ–‡æœ¬è§£æå¤±è´¥: {str(e)}")
            import traceback
            _log_error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def _create_pdf_with_text(self, pil_list, pages, title, pdf_path):
        """åˆ›å»ºå¸¦æ–‡å­—çš„PDFï¼ˆä¸Šå›¾ä¸‹æ–‡æ’ç‰ˆï¼‰"""
        try:
            from reportlab.lib.pagesizes import A4
            from reportlab.pdfgen import canvas
            from reportlab.lib.utils import ImageReader
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            import os

            # æ³¨å†Œä¸­æ–‡å­—ä½“
            try:
                # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
                font_paths = [
                    "C:/Windows/Fonts/msyh.ttc",  # å¾®è½¯é›…é»‘
                    "C:/Windows/Fonts/simhei.ttf",  # é»‘ä½“
                    "C:/Windows/Fonts/simsun.ttc",  # å®‹ä½“
                    "/System/Library/Fonts/PingFang.ttc",  # macOS
                    "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
                ]

                font_registered = False
                for font_path in font_paths:
                    if os.path.exists(font_path):
                        try:
                            pdfmetrics.registerFont(TTFont('Chinese', font_path))
                            font_registered = True
                            _log_info(f"âœ… ä½¿ç”¨å­—ä½“: {font_path}")
                            break
                        except:
                            continue

                if not font_registered:
                    _log_warning("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
                    font_name = "Helvetica"
                else:
                    font_name = "Chinese"
            except Exception as e:
                _log_warning(f"âš ï¸ å­—ä½“æ³¨å†Œå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
                font_name = "Helvetica"

            # åˆ›å»ºPDF
            c = canvas.Canvas(pdf_path, pagesize=A4)
            page_width, page_height = A4

            # è¾¹è·
            margin = 40
            content_width = page_width - 2 * margin

            for i, img in enumerate(pil_list):
                # è·å–å¯¹åº”çš„æ–‡æœ¬
                page_data = pages[i] if i < len(pages) else {"title": f"åœºæ™¯ {i+1}", "text": ""}
                page_title = page_data.get("title", f"åœºæ™¯ {i+1}")
                page_text = page_data.get("text", "")

                # ç»˜åˆ¶é¡µé¢æ ‡é¢˜å’Œé¡µç 
                c.setFont(font_name, 18)
                c.drawString(margin, page_height - margin, title)

                c.setFont(font_name, 12)
                c.drawString(page_width - margin - 60, page_height - margin, f"ç¬¬ {i+1} é¡µ")

                # å½“å‰Yä½ç½®
                current_y = page_height - margin - 40

                # ========== ä¸ŠåŠéƒ¨åˆ†ï¼šå›¾ç‰‡ ==========
                # è®¡ç®—å›¾ç‰‡å°ºå¯¸ï¼ˆä¿æŒå®½é«˜æ¯”ï¼Œå ç”¨é¡µé¢ä¸ŠåŠéƒ¨åˆ†ï¼‰
                img_aspect = img.width / img.height

                # å›¾ç‰‡å®½åº¦ä¸ºå†…å®¹åŒºåŸŸçš„90%
                img_width = content_width * 0.9
                img_height = img_width / img_aspect

                # å›¾ç‰‡æœ€å¤§é«˜åº¦ä¸ºé¡µé¢çš„60%
                max_img_height = (page_height - 2 * margin - 80) * 0.6
                if img_height > max_img_height:
                    img_height = max_img_height
                    img_width = img_height * img_aspect

                # å›¾ç‰‡å±…ä¸­æ˜¾ç¤º
                img_x = margin + (content_width - img_width) / 2
                img_y = current_y - img_height

                c.drawImage(ImageReader(img), img_x, img_y, width=img_width, height=img_height)

                # æ›´æ–°Yä½ç½®ï¼ˆå›¾ç‰‡ä¸‹æ–¹ç•™ä¸€äº›é—´è·ï¼‰
                current_y = img_y - 30

                # ========== ä¸‹åŠéƒ¨åˆ†ï¼šæ–‡æœ¬ ==========
                # ç»˜åˆ¶åœºæ™¯æ ‡é¢˜
                c.setFont(font_name, 14)
                c.drawString(margin, current_y, page_title)
                current_y -= 25

                # ç»˜åˆ¶åˆ†éš”çº¿
                c.setStrokeColorRGB(0.7, 0.7, 0.7)
                c.setLineWidth(0.5)
                c.line(margin, current_y, page_width - margin, current_y)
                current_y -= 15

                # ç»˜åˆ¶æ–‡æœ¬å†…å®¹
                c.setFont(font_name, 11)
                c.setFillColorRGB(0.2, 0.2, 0.2)

                # åˆ†è¡Œæ˜¾ç¤ºæ–‡æœ¬
                lines = page_text.split('\n')
                line_height = 18
                max_chars_per_line = 50  # æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°

                for line in lines:
                    if not line.strip():
                        current_y -= line_height / 2
                        continue

                    # æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†
                    while len(line) > max_chars_per_line:
                        c.drawString(margin, current_y, line[:max_chars_per_line])
                        line = line[max_chars_per_line:]
                        current_y -= line_height

                        # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé¡µé¢åº•éƒ¨
                        if current_y < margin + 30:
                            break

                    if current_y >= margin + 30:
                        c.drawString(margin, current_y, line)
                        current_y -= line_height

                    # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé¡µé¢åº•éƒ¨
                    if current_y < margin + 30:
                        break

                # ç»˜åˆ¶é¡µé¢åº•éƒ¨åˆ†éš”çº¿
                c.setStrokeColorRGB(0.8, 0.8, 0.8)
                c.setLineWidth(0.5)
                c.line(margin, margin + 15, page_width - margin, margin + 15)

                # ä¸‹ä¸€é¡µ
                c.showPage()

            c.save()
            _log_info(f"âœ… å·²ç”Ÿæˆå¸¦æ–‡å­—çš„PDF: {pdf_path}")
            return True

        except ImportError:
            _log_error("âŒ éœ€è¦å®‰è£… reportlab åº“æ‰èƒ½ç”Ÿæˆå¸¦æ–‡å­—çš„PDF")
            _log_error("   è¯·è¿è¡Œ: pip install reportlab")
            return False
        except Exception as e:
            _log_error(f"âŒ ç”Ÿæˆå¸¦æ–‡å­—PDFå¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())
            return False

    def export(self, images, story_structure="", title="æˆ‘çš„è¿ç¯ç”»", output_subdir="comic_export",
               filename_prefix="page_", image_format="png", jpg_quality=92,
               export_pdf=True, pdf_with_text=True, pdf_filename="comic_story.pdf"):
        try:
            import os, time
            from PIL import Image
            pil_list = self._tensor_batch_to_pil_list(images)
            if not pil_list:
                return ("", "æ²¡æœ‰å¯å¯¼å‡ºçš„å›¾åƒ")

            # ä½¿ç”¨ComfyUIçš„outputç›®å½•
            try:
                import folder_paths
                base_dir = folder_paths.get_output_directory()
                _log_info(f"ğŸ“ ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•: {base_dir}")
            except ImportError:
                # å¦‚æœåœ¨ComfyUIç¯å¢ƒå¤–ï¼Œå°è¯•æ¨æ–­ComfyUIè·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None

                # å‘ä¸ŠæŸ¥æ‰¾ComfyUIæ ¹ç›®å½•
                path_parts = current_dir.split(os.sep)
                for i in range(len(path_parts), 0, -1):
                    potential_root = os.sep.join(path_parts[:i])
                    if os.path.exists(os.path.join(potential_root, "main.py")) and \
                       os.path.exists(os.path.join(potential_root, "nodes.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    base_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(base_dir, exist_ok=True)
                    _log_info(f"ğŸ“ æ¨æ–­ComfyUIè¾“å‡ºç›®å½•: {base_dir}")
                else:
                    # é™çº§åˆ°web/exportsç›®å½•
                    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "web", "exports"))
                    _log_info(f"ğŸ“ ä½¿ç”¨web/exportsç›®å½•: {base_dir}")

            # ç›®å½•: output/<timestamp_title>/<output_subdir>
            ts_dir = f"{int(time.time())}_{title}"
            export_dir = os.path.join(base_dir, ts_dir, output_subdir)
            os.makedirs(export_dir, exist_ok=True)

            # ä¿å­˜å›¾ç‰‡åºåˆ—
            count = 0
            for i, img in enumerate(pil_list, start=1):
                if image_format == "jpg":
                    fp = os.path.join(export_dir, f"{filename_prefix}{i:02d}.jpg")
                    img.convert("RGB").save(fp, quality=int(jpg_quality))
                else:
                    fp = os.path.join(export_dir, f"{filename_prefix}{i:02d}.png")
                    img.save(fp)
                count += 1

            # ä¿å­˜æ–‡æœ¬ï¼ˆå¦‚æœ‰ï¼‰
            pages = self._parse_pages(story_structure)
            if pages:
                txt_path = os.path.join(export_dir, "story_texts.txt")
                with open(txt_path, "w", encoding="utf-8") as f:
                    for i, p in enumerate(pages, start=1):
                        f.write(f"ç¬¬{i}é¡µ\n{p.get('title','')}\n{p.get('text','')}\n\n")

            # åˆæˆPDFï¼ˆå¯é€‰ï¼‰
            pdf_path = ""
            pdf_status = "æœªç”Ÿæˆ"
            if export_pdf and len(pil_list) > 0:
                pdf_path = os.path.join(base_dir, ts_dir, pdf_filename if pdf_filename.lower().endswith('.pdf') else pdf_filename + '.pdf')
                os.makedirs(os.path.dirname(pdf_path), exist_ok=True)

                # æ ¹æ® pdf_with_text å‚æ•°é€‰æ‹©ç”Ÿæˆæ–¹å¼
                if pdf_with_text and pages:
                    # ç”Ÿæˆå¸¦æ–‡å­—çš„PDFï¼ˆå·¦å›¾å³æ–‡æ’ç‰ˆï¼‰
                    _log_info("ğŸ“„ ç”Ÿæˆå¸¦æ–‡å­—çš„PDF...")
                    success = self._create_pdf_with_text(pil_list, pages, title, pdf_path)
                    if success:
                        pdf_status = f"å·²ç”Ÿæˆå¸¦æ–‡å­—PDF: {pdf_path}"
                    else:
                        # é™çº§åˆ°çº¯å›¾ç‰‡PDF
                        _log_warning("âš ï¸ é™çº§åˆ°çº¯å›¾ç‰‡PDF")
                        first = pil_list[0].convert("RGB")
                        rest = [p.convert("RGB") for p in pil_list[1:]]
                        first.save(pdf_path, save_all=True, append_images=rest)
                        pdf_status = f"å·²ç”Ÿæˆçº¯å›¾ç‰‡PDF: {pdf_path}"
                else:
                    # ç”Ÿæˆçº¯å›¾ç‰‡PDF
                    _log_info("ğŸ“„ ç”Ÿæˆçº¯å›¾ç‰‡PDF...")
                    first = pil_list[0].convert("RGB")
                    rest = [p.convert("RGB") for p in pil_list[1:]]
                    first.save(pdf_path, save_all=True, append_images=rest)
                    pdf_status = f"å·²ç”Ÿæˆçº¯å›¾ç‰‡PDF: {pdf_path}"

            summary = f"âœ… å¯¼å‡ºå®Œæˆ\nç›®å½•: {export_dir}\nå›¾ç‰‡æ•°: {count}\nPDF: {pdf_status}"
            _log_info(summary)
            return (export_dir, summary)
        except Exception as e:
            _log_error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            return ("", f"é”™è¯¯: {str(e)}")


# è¿ç¯ç”»æµè§ˆå™¨èŠ‚ç‚¹ï¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶
class ComicBrowserViewerNode:
    """è¿ç¯ç”»æµè§ˆå™¨èŠ‚ç‚¹ - åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLè¿ç¯ç”»æ–‡ä»¶"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "viewer_path": ("STRING", {"default": "", "multiline": False}),
            },
            "optional": {
                "auto_open": ("BOOLEAN", {"default": False}),  # é»˜è®¤ä¸è‡ªåŠ¨æ‰“å¼€ï¼Œé€šè¿‡æŒ‰é’®æ§åˆ¶
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("file_url", "status")
    FUNCTION = "open_in_browser"
    CATEGORY = "Ken-Chen/Doubao"
    OUTPUT_NODE = True  # æ ‡è®°ä¸ºè¾“å‡ºèŠ‚ç‚¹ï¼Œè¿™æ ·ä¼šåœ¨æ‰§è¡Œæ—¶æ˜¾ç¤ºç»“æœ

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ€»æ˜¯æ ‡è®°ä¸ºå·²æ›´æ”¹ï¼Œç¡®ä¿æ¯æ¬¡éƒ½èƒ½æ‰§è¡Œ
        return float("nan")

    def open_in_browser(self, viewer_path, auto_open=False):
        """
        åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶

        Args:
            viewer_path: HTMLæ–‡ä»¶è·¯å¾„
            auto_open: æ˜¯å¦è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨

        Returns:
            tuple: (æ–‡ä»¶URL, çŠ¶æ€ä¿¡æ¯)
        """
        try:
            import os
            import webbrowser
            from pathlib import Path

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not viewer_path or not os.path.exists(viewer_path):
                error_msg = f"âŒ HTMLæ–‡ä»¶ä¸å­˜åœ¨: {viewer_path}"
                _log_error(error_msg)
                return ("", error_msg)

            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(viewer_path)

            # è½¬æ¢ä¸ºfile:// URL
            file_url = Path(abs_path).as_uri()

            # å¦‚æœå¯ç”¨è‡ªåŠ¨æ‰“å¼€ï¼Œåˆ™åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
            if auto_open:
                try:
                    _log_info(f"ğŸŒ æ­£åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {abs_path}")
                    webbrowser.open(file_url)
                    status = f"âœ… å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¿ç¯ç”»\næ–‡ä»¶: {abs_path}\nURL: {file_url}"
                    _log_info(status)
                except Exception as e:
                    error_msg = f"âš ï¸ è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨å¤±è´¥: {str(e)}\næ–‡ä»¶è·¯å¾„: {abs_path}\nè¯·æ‰‹åŠ¨æ‰“å¼€æ­¤æ–‡ä»¶"
                    _log_warning(error_msg)
                    status = error_msg
            else:
                status = f"ğŸ“„ HTMLæ–‡ä»¶å·²å‡†å¤‡\næ–‡ä»¶: {abs_path}\nURL: {file_url}\næç¤º: å¯ç”¨ auto_open å¯è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨"
                _log_info(status)

            return (file_url, status)

        except Exception as e:
            error_msg = f"âŒ æ‰“å¼€æµè§ˆå™¨å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            import traceback
            _log_error(traceback.format_exc())
            return ("", error_msg)


# è¿ç¯ç”»HTMLå†…åµŒé¢„è§ˆèŠ‚ç‚¹ï¼šåœ¨ComfyUIç•Œé¢å†…ç›´æ¥é¢„è§ˆè¿ç¯ç”»
class ComicHTMLPreviewNode:
    """è¿ç¯ç”»HTMLå†…åµŒé¢„è§ˆèŠ‚ç‚¹ - åœ¨ComfyUIç•Œé¢å†…ç›´æ¥é¢„è§ˆè¿ç¯ç”»HTML"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "viewer_path": ("STRING", {"default": "", "multiline": False}),
            },
            "optional": {
                "width": ("INT", {"default": 800, "min": 100, "max": 2000, "step": 10}),
                "height": ("INT", {"default": 600, "min": 100, "max": 2000, "step": 10}),
                "scale": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 2.0, "step": 0.1}),
            }
        }

    INPUT_IS_LIST = True
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("html_content",)
    FUNCTION = "preview_html"
    CATEGORY = "Ken-Chen/Doubao"
    OUTPUT_NODE = True
    OUTPUT_IS_LIST = (True,)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ€»æ˜¯æ ‡è®°ä¸ºå·²æ›´æ”¹ï¼Œç¡®ä¿æ¯æ¬¡éƒ½èƒ½åˆ·æ–°é¢„è§ˆ
        return float("nan")

    def preview_html(self, viewer_path, width=None, height=None, scale=None):
        """
        åœ¨ComfyUIç•Œé¢å†…é¢„è§ˆHTMLè¿ç¯ç”»

        Args:
            viewer_path: HTMLæ–‡ä»¶è·¯å¾„ï¼ˆåˆ—è¡¨ï¼‰
            width: é¢„è§ˆçª—å£å®½åº¦ï¼ˆåˆ—è¡¨ï¼‰
            height: é¢„è§ˆçª—å£é«˜åº¦ï¼ˆåˆ—è¡¨ï¼‰
            scale: ç¼©æ”¾æ¯”ä¾‹ï¼ˆåˆ—è¡¨ï¼‰

        Returns:
            åŒ…å«UIä¿¡æ¯å’ŒHTMLå†…å®¹çš„å­—å…¸
        """
        try:
            import os

            # å¤„ç†åˆ—è¡¨è¾“å…¥ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            path = viewer_path[0] if isinstance(viewer_path, list) else viewer_path
            w = width[0] if width and isinstance(width, list) else (width or 800)
            h = height[0] if height and isinstance(height, list) else (height or 600)
            s = scale[0] if scale and isinstance(scale, list) else (scale or 1.0)

            _log_info(f"ğŸ“º å‡†å¤‡é¢„è§ˆè¿ç¯ç”»HTML: {path}")
            _log_info(f"   é¢„è§ˆå°ºå¯¸: {w}x{h}, ç¼©æ”¾: {s}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not path or not os.path.exists(path):
                error_html = f"""
                <!DOCTYPE html>
                <html>
                <head>
                    <meta charset="utf-8">
                    <style>
                        body {{
                            font-family: Arial, sans-serif;
                            display: flex;
                            justify-content: center;
                            align-items: center;
                            height: 100vh;
                            margin: 0;
                            background: #f5f5f5;
                        }}
                        .error {{
                            background: white;
                            padding: 30px;
                            border-radius: 10px;
                            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                            text-align: center;
                        }}
                        .error h2 {{
                            color: #e74c3c;
                            margin-top: 0;
                        }}
                        .error p {{
                            color: #666;
                        }}
                    </style>
                </head>
                <body>
                    <div class="error">
                        <h2>âŒ æ–‡ä»¶æœªæ‰¾åˆ°</h2>
                        <p>HTMLæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ</p>
                        <p style="font-size: 12px; color: #999;">è·¯å¾„: {path}</p>
                    </div>
                </body>
                </html>
                """
                _log_error(f"âŒ HTMLæ–‡ä»¶ä¸å­˜åœ¨: {path}")
                return {
                    "ui": {
                        "html": [error_html],
                        "width": [w],
                        "height": [h],
                        "scale": [s],
                        "is_portrait": [False]
                    },
                    "result": ([error_html],)
                }

            # è¯»å–HTMLæ–‡ä»¶å†…å®¹
            with open(path, 'r', encoding='utf-8') as f:
                html_content = f.read()

            _log_info(f"âœ… æˆåŠŸè¯»å–HTMLæ–‡ä»¶ï¼Œå¤§å°: {len(html_content)} å­—èŠ‚")

            # è¿”å›UIä¿¡æ¯å’ŒHTMLå†…å®¹
            return {
                "ui": {
                    "html": [html_content],
                    "width": [w],
                    "height": [h],
                    "scale": [s],
                    "is_portrait": [False]  # è¿ç¯ç”»é€šå¸¸æ˜¯æ¨ªå‘å¸ƒå±€
                },
                "result": ([html_content],)
            }

        except Exception as e:
            _log_error(f"é¢„è§ˆHTMLå¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())

            error_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <style>
                    body {{
                        font-family: Arial, sans-serif;
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        height: 100vh;
                        margin: 0;
                        background: #f5f5f5;
                    }}
                    .error {{
                        background: white;
                        padding: 30px;
                        border-radius: 10px;
                        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                        text-align: center;
                        max-width: 600px;
                    }}
                    .error h2 {{
                        color: #e74c3c;
                        margin-top: 0;
                    }}
                    .error p {{
                        color: #666;
                    }}
                    .error pre {{
                        background: #f8f8f8;
                        padding: 10px;
                        border-radius: 5px;
                        text-align: left;
                        overflow-x: auto;
                        font-size: 12px;
                    }}
                </style>
            </head>
            <body>
                <div class="error">
                    <h2>âŒ é¢„è§ˆå¤±è´¥</h2>
                    <p>æ— æ³•åŠ è½½HTMLå†…å®¹</p>
                    <pre>{str(e)}</pre>
                </div>
            </body>
            </html>
            """

            return {
                "ui": {
                    "html": [error_html],
                    "width": [800],
                    "height": [600],
                    "scale": [1.0],
                    "is_portrait": [False]
                },
                "result": ([error_html],)
            }


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "SeedReam4APINode": SeedReam4APINode,
    "SeedReam4APISingleNode": SeedReam4APISingleNode,
    "DoubaoSeedanceVideoNode": DoubaoSeedanceVideoNode,
    "DoubaoSeedanceContinuousVideoNode": DoubaoSeedanceContinuousVideoNode,
    "DoubaoSeedanceMultiRefVideoNode": DoubaoSeedanceMultiRefVideoNode,
    "DoubaoSeed16Node": DoubaoSeed16Node,
    "DoubaoComicBookNode": DoubaoComicBookNode,
    "ComicPageSelectorNode": ComicPageSelectorNode,
    "ComicHTMLViewerNode": ComicHTMLViewerNode,
    "ComicBatchExporterNode": ComicBatchExporterNode,
    "ComicBrowserViewerNode": ComicBrowserViewerNode,
    "ComicHTMLPreviewNode": ComicHTMLPreviewNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SeedReam4APINode": "SeedReam4API (å¤šå›¾)",
    "SeedReam4APISingleNode": "SeedReam4API (å•å›¾)",
    "DoubaoSeedanceVideoNode": "Doubao-Seedanceè§†é¢‘ç”Ÿæˆ",
    "DoubaoSeedanceContinuousVideoNode": "Doubao-Seedanceè¿ç»­è§†é¢‘ç”Ÿæˆ",
    "DoubaoSeedanceMultiRefVideoNode": "Doubao-Seedanceå¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆ",
    "DoubaoSeed16Node": "doubao-seed-1-6",
    "DoubaoComicBookNode": "è±†åŒ…è¿ç¯ç”»åˆ›ä½œ",
    "ComicPageSelectorNode": "è¿ç¯ç”»åˆ†é¡µæµè§ˆ",
    "ComicHTMLViewerNode": "è¿ç¯ç”»HTMLæµè§ˆå¯¼å‡º",
    "ComicBatchExporterNode": "è¿ç¯ç”»æ‰¹é‡å¯¼å‡º(PNG/JPG/PDF)",
    "ComicBrowserViewerNode": "è¿ç¯ç”»æµè§ˆå™¨é¢„è§ˆ",
    "ComicHTMLPreviewNode": "è¿ç¯ç”»HTMLå†…åµŒé¢„è§ˆ",
}


# Web API è·¯ç”±
WEB_DIRECTORY = "./web"

# æ³¨å†Œ API è·¯ç”±
try:
    from aiohttp import web
    import server

    @server.PromptServer.instance.routes.post("/doubao_seed/open_browser")
    async def open_browser_api(request):
        """API ç«¯ç‚¹ï¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æ–‡ä»¶"""
        try:
            import os
            import webbrowser
            from pathlib import Path

            # è·å–è¯·æ±‚æ•°æ®
            data = await request.json()
            viewer_path = data.get("viewer_path", "")

            _log_info(f"ğŸŒ æ”¶åˆ°æ‰“å¼€æµè§ˆå™¨è¯·æ±‚: {viewer_path}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not viewer_path or not os.path.exists(viewer_path):
                error_msg = f"HTMLæ–‡ä»¶ä¸å­˜åœ¨: {viewer_path}"
                _log_error(f"âŒ {error_msg}")
                return web.json_response({
                    "success": False,
                    "error": error_msg
                })

            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(viewer_path)

            # è½¬æ¢ä¸º file:// URL
            file_url = Path(abs_path).as_uri()

            # åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
            try:
                _log_info(f"ğŸŒ æ­£åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {abs_path}")
                webbrowser.open(file_url)

                success_msg = "å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¿ç¯ç”»"
                _log_info(f"âœ… {success_msg}")

                return web.json_response({
                    "success": True,
                    "message": success_msg,
                    "file_path": abs_path,
                    "file_url": file_url
                })

            except Exception as e:
                error_msg = f"æ‰“å¼€æµè§ˆå™¨å¤±è´¥: {str(e)}"
                _log_error(f"âŒ {error_msg}")
                return web.json_response({
                    "success": False,
                    "error": error_msg,
                    "file_path": abs_path,
                    "file_url": file_url
                })

        except Exception as e:
            error_msg = f"API è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
            _log_error(f"âŒ {error_msg}")
            import traceback
            _log_error(traceback.format_exc())
            return web.json_response({
                "success": False,
                "error": error_msg
            })

    _log_info("âœ… ComicBrowserViewer API è·¯ç”±å·²æ³¨å†Œ")

except Exception as e:
    _log_warning(f"âš ï¸ æ— æ³•æ³¨å†Œ API è·¯ç”±: {str(e)}")
    _log_warning("æµè§ˆå™¨é¢„è§ˆåŠŸèƒ½å¯èƒ½æ— æ³•é€šè¿‡æŒ‰é’®ä½¿ç”¨ï¼Œä½†ä»å¯é€šè¿‡ auto_open å‚æ•°ä½¿ç”¨")
